
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5. Neural Networks for Regression &#8212; Statistical Foundations of Machine Learning - Practicals handbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="application/vnd.jupyter.widget-state+json">{"state": {"28d70dd0b0534afb98feca5d5d4793f6": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "06361bebdd5249808055d96d58d2b1f6": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "ad4bc566d6f34f90b07750b902ff51da": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_28d70dd0b0534afb98feca5d5d4793f6", "max": 20.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_06361bebdd5249808055d96d58d2b1f6", "tabbable": null, "tooltip": null, "value": 20.0}}, "1d12209448084b2abe22ab2226940ce7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e3357db1a4734cf6a9852211299f2b63": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "1370fb011e024edc9cfdf3b855a95302": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_1d12209448084b2abe22ab2226940ce7", "placeholder": "\u200b", "style": "IPY_MODEL_e3357db1a4734cf6a9852211299f2b63", "tabbable": null, "tooltip": null, "value": "Epoch\u200720/20\u2007-\u2007Train\u2007Loss:\u200784.5405\u2007-\u2007Val\u2007Loss:\u2007101.8975:\u2007100%"}}, "a6077cf55f3146f2b28fb60257011c51": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1d860ad668f4443086bd394a325c846d": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "939939136ca54322a2c5584776b2627e": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_a6077cf55f3146f2b28fb60257011c51", "placeholder": "\u200b", "style": "IPY_MODEL_1d860ad668f4443086bd394a325c846d", "tabbable": null, "tooltip": null, "value": "\u200720/20\u2007[00:15&lt;00:00,\u2007\u20071.76it/s]"}}, "da47c33f9a7442d5aa01bb7db0d1ca6e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "105f70bf4c0b4978b360b80043b0756c": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_1370fb011e024edc9cfdf3b855a95302", "IPY_MODEL_ad4bc566d6f34f90b07750b902ff51da", "IPY_MODEL_939939136ca54322a2c5584776b2627e"], "layout": "IPY_MODEL_da47c33f9a7442d5aa01bb7db0d1ca6e", "tabbable": null, "tooltip": null}}, "f5a397243b0b48fa9cc77ab6cf3ac7e2": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4277232450bb47e0b3afc063dd99ff55": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "6bd5a1c31a5c425c9a27ad8778fe9439": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_f5a397243b0b48fa9cc77ab6cf3ac7e2", "max": 20.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_4277232450bb47e0b3afc063dd99ff55", "tabbable": null, "tooltip": null, "value": 20.0}}, "5680dc34cc474b6185aedb39cefa99f7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9ee8353cb33448b3908768c0359a8aa2": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "8b2a21a83f5e4178a4e4d18ab922c428": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_5680dc34cc474b6185aedb39cefa99f7", "placeholder": "\u200b", "style": "IPY_MODEL_9ee8353cb33448b3908768c0359a8aa2", "tabbable": null, "tooltip": null, "value": "Epoch\u200720/20\u2007-\u2007Training\u2007Loss:\u200737.4186\u2007-\u2007Validation\u2007Loss:\u200711.9391:\u2007100%"}}, "1c3e063e4f8d44a89dd0a4fd4e8111fe": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "40154854df7e47babdc4a771c2df046d": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "916a38ef1f314690859fdaa9c4dbc85b": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_1c3e063e4f8d44a89dd0a4fd4e8111fe", "placeholder": "\u200b", "style": "IPY_MODEL_40154854df7e47babdc4a771c2df046d", "tabbable": null, "tooltip": null, "value": "\u200720/20\u2007[00:42&lt;00:00,\u2007\u20072.26s/it]"}}, "df11afd66a104327b8e6a96588998e70": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "45927141ffda465bab0c91db5d6e2f13": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_8b2a21a83f5e4178a4e4d18ab922c428", "IPY_MODEL_6bd5a1c31a5c425c9a27ad8778fe9439", "IPY_MODEL_916a38ef1f314690859fdaa9c4dbc85b"], "layout": "IPY_MODEL_df11afd66a104327b8e6a96588998e70", "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '04';</script>
    <link rel="icon" href="_static/sfml.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. Ensembles of models and feature selection" href="05.html" />
    <link rel="prev" title="4. Data preprocessing and tree-based models" href="03.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="frontpage.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/sfml.png" class="logo__image only-light" alt="Statistical Foundations of Machine Learning - Practicals handbook - Home"/>
    <script>document.write(`<img src="_static/sfml.png" class="logo__image only-dark" alt="Statistical Foundations of Machine Learning - Practicals handbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="frontpage.html">
                    Home
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="01.html">2. Introduction to probabilistic methods and Monte Carlo simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="02.html">3. Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="03.html">4. Data preprocessing and tree-based models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. Neural Networks for Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="05.html">6. Ensembles of models and feature selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="06.html">7. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusion.html">8. Conclusion</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/04.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Networks for Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-neural-networks">5.1. Introduction to Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-for-neural-networks">5.1.1. Data Preprocessing for Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normalization-and-standardization">5.1.1.1. Normalization and Standardization</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#input-data-shaping">5.1.1.2. Input Data Shaping</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feed-forward-neural-networks-mlps">5.1.2. Feed-Forward Neural Networks (MLPs)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-and-notation">5.1.2.1. Architecture and Notation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">5.1.2.2. Activation Functions</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-function-and-matrix-based-back-propagation">5.1.3. Cost function and matrix-based Back-Propagation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squared-errors-sse">5.1.3.1. Sum of Squared Errors (SSE)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent-update">5.1.3.2. Gradient Descent Update</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#back-propagation-algorithm-2">5.1.3.3. Back-Propagation (Algorithm 2)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-networks-cnns">5.1.4. Convolutional Neural Networks (CNNs)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution-operation">5.1.4.1. Convolution Operation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling-layers">5.1.4.2. Pooling Layers</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-and-cross-validation">5.1.5. Overfitting and Cross-Validation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-phenomenon">5.1.5.1. Overfitting Phenomenon</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#detection-and-mitigation">5.1.5.2. Detection and Mitigation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-aspects-model-saving-and-loading-in-pytorch">5.1.6. Practical Aspects: Model Saving and Loading in PyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-example-of-a-cnn-for-regression">5.1.7. Complete example of a CNN for Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-pytorch-tensors">5.2. Introduction to PyTorch tensors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-tensors">5.2.1. Creating Tensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-tensor-operations">5.2.2. Basic Tensor Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#arithmetic-operations">5.2.2.1. Arithmetic operations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing-and-slicing">5.2.2.2. Indexing and slicing</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autograd-and-gradients">5.2.3. Autograd and Gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-tensor-functions">5.2.4. Advanced Tensor Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">5.2.4.1. Broadcasting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#device-management-cpu-vs-gpu">5.2.4.2. Device Management (CPU vs GPU)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#in-place-operations">5.2.4.3. In-place Operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">5.3. Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-symbolic-and-automatic-differentiation-in-a-simple-feedforward-neural-network">5.3.1. Comparison of symbolic and automatic differentiation in a simple feedforward neural network</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-setup">5.4. Problem setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-implementation">5.5. PyTorch implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-activation-function-and-its-derivative">5.5.1. Define the activation function and its derivative</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-working-variables">5.5.2. Define the working variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-pass">5.5.3. Forward pass</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#symbolic-gradients">5.5.4. Symbolic gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-differentiation">5.5.5. Automatic differentiation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-symbolic-and-automatic-differentiation">5.5.6. Comparison of symbolic and automatic differentiation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#facial-keypoints-detection-with-pytorch-fcn-and-cnn-architectures">5.5.7. Facial keypoints detection with PyTorch FCN and CNN architectures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-overview">5.5.8. Dataset overview</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-format">5.5.8.1. Data format</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#missing-values">5.5.8.2. Missing values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-exploration">5.6. Data exploration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">5.6.1. Missing Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-visualization">5.6.2. Sample visualization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">5.7. Data preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fully-connected-neural-network-fcn">5.8. Fully connected neural network (FCN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fcn-architecture">5.8.1. FCN architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#split-the-flattened-dataset-for-training-validation">5.8.2. Split the Flattened Dataset for Training/Validation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-pytorch-datasets-and-dataloaders">5.8.3. Create PyTorch Datasets and DataLoaders</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instantiate-the-fcn-model-define-criterion-and-the-optimizer">5.8.4. Instantiate the FCN Model, define criterion and the optimizer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-with-ongoing-evaluation-of-the-validation-error">5.8.5. Training with ongoing evaluation of the validation error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-on-validation-set">5.8.6. Evaluate on validation set</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-network">5.9. Convolutional neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">5.10. Training the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-and-results">5.11. Evaluation and results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-predictions">5.11.1. Visualizing predictions</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="neural-networks-for-regression">
<h1><span class="section-number">5. </span>Neural Networks for Regression<a class="headerlink" href="#neural-networks-for-regression" title="Link to this heading">#</a></h1>
<section id="introduction-to-neural-networks">
<h2><span class="section-number">5.1. </span>Introduction to Neural Networks<a class="headerlink" href="#introduction-to-neural-networks" title="Link to this heading">#</a></h2>
<p>This part of the introduction summarizes the key theoretical concepts for <strong>Neural Networks for Regression</strong>, building on Chapter 8 of the handbook (pp. 189–199).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!pip install torch torchsummary</span>
</pre></div>
</div>
</div>
</div>
<p>Let us define some basic imports and a <code class="docutils literal notranslate"><span class="pre">pprint</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpyarray_to_latex.jupyter</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_ltx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn-v0_8-muted&#39;</span><span class="p">,</span> <span class="s1">&#39;practicals.mplstyle&#39;</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">pprint</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">+=</span> <span class="n">to_ltx</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">brackets</span><span class="o">=</span><span class="s1">&#39;[]&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">+=</span> <span class="n">to_ltx</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">brackets</span><span class="o">=</span><span class="s1">&#39;[]&#39;</span><span class="p">,)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">+=</span> <span class="n">i</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Math</span><span class="p">(</span><span class="n">res</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<section id="data-preprocessing-for-neural-networks">
<h3><span class="section-number">5.1.1. </span>Data Preprocessing for Neural Networks<a class="headerlink" href="#data-preprocessing-for-neural-networks" title="Link to this heading">#</a></h3>
<section id="normalization-and-standardization">
<h4><span class="section-number">5.1.1.1. </span>Normalization and Standardization<a class="headerlink" href="#normalization-and-standardization" title="Link to this heading">#</a></h4>
<p><strong>Motivation</strong>:
Gradient-based optimization of neural networks often becomes unstable if different features vary widely in scale. Hence, <strong>Sec. 8.1</strong> of the handbook (and earlier practicals) reiterate that scaling inputs to zero mean and unit variance—or to a small bounded range—is essential. This ensures the gradients have more balanced magnitudes across parameters, which helps the optimizer converge more reliably.</p>
<p><strong>Typical Steps</strong>:</p>
<ol class="arabic simple">
<li><p>Compute the empirical mean and standard deviation of each input dimension:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\mu_j = \frac{1}{N} \sum_{i=1}^N x_{ij}, \quad
\sigma_j = \sqrt{\frac{1}{N}\sum_{i=1}^N (x_{ij}-\mu_j)^2}.
\]</div>
<ol class="arabic simple" start="2">
<li><p>Transform (standardise) the data as</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
x_{ij}^{(std)} = \frac{x_{ij} - \mu_j}{\sigma_j}.
\]</div>
<ol class="arabic simple" start="3">
<li><p>Use the same <span class="math notranslate nohighlight">\(\mu_j\)</span> and <span class="math notranslate nohighlight">\(\sigma_j\)</span> for the validation and test sets to maintain consistency.</p></li>
</ol>
</section>
<section id="input-data-shaping">
<h4><span class="section-number">5.1.1.2. </span>Input Data Shaping<a class="headerlink" href="#input-data-shaping" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>For MLPs</strong>: Usually arrange training data into a matrix of shape <span class="math notranslate nohighlight">\((\text{batch}, n)\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is the number of input features.</p></li>
<li><p><strong>For CNNs</strong>: Reshape data into a 4D tensor of shape <span class="math notranslate nohighlight">\((\text{batch}, \text{channels}, \text{height}, \text{width})\)</span>. Convolutional layers exploit the spatial dimensions for images or other grid-like inputs.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Suppose X_train is shape (N, n) for an MLP:</span>
<span class="n">N</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">std</span>  <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
<span class="n">X_val</span>   <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
<span class="n">X_test</span>  <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>

<span class="c1"># For CNN input, if needed:</span>
<span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span>  <span class="c1"># e.g., image dimension</span>
<span class="c1"># Reshape to (N, 1, H, W) for single-channel images:</span>
<span class="n">X_train_cnn</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="n">X_val_cnn</span>   <span class="o">=</span> <span class="n">X_val</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="n">X_test_cnn</span>  <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="feed-forward-neural-networks-mlps">
<h3><span class="section-number">5.1.2. </span>Feed-Forward Neural Networks (MLPs)<a class="headerlink" href="#feed-forward-neural-networks-mlps" title="Link to this heading">#</a></h3>
<section id="architecture-and-notation">
<h4><span class="section-number">5.1.2.1. </span>Architecture and Notation<a class="headerlink" href="#architecture-and-notation" title="Link to this heading">#</a></h4>
<p>An MLP (multi-layer perceptron, or feed-forward network) with <span class="math notranslate nohighlight">\(L\)</span> layers (including hidden and output layers) maps an input vector <span class="math notranslate nohighlight">\(\mathbf{x}\in\mathbb{R}^n\)</span> to an output (for regression, typically <span class="math notranslate nohighlight">\(\hat{y}\in\mathbb{R}\)</span> or <span class="math notranslate nohighlight">\(\mathbb{R}^m\)</span>) through successive affine transformations and nonlinear activations. In the notation of <strong>Eqs. <span class="math notranslate nohighlight">\((8.1.2)\)</span>–<span class="math notranslate nohighlight">\((8.1.5)\)</span></strong>:</p>
<ol class="arabic simple">
<li><p><strong>Layer 1</strong>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
A^{(1)} = Z^{(0)} W^{(1)} + b^{(1)},\quad Z^{(1)} = g^{(1)}(A^{(1)}),
\]</div>
<p>where <span class="math notranslate nohighlight">\(Z^{(0)} = \mathbf{x}\)</span> is the input and <span class="math notranslate nohighlight">\(W^{(1)}\)</span> is an <span class="math notranslate nohighlight">\((n \times h_1)\)</span> weight matrix if the first hidden layer has <span class="math notranslate nohighlight">\(h_1\)</span> units.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Layer 2</strong> (or subsequent hidden layers):</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
A^{(2)} = Z^{(1)} W^{(2)} + b^{(2)},\quad Z^{(2)} = g^{(2)}(A^{(2)}),
\]</div>
<p>continuing similarly up to layer <span class="math notranslate nohighlight">\(L-1\)</span>.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Output Layer</strong> (<span class="math notranslate nohighlight">\(l=L\)</span>):
For regression with a linear output,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
A^{(L)} = Z^{(L-1)} W^{(L)} + b^{(L)},\quad Z^{(L)} = A^{(L)}.
\]</div>
<p>If the output dimension is 1, <span class="math notranslate nohighlight">\(W^{(L)}\)</span> is <span class="math notranslate nohighlight">\((h_{L-1} \times 1)\)</span>. For vector outputs, adjust accordingly.</p>
</section>
<section id="activation-functions">
<h4><span class="section-number">5.1.2.2. </span>Activation Functions<a class="headerlink" href="#activation-functions" title="Link to this heading">#</a></h4>
<p>Nonlinearities <span class="math notranslate nohighlight">\(g^{(l)}(\cdot)\)</span> are critical. Common examples in the course:</p>
<ul class="simple">
<li><p><strong>Sigmoid</strong>: <span class="math notranslate nohighlight">\(\sigma(z)=1/(1+e^{-z})\)</span>, which saturates for large <span class="math notranslate nohighlight">\(|z|\)</span>.</p></li>
<li><p><strong>Tanh</strong>: <span class="math notranslate nohighlight">\(\tanh(z)\in(-1,1)\)</span>, similar saturation behavior.</p></li>
<li><p><strong>ReLU</strong>: <span class="math notranslate nohighlight">\(\max(0,z)\)</span>, which alleviates vanishing gradients on the positive side and is widely used in deep networks.</p></li>
</ul>
<p>Without a nonlinear <span class="math notranslate nohighlight">\(g^{(l)}\)</span>, the stacked linear transformations collapse to an effective single linear mapping. Nonlinearity ensures the network can approximate complex functions (Universal Approximation property).</p>
</section>
</section>
<section id="cost-function-and-matrix-based-back-propagation">
<h3><span class="section-number">5.1.3. </span>Cost function and matrix-based Back-Propagation<a class="headerlink" href="#cost-function-and-matrix-based-back-propagation" title="Link to this heading">#</a></h3>
<section id="sum-of-squared-errors-sse">
<h4><span class="section-number">5.1.3.1. </span>Sum of Squared Errors (SSE)<a class="headerlink" href="#sum-of-squared-errors-sse" title="Link to this heading">#</a></h4>
<p>For regression tasks, the <em>empirical sum of squared errors</em>:</p>
<div class="math notranslate nohighlight">
\[
\mathrm{SSE}_{\mathrm{emp}}(\alpha_N) = \sum_{i=1}^N (y_i - \hat{y}(x_i))^2,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{y}(x_i)\)</span> is the network’s prediction for input <span class="math notranslate nohighlight">\(x_i\)</span>, and <span class="math notranslate nohighlight">\(y_i\)</span> is the true target. The parameter vector <span class="math notranslate nohighlight">\(\alpha_N\)</span> includes <span class="math notranslate nohighlight">\(\{W^{(l)}, b^{(l)}\}\)</span> for <span class="math notranslate nohighlight">\(l=1,\ldots,L\)</span>.</p>
</section>
<section id="gradient-descent-update">
<h4><span class="section-number">5.1.3.2. </span>Gradient Descent Update<a class="headerlink" href="#gradient-descent-update" title="Link to this heading">#</a></h4>
<p>Using the notation from <strong>Algorithm 2 (p. 194)</strong>, we iteratively update each parameter in the direction that reduces the SSE cost:</p>
<div class="math notranslate nohighlight">
\[
\alpha_N(k+1) = \alpha_N(k) - \eta\, \frac{\partial\,\mathrm{SSE}_{\mathrm{emp}}}{\partial\,\alpha_N}(k),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\eta\)</span> is the learning rate.</p>
</section>
<section id="back-propagation-algorithm-2">
<h4><span class="section-number">5.1.3.3. </span>Back-Propagation (Algorithm 2)<a class="headerlink" href="#back-propagation-algorithm-2" title="Link to this heading">#</a></h4>
<p>Back-propagation is the application of the chain rule to compute <span class="math notranslate nohighlight">\(\nabla \mathrm{SSE}_{\mathrm{emp}}\)</span> with respect to each weight matrix <span class="math notranslate nohighlight">\(W^{(l)}\)</span> and bias <span class="math notranslate nohighlight">\(b^{(l)}\)</span>.</p>
<ol class="arabic simple">
<li><p><strong>Output-Layer Delta</strong>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\delta^{(L)} = \frac{\partial\,\mathrm{SSE}_{\mathrm{emp}}}{\partial\,A^{(L)}} \odot g'^{(L)}(A^{(L)}).
\]</div>
<ul class="simple">
<li><p>In linear output regression, <span class="math notranslate nohighlight">\(g'^{(L)}(\cdot) = 1\)</span>, and the cost derivative is <span class="math notranslate nohighlight">\(\delta^{(L)} = (\hat{y}-y).\)</span></p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Backward Recursion</strong>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\delta^{(l)} = \bigl(W^{(l+1)} \delta^{(l+1)}\bigr) \odot g'^{(l)}(A^{(l)}), \quad l = L-1,\ldots,1.
\]</div>
<p>This “error” <span class="math notranslate nohighlight">\(\delta^{(l)}\)</span> is used to compute partial derivatives for <span class="math notranslate nohighlight">\(W^{(l)}\)</span> and <span class="math notranslate nohighlight">\(b^{(l)}\)</span>.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Gradient w.r.t. the weights</strong>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\frac{\partial\,\mathrm{SSE}_{\mathrm{emp}}}{\partial\,W^{(l)}} = (Z^{(l-1)})^\top \,\delta^{(l)},\quad
\frac{\partial\,\mathrm{SSE}_{\mathrm{emp}}}{\partial\,b^{(l)}} = \sum_{i=1}^{N} \delta^{(l)}_i.
\]</div>
<p>using the matrix-based form.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Simple2LayerMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ReLU activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># linear output for regression</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Instantiate the network and define SSE-like loss</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Simple2LayerMLP</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>  <span class="c1"># SSE (sum of squared errors)</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mf">1e-2</span>

<span class="c1"># Dummy data</span>
<span class="n">X_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_sample</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">)</span>

<span class="c1"># Backpropagate</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># Gradient descent step</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span> <span class="o">-=</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span>
        <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="convolutional-neural-networks-cnns">
<h3><span class="section-number">5.1.4. </span>Convolutional Neural Networks (CNNs)<a class="headerlink" href="#convolutional-neural-networks-cnns" title="Link to this heading">#</a></h3>
<p>Though the practical focuses on regression, CNNs (p. 198–199) illustrate deep architectures that handle grid-structured data (e.g., images). Main ideas:</p>
<ol class="arabic simple">
<li><p><strong>Local Connectivity</strong>: Each neuron in a convolutional layer only connects to a local patch of the input.</p></li>
<li><p><strong>Shared Weights</strong>: A small kernel (filter) is “convolved” across the entire image or feature map.</p></li>
<li><p><strong>Translation Equivariance</strong>: The same filter is applied at all spatial locations.</p></li>
</ol>
<section id="convolution-operation">
<h4><span class="section-number">5.1.4.1. </span>Convolution Operation<a class="headerlink" href="#convolution-operation" title="Link to this heading">#</a></h4>
<p>A single 2D filter:</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \sum_{m=1}^{k_h} \sum_{n=1}^{k_w} W_{mn} x_{(i + m - 1, j + n - 1)} + b,
\]</div>
<p>where <span class="math notranslate nohighlight">\((k_h, k_w)\)</span> is the kernel size. ReLU or another activation is then applied.</p>
</section>
<section id="pooling-layers">
<h4><span class="section-number">5.1.4.2. </span>Pooling Layers<a class="headerlink" href="#pooling-layers" title="Link to this heading">#</a></h4>
<p>Often, a <strong>pooling</strong> layer follows one or more convolutional layers to reduce the spatial resolution. For instance, <strong>max pooling</strong> with a <span class="math notranslate nohighlight">\(2\times2\)</span> window and stride 2 halves the height and width.</p>
</section>
</section>
<section id="overfitting-and-cross-validation">
<h3><span class="section-number">5.1.5. </span>Overfitting and Cross-Validation<a class="headerlink" href="#overfitting-and-cross-validation" title="Link to this heading">#</a></h3>
<section id="overfitting-phenomenon">
<h4><span class="section-number">5.1.5.1. </span>Overfitting Phenomenon<a class="headerlink" href="#overfitting-phenomenon" title="Link to this heading">#</a></h4>
<p>In the handbook’s example on <strong>p. 197</strong>, a network with 15 hidden units achieves extremely low training SSE but high test SSE, illustrating <strong>overfitting</strong>. Overfitting arises when a model fits training data “too well,” capturing noise rather than the underlying trend.</p>
</section>
<section id="detection-and-mitigation">
<h4><span class="section-number">5.1.5.2. </span>Detection and Mitigation<a class="headerlink" href="#detection-and-mitigation" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Validation Set</strong>: Split data into training and validation. Monitor the validation error (e.g., MSE). If it increases while training error decreases, the model is overfitting.</p></li>
<li><p><strong>Cross-Validation</strong>: Alternatively, use <span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation.</p></li>
<li><p><strong>Regularization</strong>:</p>
<ul>
<li><p><strong>Dropout</strong>: Temporarily “drop” a fraction of hidden units during training.</p></li>
<li><p><strong>Weight Decay (L2)</strong>: Penalizes large weights.</p></li>
<li><p><strong>Early Stopping</strong>: Halt training when validation performance stops improving.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="practical-aspects-model-saving-and-loading-in-pytorch">
<h3><span class="section-number">5.1.6. </span>Practical Aspects: Model Saving and Loading in PyTorch<a class="headerlink" href="#practical-aspects-model-saving-and-loading-in-pytorch" title="Link to this heading">#</a></h3>
<p>For safe and reproducible experiments, one typically needs to <strong>save</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Model Weights (state_dict)</strong>: The learned parameters <span class="math notranslate nohighlight">\(\{W^{(l)},b^{(l)}\}\)</span>.</p></li>
<li><p><strong>Optimizer State (if resuming)</strong>: Internal states like momentum buffers in gradient-based optimizers.</p></li>
</ol>
<p>A typical code pattern:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Simple2LayerMLP</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Training... then save checkpoint</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
    <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="mi">10</span>
<span class="p">},</span> <span class="s2">&quot;checkpoint.pth&quot;</span><span class="p">)</span>

<span class="c1"># Later, to resume</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;checkpoint.pth&quot;</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
<span class="n">start_epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c1"># For inference, only model_state_dict is strictly required.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="complete-example-of-a-cnn-for-regression">
<h3><span class="section-number">5.1.7. </span>Complete example of a CNN for Regression<a class="headerlink" href="#complete-example-of-a-cnn-for-regression" title="Link to this heading">#</a></h3>
<p>Below is a more detailed illustration of an implementation of a CNN in PyTorch for regression highlighting many of the points presented above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="c1"># This CNN will perform a regression task (e.g., predicting a real-valued output from an image).</span>
<span class="c1"># We&#39;ll use two convolution layers (with 2x2 max pooling after each), then two fully-connected layers,</span>
<span class="c1"># include dropout with probability=0.25, and weight decay in the optimizer for regularization.</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SimpleCNNRegression</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># First convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Second convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># After two 2x2 pools on a 28x28 input, the spatial dimension goes 28-&gt;14-&gt;7</span>
        <span class="c1"># =&gt; final feature map is 16 x 7 x 7 = 16*7*7 = 784</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>          <span class="c1"># single output for regression</span>
        
        <span class="c1"># Dropout layer to help regularize the fully connected part</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
        
        <span class="c1"># MaxPool layer (2x2) used after each convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># First conv: conv1 -&gt; ReLU -&gt; pool =&gt; shape: (N, 8, 14, 14)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>        
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Second conv: conv2 -&gt; ReLU -&gt; pool =&gt; shape: (N, 16, 7, 7)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>        
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Flatten =&gt; shape: (N, 16*7*7 = 784)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># First fully connected =&gt; ReLU =&gt; Dropout =&gt; shape: (N, 64)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Final fully connected =&gt; shape: (N, 1)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># We&#39;ll create some dummy data for regression:</span>
<span class="c1"># - Shape of X: (N, 1, 28, 28)</span>
<span class="c1"># - Shape of y: (N, 1) containing continuous values</span>
<span class="n">N_train</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">N_val</span>   <span class="o">=</span> <span class="mi">200</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># random continuous targets</span>
<span class="n">X_val</span>   <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N_val</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">y_val</span>   <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N_val</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># We&#39;ll wrap the data in TensorDatasets and DataLoaders for batching</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">val_dataset</span>   <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="n">batch_size</span>    <span class="o">=</span> <span class="mi">50</span>
<span class="n">train_loader</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span>    <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span>   <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Instantiate our CNN model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleCNNRegression</span><span class="p">()</span>

<span class="c1"># We&#39;ll use MSELoss for this regression task</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># We&#39;ll use Adam optimizer with weight decay for L2 regularization</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="c1"># Setup for training with early stopping</span>
<span class="n">max_epochs</span>         <span class="o">=</span> <span class="mi">20</span>
<span class="n">patience</span>           <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of epochs with no improvement allowed</span>
<span class="n">best_val_loss</span>      <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="n">epochs_no_improve</span>  <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_model_path</span>    <span class="o">=</span> <span class="s2">&quot;best_model.pth&quot;</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>
    <span class="c1"># Train mode: enables dropout, etc.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">running_train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="c1"># Fetch mini-batches from the training loader</span>
    <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># Zero the parameter gradients</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="c1"># Forward pass -&gt; compute predictions</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
        
        <span class="c1"># Compute MSE loss for regression</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        
        <span class="c1"># Backward pass -&gt; compute gradients</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        
        <span class="c1"># Update parameters</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">running_train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="c1"># Compute average training loss for this epoch</span>
    <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">running_train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    
    <span class="c1"># Validation phase (disable dropout, etc.)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">running_val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">Xv_batch</span><span class="p">,</span> <span class="n">yv_batch</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="c1"># Forward pass on validation set</span>
            <span class="n">val_preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">Xv_batch</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">val_preds</span><span class="p">,</span> <span class="n">yv_batch</span><span class="p">)</span>
            <span class="n">running_val_loss</span> <span class="o">+=</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="n">running_val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">max_epochs</span><span class="si">}</span><span class="s2">]  &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Train MSE: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Val MSE: </span><span class="si">{</span><span class="n">avg_val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Early stopping check</span>
    <span class="k">if</span> <span class="n">avg_val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
        <span class="c1"># If validation improves, update best_val_loss and reset patience counter</span>
        <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">avg_val_loss</span>
        <span class="n">epochs_no_improve</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Save current model as best</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">best_model_path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Best model saved (improved validation MSE).&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">epochs_no_improve</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># If no improvement for &#39;patience&#39; epochs, stop</span>
        <span class="k">if</span> <span class="n">epochs_no_improve</span> <span class="o">&gt;=</span> <span class="n">patience</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Early stopping triggered (no improvement).&quot;</span><span class="p">)</span>
            <span class="k">break</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training complete. Loading best model for final checks.&quot;</span><span class="p">)</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">SimpleCNNRegression</span><span class="p">()</span>
<span class="n">best_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">best_model_path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">best_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># We can now evaluate &#39;best_model&#39; on the validation set (or test set if we had one).</span>
<span class="c1"># For instance, a quick check of final validation MSE:</span>
<span class="n">final_val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">Xv_batch</span><span class="p">,</span> <span class="n">yv_batch</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
        <span class="n">val_preds</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">(</span><span class="n">Xv_batch</span><span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">val_preds</span><span class="p">,</span> <span class="n">yv_batch</span><span class="p">)</span>
        <span class="n">final_val_loss</span> <span class="o">+=</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final validation MSE (best model): </span><span class="si">{</span><span class="n">final_val_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/20]  Train MSE: 1.0066  Val MSE: 1.1227
  Best model saved (improved validation MSE).
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [2/20]  Train MSE: 0.9895  Val MSE: 1.1129
  Best model saved (improved validation MSE).
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [3/20]  Train MSE: 0.9733  Val MSE: 1.1080
  Best model saved (improved validation MSE).
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [4/20]  Train MSE: 0.9498  Val MSE: 1.1050
  Best model saved (improved validation MSE).
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [5/20]  Train MSE: 0.8996  Val MSE: 1.1333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [6/20]  Train MSE: 0.8473  Val MSE: 1.1637
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [7/20]  Train MSE: 0.7622  Val MSE: 1.1757
Early stopping triggered (no improvement).

Training complete. Loading best model for final checks.
Final validation MSE (best model): 1.1050
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="introduction-to-pytorch-tensors">
<h2><span class="section-number">5.2. </span>Introduction to PyTorch tensors<a class="headerlink" href="#introduction-to-pytorch-tensors" title="Link to this heading">#</a></h2>
<p>PyTorch is a popular open-source deep learning framework, and <strong>tensors</strong> are its core data structure. In PyTorch, tensors are the central data abstraction – a specialized data structure very similar to arrays or matrices, used to represent data (inputs, outputs, model parameters) in deep learning models. Tensors are conceptually like NumPy’s multi-dimensional arrays, but with two key advantages: they can run on GPUs (for accelerated computing), and they support automatic differentiation (through PyTorch’s autograd engine) for computing gradients. These features make tensors fundamental for building and training neural networks.</p>
<p>In this introduction, we’ll explore PyTorch tensors from the ground up. We assume you are comfortable with Python and NumPy, but completely new to PyTorch. We’ll cover what tensors are and how they compare to NumPy arrays, how to create and manipulate them, basic operations, how PyTorch’s autograd works for automatic differentiation, and some additional important tensor functionalities like broadcasting, using GPUs, and in-place operations. Along the way, you’ll find hands-on code examples you can run and modify to solidify your understanding.</p>
<p>Let’s get started by importing PyTorch (the <code class="docutils literal notranslate"><span class="pre">torch</span></code> library) and seeing how to create tensors in various ways.</p>
<p>PyTorch (<code class="docutils literal notranslate"><span class="pre">torch</span></code>) provides the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> class, which, as mentioned, is similar to NumPy’s <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>s but with GPU support and gradient computation. If you’re familiar with NumPy arrays, you’ll find the tensor API quite intuitive. In fact, many operations (creation, indexing, math, etc.) have a very similar syntax.</p>
<p>One important difference is that PyTorch operations can be automatically differentiated (if required), which is essential for tasks like training neural networks.</p>
<section id="creating-tensors">
<h3><span class="section-number">5.2.1. </span>Creating Tensors<a class="headerlink" href="#creating-tensors" title="Link to this heading">#</a></h3>
<p>There are many ways to create a tensor in PyTorch. Here are some of the most common methods:</p>
<ol class="arabic simple">
<li><p><strong>From Python data</strong>: You can create a tensor directly from a Python list or sequence of numbers using <code class="docutils literal notranslate"><span class="pre">torch.tensor()</span></code>. PyTorch will automatically infer the data type (dtype) if not specified.</p></li>
<li><p><strong>From a NumPy array</strong>: PyTorch can convert NumPy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>s into tensors with <code class="docutils literal notranslate"><span class="pre">torch.from_numpy()</span></code>, and vice versa using the Tensor’s <code class="docutils literal notranslate"><span class="pre">.numpy()</span></code> method. This makes it easy to move data between NumPy and PyTorch. (Notably, if the NumPy array is on CPU, the tensor and the array will share the same memory buffer, so changing one will also change the other.)</p></li>
<li><p><strong>Using factory functions</strong>: PyTorch provides factory methods to create tensors with specific values or distributions. For example, <code class="docutils literal notranslate"><span class="pre">torch.zeros(shape)</span></code> creates a tensor filled with zeros, <code class="docutils literal notranslate"><span class="pre">torch.ones(shape)</span></code> creates one filled with ones, and <code class="docutils literal notranslate"><span class="pre">torch.rand(shape)</span></code> creates one with random values uniformly sampled between 0 and 1. You can also create tensors based on an existing tensor’s properties with functions like <code class="docutils literal notranslate"><span class="pre">torch.ones_like(existing_tensor)</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.rand_like(existing_tensor)</span></code>.</p></li>
<li><p><strong>Uninitialized tensors</strong>: If you need an uninitialized tensor (just allocating memory without setting values), you can use <code class="docutils literal notranslate"><span class="pre">torch.empty(shape)</span></code>.</p></li>
<li><p><strong>Specifying data types and devices</strong>: All the above functions accept a <code class="docutils literal notranslate"><span class="pre">dtype</span></code> parameter to specify the tensor’s data type (e.g. <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.int64</span></code>, etc.), and a <code class="docutils literal notranslate"><span class="pre">device</span></code> parameter to specify whether the tensor should reside on the CPU or GPU. By default, PyTorch tensors are created with <code class="docutils literal notranslate"><span class="pre">dtype=torch.float32</span></code> (for floating point numbers) and on the CPU.</p></li>
</ol>
<p>Let’s go through some examples of creating tensors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating a tensor from a Python list</span>
<span class="n">data_list</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data_list</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Tensor from list:}&quot;</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>

<span class="c1"># Creating a tensor from a NumPy array</span>
<span class="n">np_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_list</span><span class="p">)</span>
<span class="n">x_np</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Tensor from NumPy array:}&quot;</span><span class="p">,</span> <span class="n">x_np</span><span class="p">)</span>

<span class="c1"># Verify that modifying the NumPy array changes the tensor (shared memory)</span>
<span class="n">np_array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">99</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{After modifying the NumPy array, the Tensor becomes:}&quot;</span><span class="p">,</span> <span class="n">x_np</span><span class="p">)</span>

<span class="c1"># Creating tensors using factory functions</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">x_ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">x_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Zero Tensor:}&quot;</span><span class="p">,</span> <span class="n">x_zeros</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Ones Tensor:}&quot;</span><span class="p">,</span> <span class="n">x_ones</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Random Tensor:}&quot;</span><span class="p">,</span> <span class="n">x_rand</span><span class="p">)</span>

<span class="c1"># Creating tensors based on existing ones</span>
<span class="n">x_like</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x_rand</span><span class="p">)</span>        <span class="c1"># tensor of ones with same shape as x_rand</span>
<span class="n">x_like_float</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># random tensor with same shape as x_data, but forced float type</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Ones-like Tensor:}&quot;</span><span class="p">,</span> <span class="n">x_like</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Rand-like Tensor with float32 dtype:}&quot;</span><span class="p">,</span> <span class="n">x_like_float</span><span class="p">)</span>

<span class="c1"># Checking tensor attributes</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor shape:&quot;</span><span class="p">,</span> <span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor data type:&quot;</span><span class="p">,</span> <span class="n">x_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor device:&quot;</span><span class="p">,</span> <span class="n">x_data</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Tensor from list:}\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Tensor from NumPy array:}\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{After modifying the NumPy array, the Tensor becomes:}\left[
\begin{array}{}
  99.0000 &amp;  2.0000 &amp;  3.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Zero Tensor:}\left[
\begin{array}{}
  0.0000 &amp;  0.0000 &amp;  0.0000\\
  0.0000 &amp;  0.0000 &amp;  0.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Ones Tensor:}\left[
\begin{array}{}
  1.0000 &amp;  1.0000 &amp;  1.0000\\
  1.0000 &amp;  1.0000 &amp;  1.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Random Tensor:}\left[
\begin{array}{}
  0.6857 &amp;  0.1305 &amp;  0.4428\\
  0.8011 &amp;  0.4786 &amp;  0.2500
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Ones-like Tensor:}\left[
\begin{array}{}
  1.0000 &amp;  1.0000 &amp;  1.0000\\
  1.0000 &amp;  1.0000 &amp;  1.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Rand-like Tensor with float32 dtype:}\left[
\begin{array}{}
  0.9903 &amp;  0.8234 &amp;  0.7674\\
  0.6472 &amp;  0.9804 &amp;  0.3621
\end{array}
\right]\end{split}\]</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tensor shape: torch.Size([2, 3])
Tensor data type: torch.int64
Tensor device: cpu
</pre></div>
</div>
</div>
</div>
</section>
<section id="basic-tensor-operations">
<h3><span class="section-number">5.2.2. </span>Basic Tensor Operations<a class="headerlink" href="#basic-tensor-operations" title="Link to this heading">#</a></h3>
<p>Once you have tensors, PyTorch provides a rich set of operations to manipulate them. In fact, there are over 100 tensor operations available, including arithmetic, linear algebra, slicing, reshaping, and more. Many of these mirror NumPy operations in syntax and function. Let’s go through some fundamental operations.</p>
<section id="arithmetic-operations">
<h4><span class="section-number">5.2.2.1. </span>Arithmetic operations<a class="headerlink" href="#arithmetic-operations" title="Link to this heading">#</a></h4>
<p>Arithmetic on tensors is typically element-wise (just like with NumPy arrays). You can use Python arithmetic operators (<code class="docutils literal notranslate"><span class="pre">+</span></code>, <code class="docutils literal notranslate"><span class="pre">-</span></code>, <code class="docutils literal notranslate"><span class="pre">*</span></code>, <code class="docutils literal notranslate"><span class="pre">/</span></code>) or the equivalent <code class="docutils literal notranslate"><span class="pre">torch</span></code> functions (<code class="docutils literal notranslate"><span class="pre">torch.add</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.sub</span></code>, etc.). For example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Element-wise arithmetic operations</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">])</span>

<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;a=&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;b=&quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;a + b =&quot;</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>        <span class="c1"># element-wise addition</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;a </span><span class="se">\\</span><span class="s2">times b =&quot;</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">)</span>        <span class="c1"># element-wise multiplication</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;a - b =&quot;</span><span class="p">,</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>        <span class="c1"># element-wise subtraction</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">frac</span><span class="si">{a}{b}</span><span class="s2"> =&quot;</span><span class="p">,</span> <span class="n">a</span> <span class="o">/</span> <span class="n">b</span><span class="p">)</span>        <span class="c1"># element-wise division</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle a=\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle b=\left[
\begin{array}{}
  4.0000 &amp;  5.0000 &amp;  6.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle a + b =\left[
\begin{array}{}
  5.0000 &amp;  7.0000 &amp;  9.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle a \times b =\left[
\begin{array}{}
  4.0000 &amp;  10.0000 &amp;  18.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle a - b =\left[
\begin{array}{}
 -3.0000 &amp; -3.0000 &amp; -3.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \frac{a}{b} =\left[
\begin{array}{}
  0.2500 &amp;  0.4000 &amp;  0.5000
\end{array}
\right]\]</div>
</div>
</div>
<p>The results should be as expected:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">+</span> <span class="pre">b</span></code> gives <code class="docutils literal notranslate"><span class="pre">[5.0,</span> <span class="pre">7.0,</span> <span class="pre">9.0]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">*</span> <span class="pre">b</span></code> gives <code class="docutils literal notranslate"><span class="pre">[4.0,</span> <span class="pre">10.0,</span> <span class="pre">18.0]</span></code></p></li>
<li><p>etc.</p></li>
</ul>
<p>If you want to do <strong>matrix multiplication</strong> (dot products, etc.), you should use the <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> operator or <code class="docutils literal notranslate"><span class="pre">torch.matmul</span></code>. For example, <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">B</span></code> does matrix multiply if <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are 2-D matrices (or higher-dim, following broadcast batch rules). For 1-D vectors, <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&#64;</span> <span class="pre">b</span></code> will give a scalar dot product. Let’s see a quick example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matrix multiplication vs elementwise</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;A=&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;B=&quot;</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Element-wise multiply:}&quot;</span><span class="p">,</span> <span class="n">A</span> <span class="o">*</span> <span class="n">B</span><span class="p">)</span>   <span class="c1"># same shape -&gt; elementwise product</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Matrix multiply:}&quot;</span><span class="p">,</span> <span class="n">A</span> <span class="o">@</span> <span class="n">B</span><span class="p">)</span>         <span class="c1"># 2x2 @ 2x2 -&gt; 2x2 matrix result</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle A=\left[
\begin{array}{}
  1.0000 &amp;  2.0000\\
  3.0000 &amp;  4.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle B=\left[
\begin{array}{}
  5.0000 &amp;  6.0000\\
  7.0000 &amp;  8.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Element-wise multiply:}\left[
\begin{array}{}
  5.0000 &amp;  12.0000\\
  21.0000 &amp;  32.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Matrix multiply:}\left[
\begin{array}{}
  19.0000 &amp;  22.0000\\
  43.0000 &amp;  50.0000
\end{array}
\right]\end{split}\]</div>
</div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">*</span> <span class="pre">B</span></code> will do element-wise multiplication (resulting in <span class="math notranslate nohighlight">\(\begin{bmatrix}5&amp;12\\21&amp;32\end{bmatrix}\)</span>), whereas <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">B</span></code> will compute the matrix product (result <span class="math notranslate nohighlight">\(\begin{bmatrix}19&amp;22\\43&amp;50\end{bmatrix}\)</span>).</p>
</section>
<section id="indexing-and-slicing">
<h4><span class="section-number">5.2.2.2. </span>Indexing and slicing<a class="headerlink" href="#indexing-and-slicing" title="Link to this heading">#</a></h4>
<p>You can access and modify parts of tensors using indexing and slicing, just like with NumPy. PyTorch uses 0-based indexing. You can use indices, ranges, colons, and even Boolean masks or index tensors (though advanced indexing is outside our scope here). Some examples:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a 2-D tensor (matrix) for demonstration</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">]])</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Original tensor: }&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># Indexing a single element</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Element at (0, 1): }&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>   <span class="c1"># .item() to get Python scalar</span>

<span class="c1"># Slicing rows and columns</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{First row: }&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>            <span class="c1"># equivalent to x[0, :]</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Last column: }&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>       <span class="c1"># all rows, last column</span>

<span class="c1"># Slice a submatrix (e.g., top-left 2x2 block)</span>
<span class="n">sub_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>   <span class="c1"># rows 0-1 and cols 0-1</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Top-left 2x2 sub-tensor: }&quot;</span><span class="p">,</span> <span class="n">sub_x</span><span class="p">)</span>

<span class="c1"># Modify part of the tensor</span>
<span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span>
                          <span class="p">[</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">]])</span>   <span class="c1"># set bottom-right 2x2 block to new values</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Tensor after modification: }&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Original tensor: }\left[
\begin{array}{}
  10.0000 &amp;  11.0000 &amp;  12.0000\\
  20.0000 &amp;  21.0000 &amp;  22.0000\\
  30.0000 &amp;  31.0000 &amp;  32.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{Element at (0, 1): }11\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{First row: }\left[
\begin{array}{}
  10.0000 &amp;  11.0000 &amp;  12.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{Last column: }\left[
\begin{array}{}
  12.0000 &amp;  22.0000 &amp;  32.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Top-left 2x2 sub-tensor: }\left[
\begin{array}{}
  10.0000 &amp;  11.0000\\
  20.0000 &amp;  21.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{Tensor after modification: }\left[
\begin{array}{}
  10.0000 &amp;  11.0000 &amp;  12.0000\\
  20.0000 &amp; -1.0000 &amp; -2.0000\\
  30.0000 &amp; -3.0000 &amp; -4.0000
\end{array}
\right]\end{split}\]</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reshape (view) a tensor</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>        <span class="c1"># 1-D tensor [0, 1, 2, ..., 15]</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;t=&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

<span class="n">t_matrix</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>  <span class="c1"># reshape to 4x4 matrix</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{t reshaped to 4x4: }&quot;</span><span class="p">,</span> <span class="n">t_matrix</span><span class="p">)</span>

<span class="c1"># Transpose the matrix (swap dimensions)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;t^T:\ &quot;</span><span class="p">,</span> <span class="n">t_matrix</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle t=\left[
\begin{array}{}
  0.0000 &amp;  1.0000 &amp;  2.0000 &amp;  3.0000 &amp;  4.0000 &amp;  5.0000 &amp;  6.0000 &amp;  7.0000 &amp;  8.0000 &amp;  9.0000 &amp;  10.0000 &amp;  11.0000 &amp;  12.0000 &amp;  13.0000 &amp;  14.0000 &amp;  15.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle \text{t reshaped to 4x4: }\left[
\begin{array}{}
  0.0000 &amp;  1.0000 &amp;  2.0000 &amp;  3.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000 &amp;  7.0000\\
  8.0000 &amp;  9.0000 &amp;  10.0000 &amp;  11.0000\\
  12.0000 &amp;  13.0000 &amp;  14.0000 &amp;  15.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle t^T:\ \left[
\begin{array}{}
  0.0000 &amp;  4.0000 &amp;  8.0000 &amp;  12.0000\\
  1.0000 &amp;  5.0000 &amp;  9.0000 &amp;  13.0000\\
  2.0000 &amp;  6.0000 &amp;  10.0000 &amp;  14.0000\\
  3.0000 &amp;  7.0000 &amp;  11.0000 &amp;  15.0000
\end{array}
\right]\end{split}\]</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Concatenate two tensors</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                   <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                   <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
<span class="n">t_cat0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># concatenate along rows (dim=0)</span>
<span class="n">t_cat1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># concatenate along columns (dim=1)</span>

<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;t_1=&quot;</span><span class="p">,</span> <span class="n">t1</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;t_2:=&quot;</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;t_1</span><span class="se">\\</span><span class="s2">text{ and }t_2</span><span class="se">\\</span><span class="s2">text{  concatenated along dim=0: }&quot;</span><span class="p">,</span> <span class="n">t_cat0</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;t_1</span><span class="se">\\</span><span class="s2">text{  and }t_2</span><span class="se">\\</span><span class="s2">text{  concatenated along dim=1: }&quot;</span><span class="p">,</span> <span class="n">t_cat1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle t_1=\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle t_2:=\left[
\begin{array}{}
  7.0000 &amp;  8.0000 &amp;  9.0000\\
  10.0000 &amp;  11.0000 &amp;  12.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle t_1\text{ and }t_2\text{  concatenated along dim=0: }\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000\\
  7.0000 &amp;  8.0000 &amp;  9.0000\\
  10.0000 &amp;  11.0000 &amp;  12.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle t_1\text{  and }t_2\text{  concatenated along dim=1: }\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000 &amp;  7.0000 &amp;  8.0000 &amp;  9.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000 &amp;  10.0000 &amp;  11.0000 &amp;  12.0000
\end{array}
\right]\end{split}\]</div>
</div>
</div>
<p>Here:</p>
<ul class="simple">
<li><p>We created a 1-D tensor <code class="docutils literal notranslate"><span class="pre">t</span></code> with 16 sequential elements. We reshaped it into a 4×4 tensor <code class="docutils literal notranslate"><span class="pre">t_matrix</span></code>.</p></li>
<li><p>We transposed <code class="docutils literal notranslate"><span class="pre">t_matrix</span></code> with <code class="docutils literal notranslate"><span class="pre">.T</span></code>.</p></li>
<li><p>We took two 2×3 tensors <code class="docutils literal notranslate"><span class="pre">t1</span></code> and <code class="docutils literal notranslate"><span class="pre">t2</span></code> and concatenated them. Along <code class="docutils literal notranslate"><span class="pre">dim=0</span></code> (rows), we got a 4×3 tensor by stacking <code class="docutils literal notranslate"><span class="pre">t2</span></code> below <code class="docutils literal notranslate"><span class="pre">t1</span></code>. Along <code class="docutils literal notranslate"><span class="pre">dim=1</span></code> (columns), we got a 2×6 tensor by stacking <code class="docutils literal notranslate"><span class="pre">t2</span></code> to the right of <code class="docutils literal notranslate"><span class="pre">t1</span></code>.</p></li>
</ul>
<p>These basic operations (arithmetic, indexing, reshaping, concatenation, etc.) allow you to manipulate tensor data in flexible ways. PyTorch’s API is designed to be highly compatible with NumPy’s where it makes sense.</p>
</section>
</section>
<section id="autograd-and-gradients">
<h3><span class="section-number">5.2.3. </span>Autograd and Gradients<a class="headerlink" href="#autograd-and-gradients" title="Link to this heading">#</a></h3>
<p>One of the most powerful features of PyTorch is its <strong>autograd</strong> system, which allows automatic computation of gradients for tensor operations. This is what enables training of neural networks using gradient descent: you define a forward computation, and PyTorch can compute the backward gradients for you.</p>
<p>In PyTorch, the <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code> engine tracks all operations on tensors that have <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code>. By default, tensors do <strong>not</strong> track gradients. You need to specify which tensors require gradient computation (usually the learnable parameters of your model, or any input for which you want to compute a derivative) by setting <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code> when creating the tensor or by calling <code class="docutils literal notranslate"><span class="pre">.requires_grad_()</span></code> on an existing tensor.</p>
<p>When you perform operations on such tensors, PyTorch builds a computational graph behind the scenes: nodes are tensors, and edges are functions that produce output tensors from input tensors. Once you have a result (typically a scalar loss value), you can call <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> on it, and PyTorch will automatically traverse the graph to compute the gradient of that result with respect to every tensor that has <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code> (using the chain rule of calculus). Let’s see a simple example to illustrate this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A simple autograd example: y = f(x) where f(x) = x^2 + 2x + 1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>   <span class="c1"># define a tensor x with gradient tracking</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># Define a function of x</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Compute the gradient dy/dx by calling backward on y</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>    <span class="c1"># computes gradient of y w.r.t. x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dy/dx at x=3:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x: tensor(3., requires_grad=True)
y: tensor(16., grad_fn=&lt;AddBackward0&gt;)
dy/dx at x=3: tensor(8.)
</pre></div>
</div>
</div>
</div>
<p>In this example:</p>
<ul class="simple">
<li><p>We created a tensor <code class="docutils literal notranslate"><span class="pre">x</span></code> with value <code class="docutils literal notranslate"><span class="pre">3.0</span></code> and <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code>. This means PyTorch will track operations on <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p></li>
<li><p>We computed <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">x**2</span> <span class="pre">+</span> <span class="pre">2*x</span> <span class="pre">+</span> <span class="pre">1</span></code>. Because <code class="docutils literal notranslate"><span class="pre">x</span></code> requires grad, <code class="docutils literal notranslate"><span class="pre">y</span></code> will also by default require grad and have a grad function associated.</p></li>
<li><p>We called <code class="docutils literal notranslate"><span class="pre">y.backward()</span></code>. Since <code class="docutils literal notranslate"><span class="pre">y</span></code> is a scalar (single value), we can call <code class="docutils literal notranslate"><span class="pre">backward</span></code> directly. After this call, the gradient of <code class="docutils literal notranslate"><span class="pre">y</span></code> with respect to <code class="docutils literal notranslate"><span class="pre">x</span></code> is computed and stored in <code class="docutils literal notranslate"><span class="pre">x.grad</span></code>.</p></li>
<li><p>We printed <code class="docutils literal notranslate"><span class="pre">x.grad</span></code>. The derivative <span class="math notranslate nohighlight">\( y = x^2 + 2x + 1 \)</span> is <span class="math notranslate nohighlight">\( dy/dx = 2x + 2 \)</span>. At <span class="math notranslate nohighlight">\( x = 3 \)</span>, that is <code class="docutils literal notranslate"><span class="pre">8</span></code>.</p></li>
</ul>
<p><strong>Important notes about autograd</strong>:</p>
<ol class="arabic simple">
<li><p>You can disable gradient tracking by wrapping code in <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">torch.no_grad():</span></code> or by using <code class="docutils literal notranslate"><span class="pre">.detach()</span></code> on a tensor to get a new tensor that shares the same data but with no grad tracking.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">y</span></code> is not a scalar, you need to specify a gradient argument in <code class="docutils literal notranslate"><span class="pre">y.backward(gradient=...)</span></code> which is the tensor of same shape as <code class="docutils literal notranslate"><span class="pre">y</span></code> containing the gradient of the final result w.r.t. each element of <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p>By default, gradients are <strong>accumulated</strong> into the <code class="docutils literal notranslate"><span class="pre">.grad</span></code> property. So typically you want to zero out gradients (e.g., <code class="docutils literal notranslate"><span class="pre">x.grad.zero_()</span></code>) between independent backward passes.</p></li>
</ol>
<p>Autograd is what powers training routines. If you had a multi-parameter function (like a neural network with many weights), you would set <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code> for all those parameters. After computing a loss (scalar), you’d call <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>, and each parameter tensor’s <code class="docutils literal notranslate"><span class="pre">.grad</span></code> will be filled with its gradient.</p>
<p>To reinforce understanding, let’s do a slightly more complex autograd example with two inputs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Autograd with two inputs: z = x * y + y^2</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span>   <span class="c1"># z is a function of both x and y</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;z:&quot;</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

<span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Compute gradients dz/dx and dz/dy</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dz/dx:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>   <span class="c1"># should be y</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dz/dy:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>   <span class="c1"># should be x + 2y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>z: tensor(3., grad_fn=&lt;AddBackward0&gt;)
dz/dx: tensor(-3.)
dz/dy: tensor(-4.)
</pre></div>
</div>
</div>
</div>
<p>Here <span class="math notranslate nohighlight">\( z = x \times y + y^2 \)</span>. We expect <span class="math notranslate nohighlight">\( dz/dx = y \)</span> and <span class="math notranslate nohighlight">\( dz/dy = x + 2y \)</span>. With <span class="math notranslate nohighlight">\( x = 2.0 \)</span> and <span class="math notranslate nohighlight">\( y = -3.0 \)</span>, those values are <span class="math notranslate nohighlight">\( dz/dx = -3 \)</span> and <span class="math notranslate nohighlight">\( dz/dy = 2 + 2(-3) = -4 \)</span>. The autograd should produce the same results in <code class="docutils literal notranslate"><span class="pre">x.grad</span></code> and <code class="docutils literal notranslate"><span class="pre">y.grad</span></code>.</p>
</section>
<section id="advanced-tensor-functions">
<h3><span class="section-number">5.2.4. </span>Advanced Tensor Functions<a class="headerlink" href="#advanced-tensor-functions" title="Link to this heading">#</a></h3>
<section id="broadcasting">
<h4><span class="section-number">5.2.4.1. </span>Broadcasting<a class="headerlink" href="#broadcasting" title="Link to this heading">#</a></h4>
<p>Like NumPy, PyTorch supports <strong>broadcasting</strong> – a mechanism that allows arithmetic operations on tensors of different shapes by automatically expanding one of them to match the shape of the other. Broadcasting rules in PyTorch are the same as NumPy’s. In short, two tensors are compatible for an elementwise operation if their shapes are equal or align in such a way that one of them can be expanded (a dimension of size 1 can be expanded to match the other’s size, and missing dimensions are treated as size 1).</p>
<p>For example, if you have a tensor of shape (4, 3) and another of shape (3,), you can add them because the second tensor can be treated as if it were (1, 3) and then expanded to (4, 3) to match the first tensor’s shape.</p>
<p>In code, we can demonstrate broadcasting with a simple example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Broadcasting example: add a vector to each row of a matrix</span>
<span class="n">mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">]])</span>   <span class="c1"># shape (4,3)</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>        <span class="c1"># shape (3,)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">mat</span> <span class="o">+</span> <span class="n">vec</span>  <span class="c1"># vec is broadcast to shape (4,3)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;M=&quot;</span><span class="p">,</span> <span class="n">mat</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;V=&quot;</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;M+V&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle M=\left[
\begin{array}{}
  0.0000 &amp;  0.0000 &amp;  0.0000\\
  10.0000 &amp;  10.0000 &amp;  10.0000\\
  20.0000 &amp;  20.0000 &amp;  20.0000\\
  30.0000 &amp;  30.0000 &amp;  30.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle V=\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle M+V\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000\\
  11.0000 &amp;  12.0000 &amp;  13.0000\\
  21.0000 &amp;  22.0000 &amp;  23.0000\\
  31.0000 &amp;  32.0000 &amp;  33.0000
\end{array}
\right]\end{split}\]</div>
</div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">vec</span></code> is added to each row of <code class="docutils literal notranslate"><span class="pre">mat</span></code>. The expected result would be each row of <code class="docutils literal notranslate"><span class="pre">mat</span></code> incremented by <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3]</span></code>. Broadcasting is a powerful feature that makes your code more concise and often more efficient.</p>
</section>
<section id="device-management-cpu-vs-gpu">
<h4><span class="section-number">5.2.4.2. </span>Device Management (CPU vs GPU)<a class="headerlink" href="#device-management-cpu-vs-gpu" title="Link to this heading">#</a></h4>
<p>One of PyTorch’s strengths is the ability to perform computations on a <strong>GPU</strong> for speed. Tensors can reside on either the CPU or the GPU. By default, tensors are created on the CPU.
You can check where a tensor is located by looking at its <code class="docutils literal notranslate"><span class="pre">.device</span></code> attribute. To leverage a GPU (if you have one and PyTorch is installed with CUDA support), you need to explicitly move tensors to the GPU. There are a few ways to do this:</p>
<ol class="arabic simple">
<li><p>Using the <code class="docutils literal notranslate"><span class="pre">.to(device)</span></code> method on a tensor, where <code class="docutils literal notranslate"><span class="pre">device</span></code> is something like <code class="docutils literal notranslate"><span class="pre">torch.device(&quot;cuda&quot;)</span></code> or the shorthand string <code class="docutils literal notranslate"><span class="pre">&quot;cuda&quot;</span></code>.</p></li>
<li><p>Using <code class="docutils literal notranslate"><span class="pre">.cuda()</span></code> method on the tensor.</p></li>
<li><p>Creating the tensor directly on the GPU by specifying <code class="docutils literal notranslate"><span class="pre">device=torch.device(&quot;cuda&quot;)</span></code> (or <code class="docutils literal notranslate"><span class="pre">device=&quot;cuda&quot;</span></code>) in the creation function.</p></li>
</ol>
<p>It’s common to write code that is device-agnostic (runs on CPU if no GPU is available, otherwise uses the GPU). For example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Device-agnostic code: choose CPU or CUDA</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="p">(</span><span class="s2">&quot;mps&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using device:&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="c1"># Create a tensor on the chosen device</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x device:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Alternatively, move an existing tensor to the device</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>            <span class="c1"># defaults to CPU</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>             <span class="c1"># move to GPU if available</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y device:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using device: mps
x device: mps:0
y device: mps:0
</pre></div>
</div>
</div>
</div>
<p>If you actually run this on a system with a GPU and CUDA installed, you should see device printed as <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code> and the tensor devices as such. On a CPU-only system, it will say <code class="docutils literal notranslate"><span class="pre">cpu</span></code>.</p>
<p>A quick verification of CPU vs GPU performance can be done by timing a large matrix multiplication. (Note: if you actually run this, avoid printing the giant result; just measure the time.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Large tensor operation on CPU vs GPU (if available)</span>
<span class="n">large_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>  <span class="c1"># 10000x10000 matrix on CPU</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">res_cpu</span> <span class="o">=</span> <span class="n">large_cpu</span> <span class="o">@</span> <span class="n">large_cpu</span>       <span class="c1"># matrix multiply on CPU</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CPU computation time:&quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s2">&quot;seconds&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">large_gpu</span> <span class="o">=</span> <span class="n">large_cpu</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>  <span class="c1"># ensure data is transferred</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">res_gpu</span> <span class="o">=</span> <span class="n">large_gpu</span> <span class="o">@</span> <span class="n">large_gpu</span>   <span class="c1"># matrix multiply on GPU</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>  <span class="c1"># wait for GPU to finish computation</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU computation time:&quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s2">&quot;seconds&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">large_gpu</span> <span class="o">=</span> <span class="n">large_cpu</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">res_gpu</span> <span class="o">=</span> <span class="n">large_gpu</span> <span class="o">@</span> <span class="n">large_gpu</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MPS computation time:&quot;</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s2">&quot;seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU computation time: 2.957353115081787 seconds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MPS computation time: 0.06571102142333984 seconds
</pre></div>
</div>
</div>
</div>
<p>This snippet will likely show that the GPU computation is significantly faster for large matrix operations (depending on hardware). Remember to move your <strong>model parameters</strong> and <strong>data</strong> to the same device before doing operations.</p>
<p>For example, the code below moves a tensor to GPU if available:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before moving, device:&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After moving, device:&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;mps&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After moving, device:&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before moving, device: cpu
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>After moving, device: mps:0
</pre></div>
</div>
</div>
</div>
<p>Running this will print:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Before moving, device: cpu
After moving, device: cuda:0
</pre></div>
</div>
<p>if you have a GPU, or</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Before moving, device: cpu
After moving, device: mps:0
</pre></div>
</div>
<p>on M-chip Apple devices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">set_default_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="in-place-operations">
<h4><span class="section-number">5.2.4.3. </span>In-place Operations<a class="headerlink" href="#in-place-operations" title="Link to this heading">#</a></h4>
<p>PyTorch differentiates between operations that create new tensors and those that modify an existing tensor <strong>in-place</strong>. In-place operations are identified by an underscore suffix in the method name. For example, <code class="docutils literal notranslate"><span class="pre">tensor.add_(5)</span></code> will add 5 to every element of the tensor <strong>in-place</strong> (mutating the tensor), whereas <code class="docutils literal notranslate"><span class="pre">tensor.add(5)</span></code> returns a new tensor with the result and leaves the original unchanged. All functions ending in <code class="docutils literal notranslate"><span class="pre">_</span></code> modify the tensor in-place.</p>
<p>Why use in-place ops? They can save memory and sometimes a bit of compute, because you don’t allocate a new tensor for the result. However, be careful: in-place operations can sometimes interfere with autograd (if you modify values required to compute gradients). As a rule of thumb, avoid using in-place ops on tensors that require grad unless you know what you’re doing.</p>
<p>Let’s demonstrate the difference between an in-place operation and its out-of-place counterpart:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;a=&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

<span class="c1"># Out-of-place addition</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After b = a.add(5):&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;a=&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>  <span class="c1"># a should remain unchanged</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;b=&quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># b is the new tensor</span>

<span class="c1"># In-place addition</span>
<span class="n">a</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">After a.add_(5):&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;a=&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>  <span class="c1"># a is now changed in-place</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle a=\left[
\begin{array}{}
  1.0000 &amp;  1.0000 &amp;  1.0000 &amp;  1.0000 &amp;  1.0000
\end{array}
\right]\]</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>After b = a.add(5):
</pre></div>
</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle a=\left[
\begin{array}{}
  1.0000 &amp;  1.0000 &amp;  1.0000 &amp;  1.0000 &amp;  1.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle b=\left[
\begin{array}{}
  6.0000 &amp;  6.0000 &amp;  6.0000 &amp;  6.0000 &amp;  6.0000
\end{array}
\right]\]</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>After a.add_(5):
</pre></div>
</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle a=\left[
\begin{array}{}
  6.0000 &amp;  6.0000 &amp;  6.0000 &amp;  6.0000 &amp;  6.0000
\end{array}
\right]\]</div>
</div>
</div>
<p>Output should show:</p>
<ol class="arabic simple">
<li><p>Initially, <code class="docutils literal notranslate"><span class="pre">a</span></code> is <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>.</p></li>
<li><p>After <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">=</span> <span class="pre">a.add(5)</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> stays <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1]</span></code> but <code class="docutils literal notranslate"><span class="pre">b</span></code> is <code class="docutils literal notranslate"><span class="pre">[6,</span> <span class="pre">6,</span> <span class="pre">6,</span> <span class="pre">6,</span> <span class="pre">6]</span></code>.</p></li>
<li><p>After <code class="docutils literal notranslate"><span class="pre">a.add_(5)</span></code>, now <code class="docutils literal notranslate"><span class="pre">a</span></code> has become <code class="docutils literal notranslate"><span class="pre">[6,</span> <span class="pre">6,</span> <span class="pre">6,</span> <span class="pre">6,</span> <span class="pre">6]</span></code> in-place.</p></li>
</ol>
<p>Another example with multiplication:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># in-place multiply x by 2</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;x=&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;y=&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{x after in-place mul\_: }&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{y (result of x.mul\_(2)): }&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Now x is [2,2,2], let&#39;s do out-of-place multiply</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{x after out-of-place mul(3): }&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>  <span class="c1"># x remains [2,2,2]</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{z (result of x.mul(3)): }&quot;</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>       <span class="c1"># z is [6,6,6]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle x=\left[
\begin{array}{}
  2.0000 &amp;  2.0000 &amp;  2.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle y=\left[
\begin{array}{}
  2.0000 &amp;  2.0000 &amp;  2.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{x after in-place mul\_: }\left[
\begin{array}{}
  2.0000 &amp;  2.0000 &amp;  2.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{y (result of x.mul\_(2)): }\left[
\begin{array}{}
  2.0000 &amp;  2.0000 &amp;  2.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{x after out-of-place mul(3): }\left[
\begin{array}{}
  2.0000 &amp;  2.0000 &amp;  2.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{z (result of x.mul(3)): }\left[
\begin{array}{}
  6.0000 &amp;  6.0000 &amp;  6.0000
\end{array}
\right]\]</div>
</div>
</div>
<p>This shows that after the in-place multiply, <code class="docutils literal notranslate"><span class="pre">x</span></code> (and <code class="docutils literal notranslate"><span class="pre">y</span></code>) have doubled their values, while the out-of-place multiply by 3 produces a new tensor <code class="docutils literal notranslate"><span class="pre">z</span></code> and leaves <code class="docutils literal notranslate"><span class="pre">x</span></code> the same.</p>
</section>
</section>
</section>
<section id="exercises">
<h2><span class="section-number">5.3. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<section id="comparison-of-symbolic-and-automatic-differentiation-in-a-simple-feedforward-neural-network">
<h3><span class="section-number">5.3.1. </span>Comparison of symbolic and automatic differentiation in a simple feedforward neural network<a class="headerlink" href="#comparison-of-symbolic-and-automatic-differentiation-in-a-simple-feedforward-neural-network" title="Link to this heading">#</a></h3>
<p>In this exercise, we will illustrate how <strong>automatic differentiation</strong> (as implemented in PyTorch) matches with the result of <strong>symbolic differentiation</strong> for a simple two-hidden-neuron feedforward neural network. You should:</p>
<ol class="arabic simple">
<li><p><strong>Define</strong> a simple feedforward neural network (FNN) with two hidden neurons <span class="math notranslate nohighlight">\(z_1\)</span> and <span class="math notranslate nohighlight">\(z_2\)</span> using the values and notation from the figure below.</p></li>
<li><p><strong>Compute</strong> the network output and the loss function (a squared error).</p></li>
<li><p><strong>Derive</strong> the gradient of the loss function with respect to each weight <strong>symbolically</strong>.</p></li>
<li><p><strong>Use</strong> PyTorch’s <strong>automatic differentiation</strong> to compute the same gradients <strong>numerically</strong>.</p></li>
<li><p><strong>Compare</strong> the two results to verify they match.</p></li>
</ol>
<p>The feedforward neural network architecture that we will use in this exercise is the following:</p>
<img src="data:image/png;base64,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" style="width: 50%; height: 100%;"/></section>
</section>
<section id="problem-setup">
<h2><span class="section-number">5.4. </span>Problem setup<a class="headerlink" href="#problem-setup" title="Link to this heading">#</a></h2>
<p>Let’s consider the following simplified network:</p>
<ul class="simple">
<li><p><strong>Input</strong>: <span class="math notranslate nohighlight">\(x\)</span>, a single scalar input.</p></li>
<li><p><strong>Hidden layer</strong>: two neurons <span class="math notranslate nohighlight">\(z_1\)</span> and <span class="math notranslate nohighlight">\(z_2\)</span></p></li>
<li><p><strong>Output</strong>: <span class="math notranslate nohighlight">\(\hat{y}\)</span></p></li>
</ul>
<p>For a single input <span class="math notranslate nohighlight">\(x\)</span>, the hidden neurons are given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\text{Neuron } z_1: &amp; \quad a_1^{(1)} = w_{11}^{(1)} \cdot x, &amp;&amp; \quad z_1 = g(a_1^{(1)}) = \frac{1}{1 + e^{-a_1^{(1)}}}, \\
\text{Neuron } z_2: &amp; \quad a_2^{(1)} = w_{12}^{(1)} \cdot x, &amp;&amp; \quad z_2 = g(a_2^{(1)}) = \frac{1}{1 + e^{-a_2^{(1)}}}.
\end{aligned}
\end{split}\]</div>
<p>Then the output neuron combines these two hidden neurons:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
a_1^{(2)} &amp;= w_{11}^{(2)} z_1 + w_{21}^{(2)} z_2, \\
\hat{y} &amp;= g(a_1^{(2)}) = \frac{1}{1 + e^{-a_1^{(2)}}}.
\end{aligned}
\end{split}\]</div>
<p>We consider a <strong>loss</strong> (squared error w.r.t. a true label <span class="math notranslate nohighlight">\(y\)</span>):</p>
<div class="math notranslate nohighlight">
\[L = (y - \hat{y})^2.\]</div>
<p>Our goal is to <strong>differentiate</strong> <span class="math notranslate nohighlight">\(L\)</span> with respect to the parameters:</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
w_{11}^{(1)},\quad w_{12}^{(1)},\quad w_{11}^{(2)},\quad w_{21}^{(2)}.
\end{aligned}
\]</div>
<p>We will compute these derivatives in two ways:</p>
<ol class="arabic simple">
<li><p><strong>Symbolic Differentiation</strong> (analytical formulas)</p></li>
<li><p><strong>Automatic Differentiation</strong> (via PyTorch <code class="docutils literal notranslate"><span class="pre">backward()</span></code>)</p></li>
</ol>
<p>We will show that these two results match.</p>
</section>
<section id="pytorch-implementation">
<h2><span class="section-number">5.5. </span>PyTorch implementation<a class="headerlink" href="#pytorch-implementation" title="Link to this heading">#</a></h2>
<section id="define-the-activation-function-and-its-derivative">
<h3><span class="section-number">5.5.1. </span>Define the activation function and its derivative<a class="headerlink" href="#define-the-activation-function-and-its-derivative" title="Link to this heading">#</a></h3>
<p>We will use the logistic sigmoid <span class="math notranslate nohighlight">\(g(a) = 1 / (1 + e^{-a})\)</span> as the activation function. Its derivative with respect to <span class="math notranslate nohighlight">\(a\)</span> is:</p>
<div class="math notranslate nohighlight">
\[\frac{d}{da} g(a) = g(a) \bigl(1 - g(a)\bigr).\]</div>
<p>However, for clarity, we can directly implement it as given in the example code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">g</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sigmoid function g(a) = 1 / (1 + e^-a)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">gp</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Derivative of the sigmoid function g&#39;(a)</span>
<span class="sd">    = exp(-a) / (1 + exp(-a))^2</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-the-working-variables">
<h3><span class="section-number">5.5.2. </span>Define the working variables<a class="headerlink" href="#define-the-working-variables" title="Link to this heading">#</a></h3>
<p>We will define:</p>
<ul class="simple">
<li><p>A target value <span class="math notranslate nohighlight">\(y\)</span></p></li>
<li><p>An input <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p>Four weights we wish to learn/differentiate:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(w_{11}^{(1)}\)</span> and <span class="math notranslate nohighlight">\(w_{12}^{(1)}\)</span> for the hidden layer</p></li>
<li><p><span class="math notranslate nohighlight">\(w_{11}^{(2)}\)</span> and <span class="math notranslate nohighlight">\(w_{21}^{(2)}\)</span> for the output layer</p></li>
</ul>
</li>
</ul>
<p>By setting <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code>, PyTorch will keep track of operations involving these tensors, allowing automatic differentiation via the <code class="docutils literal notranslate"><span class="pre">backward()</span></code> call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Input</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.7</span><span class="p">])</span>  <span class="c1"># A single scalar input</span>

<span class="c1"># True target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.5</span><span class="p">])</span>  <span class="c1"># A single scalar target</span>

<span class="c1"># Hidden layer weights</span>
<span class="n">w11_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.13</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># w_{11}^{(1)}</span>
<span class="n">w12_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># w_{12}^{(1)}</span>

<span class="c1"># Output layer weights</span>
<span class="n">w11_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>   <span class="c1"># w_{11}^{(2)}</span>
<span class="n">w21_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>   <span class="c1"># w_{21}^{(2)}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="forward-pass">
<h3><span class="section-number">5.5.3. </span>Forward pass<a class="headerlink" href="#forward-pass" title="Link to this heading">#</a></h3>
<p>We compute:</p>
<div class="math notranslate nohighlight">
\[a_1^{(1)} = w_{11}^{(1)} x,\quad
a_2^{(1)} = w_{12}^{(1)} x,\quad
z_1 = g(a_1^{(1)}),\quad z_2 = g(a_2^{(1)}),\quad
a_1^{(2)} = w_{11}^{(2)} z_1 + w_{21}^{(2)} z_2,\quad
\hat{y} = g(a_1^{(2)})
\]</div>
<p>and finally the loss <span class="math notranslate nohighlight">\(L = (y - \hat{y})^2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hidden neuron 1</span>
<span class="n">a1_1</span> <span class="o">=</span> <span class="n">w11_1</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">z1</span>   <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">a1_1</span><span class="p">)</span>

<span class="c1"># Hidden neuron 2</span>
<span class="n">a2_1</span> <span class="o">=</span> <span class="n">w12_1</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">z2</span>   <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">a2_1</span><span class="p">)</span>

<span class="c1"># Output neuron</span>
<span class="n">a1_2</span> <span class="o">=</span> <span class="n">w11_2</span> <span class="o">*</span> <span class="n">z1</span> <span class="o">+</span> <span class="n">w21_2</span> <span class="o">*</span> <span class="n">z2</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">a1_2</span><span class="p">)</span>

<span class="c1"># Loss</span>
<span class="n">L</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="symbolic-gradients">
<h3><span class="section-number">5.5.4. </span>Symbolic gradients<a class="headerlink" href="#symbolic-gradients" title="Link to this heading">#</a></h3>
<p>From the slides and from our direct symbolic differentiation, we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\frac{\partial L}{\partial w_{11}^{(1)}} 
&amp;= -2 \,(y - \hat{y})\; g'(a_1^{(2)})\; w_{11}^{(2)}\; g'(a_1^{(1)})\; x,\\
\frac{\partial L}{\partial w_{12}^{(1)}} 
&amp;= -2 \,(y - \hat{y})\; g'(a_1^{(2)})\; w_{21}^{(2)}\; g'(a_2^{(1)})\; x,\\
\frac{\partial L}{\partial w_{11}^{(2)}} 
&amp;= -2 \,(y - \hat{y})\; g'(a_1^{(2)})\; z_1,\\
\frac{\partial L}{\partial w_{21}^{(2)}} 
&amp;= -2 \,(y - \hat{y})\; g'(a_1^{(2)})\; z_2.
\end{aligned}\end{split}\]</div>
<p>Let’s compute these values explicitly in PyTorch (still using the same <code class="docutils literal notranslate"><span class="pre">gp</span></code> function for <span class="math notranslate nohighlight">\(g'(a)\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Symbolic gradients</span>
<span class="n">Sgrad_L_w11_1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span> <span class="o">*</span> <span class="n">gp</span><span class="p">(</span><span class="n">a1_2</span><span class="p">)</span> <span class="o">*</span> <span class="n">w11_2</span> <span class="o">*</span> <span class="n">gp</span><span class="p">(</span><span class="n">a1_1</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">Sgrad_L_w12_1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span> <span class="o">*</span> <span class="n">gp</span><span class="p">(</span><span class="n">a1_2</span><span class="p">)</span> <span class="o">*</span> <span class="n">w21_2</span> <span class="o">*</span> <span class="n">gp</span><span class="p">(</span><span class="n">a2_1</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">Sgrad_L_w11_2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span> <span class="o">*</span> <span class="n">gp</span><span class="p">(</span><span class="n">a1_2</span><span class="p">)</span> <span class="o">*</span> <span class="n">z1</span>
<span class="n">Sgrad_L_w21_2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span> <span class="o">*</span> <span class="n">gp</span><span class="p">(</span><span class="n">a1_2</span><span class="p">)</span> <span class="o">*</span> <span class="n">z2</span>

<span class="n">Sgrad_L_w11_1</span><span class="p">,</span> <span class="n">Sgrad_L_w12_1</span><span class="p">,</span> <span class="n">Sgrad_L_w11_2</span><span class="p">,</span> <span class="n">Sgrad_L_w21_2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([-0.8892], device=&#39;mps:0&#39;, grad_fn=&lt;MulBackward0&gt;),
 tensor([-0.0563], device=&#39;mps:0&#39;, grad_fn=&lt;MulBackward0&gt;),
 tensor([0.9424], device=&#39;mps:0&#39;, grad_fn=&lt;MulBackward0&gt;),
 tensor([2.0494], device=&#39;mps:0&#39;, grad_fn=&lt;MulBackward0&gt;))
</pre></div>
</div>
</div>
</div>
</section>
<section id="automatic-differentiation">
<h3><span class="section-number">5.5.5. </span>Automatic differentiation<a class="headerlink" href="#automatic-differentiation" title="Link to this heading">#</a></h3>
<p>We can then rely on PyTorch’s <strong>autograd</strong> engine to compute the gradients for us. Simply call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">L</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<p>and then retrieve the <code class="docutils literal notranslate"><span class="pre">.grad</span></code> attribute of each parameter of interest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reset gradients (in case this cell is run multiple times)</span>
<span class="n">w11_1</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">w12_1</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">w11_2</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">w21_2</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># Perform backprop</span>
<span class="n">L</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># Automatic gradients</span>
<span class="n">grad_L_w11_1</span> <span class="o">=</span> <span class="n">w11_1</span><span class="o">.</span><span class="n">grad</span>
<span class="n">grad_L_w12_1</span> <span class="o">=</span> <span class="n">w12_1</span><span class="o">.</span><span class="n">grad</span>
<span class="n">grad_L_w11_2</span> <span class="o">=</span> <span class="n">w11_2</span><span class="o">.</span><span class="n">grad</span>
<span class="n">grad_L_w21_2</span> <span class="o">=</span> <span class="n">w21_2</span><span class="o">.</span><span class="n">grad</span>

<span class="n">grad_L_w11_1</span><span class="p">,</span> <span class="n">grad_L_w12_1</span><span class="p">,</span> <span class="n">grad_L_w11_2</span><span class="p">,</span> <span class="n">grad_L_w21_2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([-0.8892], device=&#39;mps:0&#39;),
 tensor([-0.0563], device=&#39;mps:0&#39;),
 tensor([0.9424], device=&#39;mps:0&#39;),
 tensor([2.0494], device=&#39;mps:0&#39;))
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparison-of-symbolic-and-automatic-differentiation">
<h3><span class="section-number">5.5.6. </span>Comparison of symbolic and automatic differentiation<a class="headerlink" href="#comparison-of-symbolic-and-automatic-differentiation" title="Link to this heading">#</a></h3>
<p>Finally, let’s print them side by side to verify they match (or are very close, up to floating-point rounding).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss L =&quot;</span><span class="p">,</span> <span class="n">L</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- dL/dw11^(2) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Auto-grad:&quot;</span><span class="p">,</span> <span class="n">grad_L_w11_2</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Symbolic:&quot;</span><span class="p">,</span> <span class="n">Sgrad_L_w11_2</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- dL/dw21^(2) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Auto-grad:&quot;</span><span class="p">,</span> <span class="n">grad_L_w21_2</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Symbolic:&quot;</span><span class="p">,</span> <span class="n">Sgrad_L_w21_2</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- dL/dw11^(1) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Auto-grad:&quot;</span><span class="p">,</span> <span class="n">grad_L_w11_1</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Symbolic:&quot;</span><span class="p">,</span> <span class="n">Sgrad_L_w11_1</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- dL/dw12^(1) ---&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Auto-grad:&quot;</span><span class="p">,</span> <span class="n">grad_L_w12_1</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2"> Symbolic:&quot;</span><span class="p">,</span> <span class="n">Sgrad_L_w12_1</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loss L = 27.21538734436035

--- dL/dw11^(2) ---
Auto-grad: 0.942385196685791 	 Symbolic: 0.9423852562904358

--- dL/dw21^(2) ---
Auto-grad: 2.049447774887085 	 Symbolic: 2.049448013305664

--- dL/dw11^(1) ---
Auto-grad: -0.8891823887825012 	 Symbolic: -0.8891823887825012

--- dL/dw12^(1) ---
Auto-grad: -0.05625968053936958 	 Symbolic: -0.05625968798995018
</pre></div>
</div>
</div>
</div>
<p>In this exercise, we demonstrated that for our simple 2-hidden-neuron feedforward network:</p>
<ol class="arabic simple">
<li><p><strong>Symbolic differentiation</strong> (i.e., deriving the gradient expressions by hand)</p></li>
<li><p><strong>Automatic differentiation</strong> (i.e., via PyTorch’s <code class="docutils literal notranslate"><span class="pre">backward()</span></code>)</p></li>
</ol>
<p>yield the <strong>same</strong> results, up to numerical precision. This is a powerful illustration of why automatic differentiation is so valuable: it <strong>automates</strong> what would otherwise be a lengthy (and error-prone) symbolic derivation process.</p>
<p>Feel free to change the values of <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(y\)</span>, and the weights <span class="math notranslate nohighlight">\(w\)</span> to see how the gradients match up in other situations.
You can now expand this example to more complex network architectures or different activation and loss functions.</p>
</section>
<section id="facial-keypoints-detection-with-pytorch-fcn-and-cnn-architectures">
<h3><span class="section-number">5.5.7. </span>Facial keypoints detection with PyTorch FCN and CNN architectures<a class="headerlink" href="#facial-keypoints-detection-with-pytorch-fcn-and-cnn-architectures" title="Link to this heading">#</a></h3>
<p>Facial keypoint detection is the task of identifying important landmarks on a human face (e.g., corners of the eyes, nose tip, mouth corners) in an image. These keypoints are crucial for many applications in computer vision:</p>
<ul class="simple">
<li><p>Aligning faces for recognition or verification.</p></li>
<li><p>Tracking facial expressions for emotion detection.</p></li>
<li><p>Applying augmented reality filters or effects accurately on a face.</p></li>
</ul>
<p>In this exercise, we will build fully connected neural networks and convolutional neural networks to detect <strong>15 keypoints</strong> on <strong>96x96 grayscale face images</strong>. The network will take an image as input and output the <span class="math notranslate nohighlight">\( (x,y) \)</span> coordinates of the <strong>15 facial keypoints</strong>.</p>
<p>Source: <a class="reference external" href="https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/">danielnouri.org</a></p>
</section>
<section id="dataset-overview">
<h3><span class="section-number">5.5.8. </span>Dataset overview<a class="headerlink" href="#dataset-overview" title="Link to this heading">#</a></h3>
<p>We will use the <strong>Kaggle Facial Keypoints Detection</strong> dataset (<a class="reference external" href="https://www.kaggle.com/competitions/facial-keypoints-detection">Kaggle challenge webpage</a>). This dataset consists of a training set of <strong>7,049</strong> face images (96x96 pixels, grayscale). Each image has up to <strong>15 keypoint coordinates</strong> labeled (30 values: <span class="math notranslate nohighlight">\( x \)</span> and <span class="math notranslate nohighlight">\( y \)</span> for each of 15 facial landmarks). For example, the keypoints include the centers of the eyes, the tip of the nose, and the corners of the mouth.</p>
<section id="data-format">
<h4><span class="section-number">5.5.8.1. </span>Data format<a class="headerlink" href="#data-format" title="Link to this heading">#</a></h4>
<p>The training data is provided as a CSV file (<code class="docutils literal notranslate"><span class="pre">training.csv</span></code>). Each row contains:</p>
<ul class="simple">
<li><p><strong>30 columns</strong> of keypoint coordinates: <code class="docutils literal notranslate"><span class="pre">left_eye_center_x</span></code>, <code class="docutils literal notranslate"><span class="pre">left_eye_center_y</span></code>, <code class="docutils literal notranslate"><span class="pre">right_eye_center_x</span></code>, … etc. (15 keypoints <span class="math notranslate nohighlight">\(\times\)</span> 2). If a keypoint was not labeled for a given image, its value is missing.</p></li>
<li><p>An <strong>Image</strong> column containing 96x96 pixel intensity values (9216 numbers) in a single string, separated by spaces.</p></li>
</ul>
<p>If you downloaded this exercise from the Université Virtuelle, you should have a <code class="docutils literal notranslate"><span class="pre">training.csv</span></code> file in the <code class="docutils literal notranslate"><span class="pre">data/</span></code> directory. Now, let’s load the training data using pandas and examine its structure.</p>
</section>
<section id="missing-values">
<h4><span class="section-number">5.5.8.2. </span>Missing values<a class="headerlink" href="#missing-values" title="Link to this heading">#</a></h4>
<p>Not all images have all 15 keypoints annotated. In fact, only about 30% of the images have all 15 keypoints; the rest have some missing keypoint labels. Nearly all images have at least a few keypoints (e.g., eyes, nose, mouth) labeled, but many did not have the more peripheral points. In this tutorial, for simplicity, we will use only images with <strong>complete keypoint data</strong> (all 15 points). This means we’ll discard images with any missing keypoint values. (In practice, one could use data augmentation or multi-stage training to leverage partially labeled images, but we will not cover that here.)</p>
<p>In this exercise, you should:</p>
<ol class="arabic simple">
<li><p>Explore the dataset</p></li>
<li><p>Preprocess the dataset to use it with neural networks including:</p>
<ul class="simple">
<li><p>handling missing values</p></li>
<li><p>converting the image data from strings to numeric arrays</p></li>
<li><p>normalizing the pixel values</p></li>
<li><p>reshaping the images</p></li>
<li><p>preparing the keypoint coordinates labels</p></li>
</ul>
</li>
<li><p>Implement a fully connected neural network and compute the validated MSE</p></li>
<li><p>Implement a convolutional neural network and compute the validated MSE</p></li>
<li><p>Visualize the predictions of both models with respect to the true keypoints coordinates on images</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Load the training data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;facial-keypoints-detection/training.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training data shape:&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># show first 5 rows as an example</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training data shape: (7049, 31)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>left_eye_center_x</th>
      <th>left_eye_center_y</th>
      <th>right_eye_center_x</th>
      <th>right_eye_center_y</th>
      <th>left_eye_inner_corner_x</th>
      <th>left_eye_inner_corner_y</th>
      <th>left_eye_outer_corner_x</th>
      <th>left_eye_outer_corner_y</th>
      <th>right_eye_inner_corner_x</th>
      <th>right_eye_inner_corner_y</th>
      <th>...</th>
      <th>nose_tip_y</th>
      <th>mouth_left_corner_x</th>
      <th>mouth_left_corner_y</th>
      <th>mouth_right_corner_x</th>
      <th>mouth_right_corner_y</th>
      <th>mouth_center_top_lip_x</th>
      <th>mouth_center_top_lip_y</th>
      <th>mouth_center_bottom_lip_x</th>
      <th>mouth_center_bottom_lip_y</th>
      <th>Image</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>66.033564</td>
      <td>39.002274</td>
      <td>30.227008</td>
      <td>36.421678</td>
      <td>59.582075</td>
      <td>39.647423</td>
      <td>73.130346</td>
      <td>39.969997</td>
      <td>36.356571</td>
      <td>37.389402</td>
      <td>...</td>
      <td>57.066803</td>
      <td>61.195308</td>
      <td>79.970165</td>
      <td>28.614496</td>
      <td>77.388992</td>
      <td>43.312602</td>
      <td>72.935459</td>
      <td>43.130707</td>
      <td>84.485774</td>
      <td>238 236 237 238 240 240 239 241 241 243 240 23...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>64.332936</td>
      <td>34.970077</td>
      <td>29.949277</td>
      <td>33.448715</td>
      <td>58.856170</td>
      <td>35.274349</td>
      <td>70.722723</td>
      <td>36.187166</td>
      <td>36.034723</td>
      <td>34.361532</td>
      <td>...</td>
      <td>55.660936</td>
      <td>56.421447</td>
      <td>76.352000</td>
      <td>35.122383</td>
      <td>76.047660</td>
      <td>46.684596</td>
      <td>70.266553</td>
      <td>45.467915</td>
      <td>85.480170</td>
      <td>219 215 204 196 204 211 212 200 180 168 178 19...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>65.057053</td>
      <td>34.909642</td>
      <td>30.903789</td>
      <td>34.909642</td>
      <td>59.412000</td>
      <td>36.320968</td>
      <td>70.984421</td>
      <td>36.320968</td>
      <td>37.678105</td>
      <td>36.320968</td>
      <td>...</td>
      <td>53.538947</td>
      <td>60.822947</td>
      <td>73.014316</td>
      <td>33.726316</td>
      <td>72.732000</td>
      <td>47.274947</td>
      <td>70.191789</td>
      <td>47.274947</td>
      <td>78.659368</td>
      <td>144 142 159 180 188 188 184 180 167 132 84 59 ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>65.225739</td>
      <td>37.261774</td>
      <td>32.023096</td>
      <td>37.261774</td>
      <td>60.003339</td>
      <td>39.127179</td>
      <td>72.314713</td>
      <td>38.380967</td>
      <td>37.618643</td>
      <td>38.754115</td>
      <td>...</td>
      <td>54.166539</td>
      <td>65.598887</td>
      <td>72.703722</td>
      <td>37.245496</td>
      <td>74.195478</td>
      <td>50.303165</td>
      <td>70.091687</td>
      <td>51.561183</td>
      <td>78.268383</td>
      <td>193 192 193 194 194 194 193 192 168 111 50 12 ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>66.725301</td>
      <td>39.621261</td>
      <td>32.244810</td>
      <td>38.042032</td>
      <td>58.565890</td>
      <td>39.621261</td>
      <td>72.515926</td>
      <td>39.884466</td>
      <td>36.982380</td>
      <td>39.094852</td>
      <td>...</td>
      <td>64.889521</td>
      <td>60.671411</td>
      <td>77.523239</td>
      <td>31.191755</td>
      <td>76.997301</td>
      <td>44.962748</td>
      <td>73.707387</td>
      <td>44.227141</td>
      <td>86.871166</td>
      <td>147 148 160 196 215 214 216 217 219 220 206 18...</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div></div></div>
</div>
<p>This will show the DataFrame with columns for each keypoint and the “Image” column containing pixel values. Let’s check how many values are present in each column and how many are missing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count non-null values in each column</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>left_eye_center_x            7039
left_eye_center_y            7039
right_eye_center_x           7036
right_eye_center_y           7036
left_eye_inner_corner_x      2271
left_eye_inner_corner_y      2271
left_eye_outer_corner_x      2267
left_eye_outer_corner_y      2267
right_eye_inner_corner_x     2268
right_eye_inner_corner_y     2268
right_eye_outer_corner_x     2268
right_eye_outer_corner_y     2268
left_eyebrow_inner_end_x     2270
left_eyebrow_inner_end_y     2270
left_eyebrow_outer_end_x     2225
left_eyebrow_outer_end_y     2225
right_eyebrow_inner_end_x    2270
right_eyebrow_inner_end_y    2270
right_eyebrow_outer_end_x    2236
right_eyebrow_outer_end_y    2236
nose_tip_x                   7049
nose_tip_y                   7049
mouth_left_corner_x          2269
mouth_left_corner_y          2269
mouth_right_corner_x         2270
mouth_right_corner_y         2270
mouth_center_top_lip_x       2275
mouth_center_top_lip_y       2275
mouth_center_bottom_lip_x    7016
mouth_center_bottom_lip_y    7016
Image                        7049
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>From this, we can see which keypoint columns have missing values. We expect some columns to have 7049 values (no missing data for those keypoints) and others to have fewer (indicating missing labels). If a column has fewer than 7049 non-null entries, the difference is the number of missing values.</p>
</section>
</section>
</section>
<section id="data-exploration">
<h2><span class="section-number">5.6. </span>Data exploration<a class="headerlink" href="#data-exploration" title="Link to this heading">#</a></h2>
<p>Before training a model, it’s important to understand the dataset. We will:</p>
<ol class="arabic simple">
<li><p>Identify how many keypoint annotations are missing.</p></li>
<li><p>Visualize a few images with their annotated keypoints to get an intuition of the task.</p></li>
</ol>
<section id="id1">
<h3><span class="section-number">5.6.1. </span>Missing Values<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>We already counted non-null values. Let’s quantify missing data more directly:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check total missing values per column</span>
<span class="n">missing_counts</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing values per column:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">missing_counts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Missing values per column:
left_eye_center_x              10
left_eye_center_y              10
right_eye_center_x             13
right_eye_center_y             13
left_eye_inner_corner_x      4778
left_eye_inner_corner_y      4778
left_eye_outer_corner_x      4782
left_eye_outer_corner_y      4782
right_eye_inner_corner_x     4781
right_eye_inner_corner_y     4781
right_eye_outer_corner_x     4781
right_eye_outer_corner_y     4781
left_eyebrow_inner_end_x     4779
left_eyebrow_inner_end_y     4779
left_eyebrow_outer_end_x     4824
left_eyebrow_outer_end_y     4824
right_eyebrow_inner_end_x    4779
right_eyebrow_inner_end_y    4779
right_eyebrow_outer_end_x    4813
right_eyebrow_outer_end_y    4813
nose_tip_x                      0
nose_tip_y                      0
mouth_left_corner_x          4780
mouth_left_corner_y          4780
mouth_right_corner_x         4779
mouth_right_corner_y         4779
mouth_center_top_lip_x       4774
mouth_center_top_lip_y       4774
mouth_center_bottom_lip_x      33
mouth_center_bottom_lip_y      33
Image                           0
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>You should see that some keypoint columns (e.g., <code class="docutils literal notranslate"><span class="pre">left_eye_center_x</span></code>) have very few missing values, while others (e.g., some mouth or eyebrow points) have thousands of missing entries. In fact, only 2,140 images have <strong>all</strong> 15 keypoints labeled, meaning the remainder have some missing points. We will handle this in preprocessing by removing incomplete rows.</p>
</section>
<section id="sample-visualization">
<h3><span class="section-number">5.6.2. </span>Sample visualization<a class="headerlink" href="#sample-visualization" title="Link to this heading">#</a></h3>
<p>Let’s visualize some of the images with their keypoints to understand the data. We will pick a few examples (ensuring they have no missing keypoints) and plot them in a grid.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_complete</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of complete cases (no missing keypoints):&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_complete</span><span class="p">))</span>

<span class="n">sample_images</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="s1">&#39;Image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">sample_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">img_str</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">)</span> <span class="k">for</span> <span class="n">img_str</span> <span class="ow">in</span> <span class="n">sample_images</span><span class="p">]</span>
<span class="n">sample_keypoints</span> <span class="o">=</span> <span class="n">df_complete</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">9</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># first 30 columns are keypoints</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="c1"># Plot keypoints as red dots</span>
    <span class="n">kp</span> <span class="o">=</span> <span class="n">sample_keypoints</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">kp</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">kp</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of complete cases (no missing keypoints): 2140
</pre></div>
</div>
<img alt="_images/c84d9d38a77a5d2cc3efaeb53ed41463a0ef89e4571897350f3310b6dbe2e290.png" src="_images/c84d9d38a77a5d2cc3efaeb53ed41463a0ef89e4571897350f3310b6dbe2e290.png" />
</div>
</div>
<p>We see 9 face images with red dots marking the locations of eyes, nose, mouth, etc. This visual check helps verify that the keypoints line up with facial features (for instance, dots around the eyes, nose, and mouth).</p>
</section>
</section>
<section id="data-preprocessing">
<h2><span class="section-number">5.7. </span>Data preprocessing<a class="headerlink" href="#data-preprocessing" title="Link to this heading">#</a></h2>
<p>Next, we need to prepare the data for training a PyTorch model. This involves:</p>
<ol class="arabic simple">
<li><p><strong>Handling missing keypoint values</strong>: We’ll simplify by using only the images that have all 15 keypoints labeled.</p></li>
<li><p><strong>Converting the image data</strong> from strings to numeric arrays.</p></li>
<li><p><strong>Normalizing</strong> the pixel values (scaling them to <span class="math notranslate nohighlight">\([0,1]\)</span>) by dividing by 255.</p></li>
<li><p><strong>Reshaping</strong> the images to the proper format (<span class="math notranslate nohighlight">\( (N, 1, 96, 96) \)</span> for a single-channel image).</p></li>
<li><p><strong>Preparing the keypoint coordinates</strong> array of shape (<span class="math notranslate nohighlight">\( N, 30 \)</span>). Each sample has 30 target values: 15 <span class="math notranslate nohighlight">\( x \)</span>-coordinates and 15 <span class="math notranslate nohighlight">\( y \)</span>-coordinates.</p></li>
</ol>
<p>We encourage you to try at home to use more sophisticated data augmentation strategies or partial labeling approaches, but we’ll keep things simple here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Drop rows with missing values</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Remaining training samples after dropping missing:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>

<span class="c1"># 2. Convert the &#39;Image&#39; column from strings to numpy arrays of shape (96,96)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="c1"># 3. Normalize pixel values to [0,1]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">img</span><span class="p">:</span> <span class="n">img</span><span class="o">/</span><span class="mf">255.0</span><span class="p">)</span>

<span class="c1"># 4. Convert list of image arrays to a 4D numpy array for model input</span>
<span class="n">X_fcn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>  <span class="c1"># shape (N, 9216)</span>
<span class="n">X_cnn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (N, 1, 96, 96)</span>

<span class="c1"># 5. Prepare keypoint targets as a numpy array</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># all columns except the &#39;Image&#39; column</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_fcn shape:&quot;</span><span class="p">,</span> <span class="n">X_fcn</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;y shape:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X_cnn shape:&quot;</span><span class="p">,</span> <span class="n">X_cnn</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;y shape:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Remaining training samples after dropping missing: 2140
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X_fcn shape: (2140, 9216) y shape: (2140, 30)
X_cnn shape: (2140, 1, 96, 96) y shape: (2140, 30)
</pre></div>
</div>
</div>
</div>
</section>
<section id="fully-connected-neural-network-fcn">
<h2><span class="section-number">5.8. </span>Fully connected neural network (FCN)<a class="headerlink" href="#fully-connected-neural-network-fcn" title="Link to this heading">#</a></h2>
<section id="fcn-architecture">
<h3><span class="section-number">5.8.1. </span>FCN architecture<a class="headerlink" href="#fcn-architecture" title="Link to this heading">#</a></h3>
<p>We create a <strong>Fully Connected Neural Network (FCN)</strong> using PyTorch to regress the 30 keypoint coordinates <span class="math notranslate nohighlight">\((x, y)\)</span> directly from flattened grayscale images (of size <span class="math notranslate nohighlight">\(96 \times 96 = 9216\)</span> pixels). Feel free to adjust the hidden layer sizes and dropout probabilities based on your experimentation.<br></p>
<p>The architecture of our FCN is as follows:</p>
<ul class="simple">
<li><p><strong>Fully Connected Layer 1:</strong></p>
<ul>
<li><p>Input: 9216 features (flattened image)</p></li>
<li><p>Output: 1024 neurons</p></li>
<li><p>Activation: ReLU</p></li>
<li><p>Dropout: 0.3 probability (to reduce overfitting)</p></li>
</ul>
</li>
<li><p><strong>Fully Connected Layer 2:</strong></p>
<ul>
<li><p>Input: 1024 neurons</p></li>
<li><p>Output: 512 neurons</p></li>
<li><p>Activation: ReLU</p></li>
<li><p>Dropout: 0.3 probability</p></li>
</ul>
</li>
<li><p><strong>Output Layer:</strong></p>
<ul>
<li><p>Input: 512 neurons</p></li>
<li><p>Output: 30 neurons (coordinates for 15 keypoints)</p></li>
<li><p>Linear activation (no final nonlinearity, since this is a regression output)</p></li>
</ul>
</li>
</ul>
<p>This FCN is trained using the <strong>Mean Squared Error (MSE)</strong> loss function to predict the <span class="math notranslate nohighlight">\((x, y)\)</span> coordinates of 15 facial keypoints from the flattened images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">KeypointFCN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">KeypointFCN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># We have 96*96 = 9216 input features per image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">96</span><span class="o">*</span><span class="mi">96</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>  <span class="c1"># 30 = (x,y) for 15 keypoints</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x shape: (batch_size, 9216) </span>
        <span class="c1"># (If x is not already flattened, do x = x.view(x.size(0), -1))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="split-the-flattened-dataset-for-training-validation">
<h3><span class="section-number">5.8.2. </span>Split the Flattened Dataset for Training/Validation<a class="headerlink" href="#split-the-flattened-dataset-for-training-validation" title="Link to this heading">#</a></h3>
<p>We already have <span class="math notranslate nohighlight">\(X_{fcn}\)</span> of shape <span class="math notranslate nohighlight">\((N, 9216)\)</span> and <span class="math notranslate nohighlight">\(y\)</span> of shape <span class="math notranslate nohighlight">\((N, 30)\)</span>. We split them into training and validation sets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># 90/10 train-validation split using X_fcn</span>
<span class="n">X_train_fcn</span><span class="p">,</span> <span class="n">X_val_fcn</span><span class="p">,</span> <span class="n">y_train_fcn</span><span class="p">,</span> <span class="n">y_val_fcn</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_fcn</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training samples (FCN):&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train_fcn</span><span class="p">),</span> 
      <span class="s2">&quot;Validation samples (FCN):&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_val_fcn</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training samples (FCN): 1926 Validation samples (FCN): 214
</pre></div>
</div>
</div>
</div>
</section>
<section id="create-pytorch-datasets-and-dataloaders">
<h3><span class="section-number">5.8.3. </span>Create PyTorch Datasets and DataLoaders<a class="headerlink" href="#create-pytorch-datasets-and-dataloaders" title="Link to this heading">#</a></h3>
<p>We’ll create TensorDatasets from the NumPy arrays, then wrap them in DataLoaders for batching and shuffling. Notice that we <strong>did not</strong> reshape the input for the FCN version.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset_fcn</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_fcn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>  <span class="c1"># shape: (batch_size, 9216)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_fcn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># shape: (batch_size, 30)</span>
<span class="p">)</span>
<span class="n">val_dataset_fcn</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_val_fcn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_val_fcn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">train_loader_fcn</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset_fcn</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">g</span><span class="p">)</span>
<span class="n">val_loader_fcn</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset_fcn</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="instantiate-the-fcn-model-define-criterion-and-the-optimizer">
<h3><span class="section-number">5.8.4. </span>Instantiate the FCN Model, define criterion and the optimizer<a class="headerlink" href="#instantiate-the-fcn-model-define-criterion-and-the-optimizer" title="Link to this heading">#</a></h3>
<p>We use an MSE loss since we’re doing keypoint regression. We use the Adam optimiser in this exercise but you can experiment with any optimizer you like (Adam, SGD, etc.):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchsummary</span><span class="w"> </span><span class="kn">import</span> <span class="n">summary</span>
<span class="n">fcn_model</span> <span class="o">=</span> <span class="n">KeypointFCN</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">summary</span><span class="p">(</span><span class="n">fcn_model</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">X_train_fcn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">fcn_model</span> <span class="o">=</span> <span class="n">fcn_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion_fcn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>  
<span class="n">optimizer_fcn</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">fcn_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                 [-1, 1024]       9,438,208
           Dropout-2                 [-1, 1024]               0
            Linear-3                  [-1, 512]         524,800
           Dropout-4                  [-1, 512]               0
            Linear-5                   [-1, 30]          15,390
================================================================
Total params: 9,978,398
Trainable params: 9,978,398
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.04
Forward/backward pass size (MB): 0.02
Params size (MB): 38.06
Estimated Total Size (MB): 38.12
----------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-with-ongoing-evaluation-of-the-validation-error">
<h3><span class="section-number">5.8.5. </span>Training with ongoing evaluation of the validation error<a class="headerlink" href="#training-with-ongoing-evaluation-of-the-validation-error" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="p">(</span><span class="n">pbar</span><span class="o">:=</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">))):</span>
    <span class="c1"># --- Training ---</span>
    <span class="n">fcn_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_keypoints</span> <span class="ow">in</span> <span class="n">train_loader_fcn</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">fcn_model</span><span class="p">(</span><span class="n">batch_images</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion_fcn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch_keypoints</span><span class="p">)</span>

        <span class="n">optimizer_fcn</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_fcn</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">batch_images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader_fcn</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># --- Validation ---</span>
    <span class="n">fcn_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_keypoints</span> <span class="ow">in</span> <span class="n">val_loader_fcn</span><span class="p">:</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">fcn_model</span><span class="p">(</span><span class="n">batch_images</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion_fcn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">batch_keypoints</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">batch_images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader_fcn</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> - Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> - Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "105f70bf4c0b4978b360b80043b0756c"}</script></div>
</div>
</section>
<section id="evaluate-on-validation-set">
<h3><span class="section-number">5.8.6. </span>Evaluate on validation set<a class="headerlink" href="#evaluate-on-validation-set" title="Link to this heading">#</a></h3>
<p>After the training completes, we can compute the validation set predictions and compute appropriate metrics to estimate the performance of the fully connected neural network model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fcn_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">val_preds_fcn</span> <span class="o">=</span> <span class="n">fcn_model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">X_val_fcn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
<span class="n">val_truth_fcn</span> <span class="o">=</span> <span class="n">y_val_fcn</span>
<span class="n">mse_val_fcn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">val_preds_fcn</span> <span class="o">-</span> <span class="n">val_truth_fcn</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">rmse_val_fcn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_val_fcn</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation RMSE (FCN): </span><span class="si">{</span><span class="n">rmse_val_fcn</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> pixels&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation RMSE (FCN): 10.094 pixels
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="convolutional-neural-network">
<h2><span class="section-number">5.9. </span>Convolutional neural network<a class="headerlink" href="#convolutional-neural-network" title="Link to this heading">#</a></h2>
<p>We will create a Convolutional Neural Network (CNN) to <strong>regress</strong> the 30 keypoint coordinates from the input image. CNNs are highly effective in image analysis as they can automatically learn spatial hierarchies of features from images – from low-level edges to high-level shapes – which makes them well-suited for detecting patterns like facial features.<br></p>
<p>The architecture of our CNN will be as follows:</p>
<ol class="arabic simple">
<li><p><strong>Conv Layer 1</strong>: 1 input channel (grayscale) -&gt; 32 filters, kernel size 3x3, activation ReLU, followed by Max Pooling (2x2).</p></li>
<li><p><strong>Conv Layer 2</strong>: 32 -&gt; 64 filters, 3x3, ReLU, followed by Max Pooling (2x2).</p></li>
<li><p><strong>Conv Layer 3</strong>: 64 -&gt; 128 filters, 3x3, ReLU, followed by Max Pooling (2x2).</p></li>
<li><p><strong>Flatten</strong>: Flatten the feature maps into a vector.</p></li>
<li><p><strong>Fully Connected 1</strong>: 256 neurons, ReLU, with Dropout (to reduce overfitting).</p></li>
<li><p><strong>Fully Connected 2</strong>: 128 neurons, ReLU, with Dropout.</p></li>
<li><p><strong>Output Layer</strong>: 30 outputs (the <span class="math notranslate nohighlight">\( x,y \)</span> coordinates for 15 keypoints), linear activation (no final nonlinearity, since this is a regression output).</p></li>
</ol>
<p>Dropout layers will help regularize the network by randomly dropping a fraction of neurons during training, which can improve generalization. We expect the CNN to learn to detect facial features through the convolutional layers (which capture local patterns like edges, corners of eyes/mouth, etc.), and the fully connected layers will combine these to predict the precise coordinates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">KeypointCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">KeypointCNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Convolutional layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>   <span class="c1"># 96x96 -&gt; 94x94 (then 47x47 after pool)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># 47x47 -&gt; 45x45 (then 22x22 after pool)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># 22x22 -&gt; 20x20 (then 10x10 after pool)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Dropout layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>

        <span class="c1"># Fully connected layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>  <span class="c1"># 128 feature maps * 10 * 10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>  <span class="c1"># 30 outputs (x,y for 15 keypoints)</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Three conv layers with ReLU and pooling</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

        <span class="c1"># Flatten</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Fully connected layers with dropout and ReLU</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-the-model">
<h2><span class="section-number">5.10. </span>Training the model<a class="headerlink" href="#training-the-model" title="Link to this heading">#</a></h2>
<p>Now, let’s train the model on our training data and monitor its performance on the validation set.</p>
<ul class="simple">
<li><p><strong>Data Loaders</strong>: We’ll use PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> to batch and shuffle the data for training and to batch the validation data.</p></li>
<li><p><strong>Loss Function</strong>: This is a regression problem (predicting continuous coordinate values), so a common choice is <strong>Mean Squared Error</strong> (<code class="docutils literal notranslate"><span class="pre">nn.MSELoss</span></code>) in PyTorch.</p></li>
<li><p><strong>Optimizer</strong>: We’ll use <strong>Adam</strong> for efficient stochastic gradient descent.</p></li>
<li><p><strong>Training Loop</strong>: We’ll train for a number of epochs (iterations over the whole training set). In each epoch:</p>
<ol class="arabic simple">
<li><p>Set the model to training mode.</p></li>
<li><p>Loop over mini-batches from the training loader.</p></li>
<li><p>For each batch, do a forward pass to get predictions, compute the loss, do a backward pass to compute gradients, and update weights.</p></li>
<li><p>Evaluate the model on the validation set after each epoch to track performance.</p></li>
</ol>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># We&#39;ll do a 90/10 train-validation split</span>
<span class="n">X_train_cnn</span><span class="p">,</span> <span class="n">X_val_cnn</span><span class="p">,</span> <span class="n">y_train_cnn</span><span class="p">,</span> <span class="n">y_val_cnn</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_cnn</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training samples:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train_cnn</span><span class="p">),</span> <span class="s2">&quot;Validation samples:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_val_cnn</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training samples: 1926 Validation samples: 214
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create TensorDatasets for train and validation</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_cnn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_cnn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_val_cnn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_val_cnn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

<span class="c1"># DataLoader for batching</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">g</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cnn_model</span> <span class="o">=</span> <span class="n">KeypointCNN</span><span class="p">()</span>
<span class="n">summary</span><span class="p">(</span><span class="n">cnn_model</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">X_train_cnn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">cnn_model</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 94, 94]             320
         MaxPool2d-2           [-1, 32, 47, 47]               0
            Conv2d-3           [-1, 64, 45, 45]          18,496
         MaxPool2d-4           [-1, 64, 22, 22]               0
            Conv2d-5          [-1, 128, 20, 20]          73,856
         MaxPool2d-6          [-1, 128, 10, 10]               0
            Linear-7                  [-1, 256]       3,277,056
           Dropout-8                  [-1, 256]               0
            Linear-9                  [-1, 128]          32,896
          Dropout-10                  [-1, 128]               0
           Linear-11                   [-1, 30]           3,870
================================================================
Total params: 3,406,494
Trainable params: 3,406,494
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.04
Forward/backward pass size (MB): 4.42
Params size (MB): 12.99
Estimated Total Size (MB): 17.45
----------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>  <span class="c1"># Mean Squared Error loss</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">cnn_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="p">(</span><span class="n">pbar</span><span class="o">:=</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">))):</span>
    <span class="n">cnn_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_keypoints</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">batch_images</span>
        <span class="n">keypoints</span> <span class="o">=</span> <span class="n">batch_keypoints</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">keypoints</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">cnn_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_keypoints</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">batch_images</span>
            <span class="n">keypoints</span> <span class="o">=</span> <span class="n">batch_keypoints</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">keypoints</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> - Training Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> - Validation Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "45927141ffda465bab0c91db5d6e2f13"}</script></div>
</div>
</section>
<section id="evaluation-and-results">
<h2><span class="section-number">5.11. </span>Evaluation and results<a class="headerlink" href="#evaluation-and-results" title="Link to this heading">#</a></h2>
<p>After training, we’ll evaluate the model’s performance. One common metric for this task is <strong>Root Mean Squared Error (RMSE)</strong> of the keypoint predictions. RMSE is the square root of MSE, giving an error in the same units as the coordinates (pixels). We will calculate RMSE on the validation set.</p>
<p>For instance, an RMSE of 4.0 would mean on average the predictions are about 4 pixels away from the true keypoint positions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Switch to evaluation mode</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Predict on the entire validation set</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">val_preds</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">X_val_cnn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Compute RMSE on validation set</span>
<span class="n">val_truth</span> <span class="o">=</span> <span class="n">y_val_cnn</span>  <span class="c1"># actual keypoints</span>
<span class="n">mse_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">val_preds</span> <span class="o">-</span> <span class="n">val_truth</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">rmse_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation RMSE: </span><span class="si">{</span><span class="n">rmse_val</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> pixels&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation RMSE: 3.455 pixels
</pre></div>
</div>
</div>
</div>
<section id="visualizing-predictions">
<h3><span class="section-number">5.11.1. </span>Visualizing predictions<a class="headerlink" href="#visualizing-predictions" title="Link to this heading">#</a></h3>
<p>Finally, let’s visualize some predictions to see how the model is performing. We’ll take a few images from the validation set (which the model hasn’t seen during training) and plot the image with:</p>
<ul class="simple">
<li><p>The <strong>ground truth</strong> keypoints (in green)</p></li>
<li><p>The <strong>predicted</strong> keypoints (in red)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Choose a few samples from validation to visualize</span>
<span class="n">num_samples_to_show</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples_to_show</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples_to_show</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">X_val_fcn</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">)</span>
    <span class="n">true_kp</span> <span class="o">=</span> <span class="n">y_val_fcn</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">cnn_pred_kp</span> <span class="o">=</span> <span class="n">val_preds</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">fcn_pred_kp</span> <span class="o">=</span> <span class="n">fcn_model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_val_fcn</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="o">*</span><span class="mi">96</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="c1"># Plot true keypoints in green</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">true_kp</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">true_kp</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
    <span class="c1"># Plot predicted keypoints in red</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fcn_pred_kp</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">fcn_pred_kp</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Pred&#39;</span><span class="p">)</span>
    <span class="c1"># Plot predicted keypoints in red</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cnn_pred_kp</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">cnn_pred_kp</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Pred&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d80274cc65a085c3764af995c5c83a9b23e521e01b0820df8f94922e611bc31f.png" src="_images/d80274cc65a085c3764af995c5c83a9b23e521e01b0820df8f94922e611bc31f.png" />
</div>
</div>
<p>In the displayed images, <strong>green</strong> dots should mark the actual keypoint positions and <strong>red</strong> x’s mark the model’s predicted positions. Ideally, they will be close for most points. You might notice the model does well on prominent features like the eye centers or nose tip, but could be less accurate on some others, especially if the network hasn’t fully converged or if data is limited. A deeper network or additional data augmentation could further improve performance.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="03.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Data preprocessing and tree-based models</p>
      </div>
    </a>
    <a class="right-next"
       href="05.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Ensembles of models and feature selection</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-neural-networks">5.1. Introduction to Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-for-neural-networks">5.1.1. Data Preprocessing for Neural Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normalization-and-standardization">5.1.1.1. Normalization and Standardization</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#input-data-shaping">5.1.1.2. Input Data Shaping</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feed-forward-neural-networks-mlps">5.1.2. Feed-Forward Neural Networks (MLPs)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-and-notation">5.1.2.1. Architecture and Notation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">5.1.2.2. Activation Functions</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-function-and-matrix-based-back-propagation">5.1.3. Cost function and matrix-based Back-Propagation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squared-errors-sse">5.1.3.1. Sum of Squared Errors (SSE)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent-update">5.1.3.2. Gradient Descent Update</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#back-propagation-algorithm-2">5.1.3.3. Back-Propagation (Algorithm 2)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-networks-cnns">5.1.4. Convolutional Neural Networks (CNNs)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#convolution-operation">5.1.4.1. Convolution Operation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling-layers">5.1.4.2. Pooling Layers</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-and-cross-validation">5.1.5. Overfitting and Cross-Validation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-phenomenon">5.1.5.1. Overfitting Phenomenon</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#detection-and-mitigation">5.1.5.2. Detection and Mitigation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-aspects-model-saving-and-loading-in-pytorch">5.1.6. Practical Aspects: Model Saving and Loading in PyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#complete-example-of-a-cnn-for-regression">5.1.7. Complete example of a CNN for Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-pytorch-tensors">5.2. Introduction to PyTorch tensors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-tensors">5.2.1. Creating Tensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-tensor-operations">5.2.2. Basic Tensor Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#arithmetic-operations">5.2.2.1. Arithmetic operations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing-and-slicing">5.2.2.2. Indexing and slicing</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autograd-and-gradients">5.2.3. Autograd and Gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-tensor-functions">5.2.4. Advanced Tensor Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">5.2.4.1. Broadcasting</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#device-management-cpu-vs-gpu">5.2.4.2. Device Management (CPU vs GPU)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#in-place-operations">5.2.4.3. In-place Operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">5.3. Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-symbolic-and-automatic-differentiation-in-a-simple-feedforward-neural-network">5.3.1. Comparison of symbolic and automatic differentiation in a simple feedforward neural network</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-setup">5.4. Problem setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-implementation">5.5. PyTorch implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-activation-function-and-its-derivative">5.5.1. Define the activation function and its derivative</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-working-variables">5.5.2. Define the working variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-pass">5.5.3. Forward pass</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#symbolic-gradients">5.5.4. Symbolic gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-differentiation">5.5.5. Automatic differentiation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-symbolic-and-automatic-differentiation">5.5.6. Comparison of symbolic and automatic differentiation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#facial-keypoints-detection-with-pytorch-fcn-and-cnn-architectures">5.5.7. Facial keypoints detection with PyTorch FCN and CNN architectures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-overview">5.5.8. Dataset overview</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-format">5.5.8.1. Data format</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#missing-values">5.5.8.2. Missing values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-exploration">5.6. Data exploration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">5.6.1. Missing Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-visualization">5.6.2. Sample visualization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">5.7. Data preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fully-connected-neural-network-fcn">5.8. Fully connected neural network (FCN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fcn-architecture">5.8.1. FCN architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#split-the-flattened-dataset-for-training-validation">5.8.2. Split the Flattened Dataset for Training/Validation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-pytorch-datasets-and-dataloaders">5.8.3. Create PyTorch Datasets and DataLoaders</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instantiate-the-fcn-model-define-criterion-and-the-optimizer">5.8.4. Instantiate the FCN Model, define criterion and the optimizer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-with-ongoing-evaluation-of-the-validation-error">5.8.5. Training with ongoing evaluation of the validation error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-on-validation-set">5.8.6. Evaluate on validation set</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-network">5.9. Convolutional neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-model">5.10. Training the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-and-results">5.11. Evaluation and results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-predictions">5.11.1. Visualizing predictions</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Tribel Pascal, Simar Cédric, Bontempi Gianluca
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  This is the practicals handbook for the course INFO-F422 - Statistical Foundations of Machine Learning. This is intended to be used alongside the <a href='https://www.researchgate.net/publication/242692234_Statistical_foundations_of_machine_learning_the_handbook'> theoretical handbook</a>.
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>