
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Introduction to probabilistic methods and Monte Carlo simulations &#8212; Statistical Foundations of Machine Learning - Practicals handbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '01';</script>
    <link rel="icon" href="_static/sfml.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Linear Models" href="02.html" />
    <link rel="prev" title="1. Introduction" href="introduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="frontpage.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/sfml.png" class="logo__image only-light" alt="Statistical Foundations of Machine Learning - Practicals handbook - Home"/>
    <script>document.write(`<img src="_static/sfml.png" class="logo__image only-dark" alt="Statistical Foundations of Machine Learning - Practicals handbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="frontpage.html">
                    Home
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Introduction</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Introduction to probabilistic methods and Monte Carlo simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="02.html">3. Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="03.html">4. Data preprocessing and tree-based models</a></li>
<li class="toctree-l1"><a class="reference internal" href="04.html">5. Neural Networks for Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="05.html">6. Ensembles of models and feature selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="06.html">7. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusion.html">8. Conclusion</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/01.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to probabilistic methods and Monte Carlo simulations</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#necessary-libraries">2.1. Necessary libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-numpy">2.2. Introduction to <code class="docutils literal notranslate"><span class="pre">NumPy</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#manipulation-of-numpy-arrays">2.2.1. Manipulation of <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> arrays</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-of-creation-of-arrays">2.3. Example of creation of arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-operations">2.4. Basic operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-foundations">2.5. Probabilistic Foundations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-and-variance">2.5.1. Expectation and Variance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-probability-distributions">2.5.2. Common Probability Distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#uniform-distribution">2.5.2.1. Uniform Distribution</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normal-gaussian-distribution">2.5.2.2. Normal (Gaussian) Distribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-the-numpy-random-module">2.6. Introduction to the <code class="docutils literal notranslate"><span class="pre">numpy.random</span></code> module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reproducibility-of-results">2.6.1. Reproducibility of results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#available-distributions">2.6.2. Available distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling">2.6.3. Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-analysis">2.6.4. Statistical analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-histogram">2.6.5. Exercise: Histogram</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">2.6.5.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-simulation">2.7. Monte Carlo Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-integration">2.7.1. Monte Carlo Integration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-integral-estimation">2.7.2. Exercise: Integral estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.7.2.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-probability-estimation">2.7.3. Exercise: Probability estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.7.3.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-monte-carlo-approximation-of-parameters">2.7.4. Exercise: Monte Carlo approximation of parameters</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.7.4.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-absolute-value">2.7.5. Exercise: Absolute value</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.7.5.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-expected-value-for-any-function">2.7.6. Exercise: Expected value for any function</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.7.6.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-variance-of-uniform-random-variable">2.7.7. Exercise: Variance of uniform random variable</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.7.7.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-covariance-of-a-multiple-of-a-random-variable">2.7.8. Exercise: Covariance of a multiple of a random variable</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">2.7.8.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-gaussian-distributions">2.8. Multivariate Gaussian distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2d-monte-carlo-simulation">2.8.1. Exercise: 2D Monte Carlo Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">2.8.1.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">2.8.2. Exercise:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.8.2.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-trivariate-gaussian-data">2.8.3. Exercise: Trivariate Gaussian data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.8.3.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-partial-correlation">2.8.4. Exercise: Partial correlation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">2.8.4.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimization">2.9. Minimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-minimization">2.9.1. Exercise: Minimization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">2.9.1.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixture-of-gaussians">2.10. Mixture of Gaussians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">2.11. Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-probabilistic-methods-and-monte-carlo-simulations">
<h1><span class="section-number">2. </span>Introduction to probabilistic methods and Monte Carlo simulations<a class="headerlink" href="#introduction-to-probabilistic-methods-and-monte-carlo-simulations" title="Link to this heading">#</a></h1>
<p>Probabilistic methods and Monte Carlo simulations represent fundamental techniques in computational mathematics, offering powerful approaches to solve complex problems that would be analytically intractable. These methods have found widespread applications across diverse domains including statistical physics, financial mathematics, quantum mechanics, machine learning, and computational biology. The course of INFO-F305 - <em>Modélisation et Simulation</em> proposes a good introduction to Monte Carlo simulations.</p>
<p>This chapter introduces the fundamental concepts, tools, and techniques of probabilistic methods with a particular focus on Monte Carlo simulations. We will explore how to generate random variables from different distributions, estimate integrals, solve optimization problems, and analyze statistical properties of random processes. Throughout the chapter, we will emphasize both the theoretical foundations and practical implementations using Python and its scientific computing ecosystem.</p>
<p>Note, the proper understanding of this set of methods is extremely important for having a good approach of many modern Machine Learning problems. Real-life data collection can indeed, in many cases, be modelized by a Monte Carlo simulation, and the statistical/probabilistic study of the simulated problem often offers valuable insights about the real-life dynamics.</p>
<p>By the end of this chapter, you will have developed a solid understanding of how to apply Monte Carlo techniques to solve a variety of mathematical and statistical problems, setting the foundation for more advanced applications in subsequent chapters.</p>
<section id="necessary-libraries">
<h2><span class="section-number">2.1. </span>Necessary libraries<a class="headerlink" href="#necessary-libraries" title="Link to this heading">#</a></h2>
<p>To run this practical work, the following libraries must be installed:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">NumPy</span></code>: Vector and matrix manipulation, random number generation,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SciPy</span></code>: For advanced numerical statistical methods,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Pandas</span></code>: For advanced data manipulation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Matplotlib</span></code>, <code class="docutils literal notranslate"><span class="pre">seaborn</span></code>: For data visualization,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tqdm</span></code>: For beautiful loading bars.</p></li>
</ul>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>If the libraries are already installed, you can skip this step.</p>
</aside>
<p>If you are using Jupyter Notebook, you can install the dependencies directly by running the cell below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!pip install numpy matplotlib tqdm pandas seaborn  numpyarray_to_latex</span>
</pre></div>
</div>
</div>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>This <code class="docutils literal notranslate"><span class="pre">pprint</span></code> function will allow to render the output of some codes in LaTeX, such as the vectors and the matrices. Remark that calling this function only works in <code class="docutils literal notranslate"><span class="pre">Jupyter</span></code>. If you code in plain <code class="docutils literal notranslate"><span class="pre">Python</span></code>, you should rather use the default <code class="docutils literal notranslate"><span class="pre">str</span></code> and <code class="docutils literal notranslate"><span class="pre">print</span></code> functions.</p>
</aside>
<p>We make some imports and define a <code class="docutils literal notranslate"><span class="pre">pprint</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpyarray_to_latex.jupyter</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_ltx</span>
<span class="k">def</span><span class="w"> </span><span class="nf">pprint</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">+=</span> <span class="n">to_ltx</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">brackets</span><span class="o">=</span><span class="s1">&#39;[]&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">+=</span> <span class="n">i</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Math</span><span class="p">(</span><span class="n">res</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="introduction-to-numpy">
<h2><span class="section-number">2.2. </span>Introduction to <code class="docutils literal notranslate"><span class="pre">NumPy</span></code><a class="headerlink" href="#introduction-to-numpy" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">NumPy</span></code> is an essential library for scientific computations in Python. It offers:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ndarray</span></code> objects to represent multi-dimensional arrays.</p></li>
<li><p>A collection of mathematical functions to perform fast operations on these arrays.</p></li>
</ul>
<section id="manipulation-of-numpy-arrays">
<h3><span class="section-number">2.2.1. </span>Manipulation of <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> arrays<a class="headerlink" href="#manipulation-of-numpy-arrays" title="Link to this heading">#</a></h3>
<p>Here are some examples for creating and manipulating <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> arrays:</p>
</section>
</section>
<section id="example-of-creation-of-arrays">
<h2><span class="section-number">2.3. </span>Example of creation of arrays<a class="headerlink" href="#example-of-creation-of-arrays" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">v3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;v_0=&quot;</span><span class="p">,</span> <span class="n">v0</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;v_1=&quot;</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;v_2=&quot;</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;v_3=&quot;</span><span class="p">,</span> <span class="n">v3</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;M=&quot;</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle v_0=\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle v_1=\left[
\begin{array}{}
  0.0000 &amp;  0.4000 &amp;  0.8000 &amp;  1.2000 &amp;  1.6000 &amp;  2.0000 &amp;  2.4000 &amp;  2.8000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle v_2=\left[
\begin{array}{}
  0.0000 &amp;  0.5556 &amp;  1.1111 &amp;  1.6667 &amp;  2.2222 &amp;  2.7778 &amp;  3.3333 &amp;  3.8889 &amp;  4.4444 &amp;  5.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle v_3=\left[
\begin{array}{}
  0.0000 &amp;  0.2222 &amp;  0.4444 &amp;  0.6667 &amp;  0.8889 &amp;  1.1111 &amp;  1.3333 &amp;  1.5556 &amp;  1.7778 &amp;  2.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle M=\left[
\begin{array}{}
  1.0000 &amp;  2.0000 &amp;  3.0000\\
  4.0000 &amp;  5.0000 &amp;  6.0000\\
  7.0000 &amp;  8.0000 &amp;  9.0000
\end{array}
\right]\end{split}\]</div>
</div>
</div>
</section>
<section id="basic-operations">
<h2><span class="section-number">2.4. </span>Basic operations<a class="headerlink" href="#basic-operations" title="Link to this heading">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Remark, those functions (and basically, most of the <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> functions) are <em>vectorial</em>. This means that they are applied in parallel on all the components of the vectors. Later on, when we will present the <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> library, we will show how this parallelisation can benefit from using specialized hardware, such as the GPU’s.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v0</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sum of v0 components:&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average value in M:&quot;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scalar product of v2 and v3:&quot;</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sum of v0 components: 6
Average value in M: 5.0
Scalar product of v2 and v3: 35.18518518518518
</pre></div>
</div>
</div>
</div>
<p>We encourage you to consult the official <a class="reference external" href="https://numpy.org/doc/stable/"><code class="docutils literal notranslate"><span class="pre">NumPy</span></code> documentation</a> to explore its many features.
A larger introduction to <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> and <code class="docutils literal notranslate"><span class="pre">MatPlotLib</span></code> is available in the <span class="math notranslate nohighlight">\(5^{\text{th}}\)</span> practical of the course INFO-F305 - <em>Modélisation et Simulation</em>.</p>
</section>
<section id="probabilistic-foundations">
<h2><span class="section-number">2.5. </span>Probabilistic Foundations<a class="headerlink" href="#probabilistic-foundations" title="Link to this heading">#</a></h2>
<p>The course of MATH-F315 - <em>Probabilités et Statistiques</em> has presented all the necessary materials used in this chapter. This is let as reference for the formal demonstrations of the tools and theorems used here. However, we propose a small review of the most important notions that will help you understand the exercises at the end of the chapter. Remember: the exercises are not meant to make you familiar with one specific practical implementation of the techniques and tools, they are intended to make you apply some well understood and completely digested statistical and probabilistic concepts. We strongly recommend the reader to delve in depth in the theoretical concepts related to the exercises.</p>
<section id="expectation-and-variance">
<h3><span class="section-number">2.5.1. </span>Expectation and Variance<a class="headerlink" href="#expectation-and-variance" title="Link to this heading">#</a></h3>
<p>The expectation of a random variable <span class="math notranslate nohighlight">\(\mathbf X\)</span>, denoted <span class="math notranslate nohighlight">\(E[\mathbf X]\)</span>, is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
E[\mathbf X] = \begin{cases}
    \int_{-\infty}^{\infty} x f_{\mathbf X}(x) dx &amp; \text{for continuous $\mathbf X$} \\
    \sum_{x} x p_{\mathbf X}(x) &amp; \text{for discrete $\mathbf X$}
\end{cases}
\end{split}\]</div>
<p>Statistically, the average is an unbiased estimator of the expected value. In \codeword{NumPy}, the average value in an array can be computed with the <code class="docutils literal notranslate"><span class="pre">numpy.mean</span></code> function.
The variance of <span class="math notranslate nohighlight">\(\mathbf X\)</span>, denoted <span class="math notranslate nohighlight">\(\text{Var}(\mathbf X)\)</span>, measures the dispersion around the mean:</p>
<div class="math notranslate nohighlight">
\[
\text{Var}(\mathbf X) = E[(\mathbf X - E[\mathbf X])^2] = E[\mathbf X^2] - (E[\mathbf X])^2
\]</div>
<p>The variance is the square of the standard deviation.
So, in <code class="docutils literal notranslate"><span class="pre">NumPy</span></code>, the variance of an array can be computed by squaring the result of the <code class="docutils literal notranslate"><span class="pre">numpy.std</span></code> function.
For two random variables <span class="math notranslate nohighlight">\(\mathbf X\)</span> and \mathbf <span class="math notranslate nohighlight">\(Y\)</span>, their covariance is defined as:</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}(\mathbf X, \mathbf Y) = E[(\mathbf X - E[\mathbf X])(\mathbf Y - E[\mathbf Y])] = E[\mathbf X\mathbf Y] - E[\mathbf X]E[\mathbf Y]
\]</div>
<p>In <code class="docutils literal notranslate"><span class="pre">NumPy</span></code>, the covariance between two vectors can be computed with the <code class="docutils literal notranslate"><span class="pre">numpy.cov</span></code> function.
The correlation coefficient, which measures the linear dependence between <span class="math notranslate nohighlight">\(\mathbf X\)</span> and <span class="math notranslate nohighlight">\(\mathbf Y\)</span>, is:</p>
<div class="math notranslate nohighlight">
\[
\rho_{\mathbf X,\mathbf Y} = \frac{\text{Cov}(\mathbf X, \mathbf Y)}{\sqrt{\text{Var}(\mathbf X) \cdot \text{Var}(\mathbf Y)}}
\]</div>
<p>In <code class="docutils literal notranslate"><span class="pre">NumPy</span></code>, the correlation coefficient between two vectors can be computed with the `numpy.corrcoef function.</p>
</section>
<section id="common-probability-distributions">
<h3><span class="section-number">2.5.2. </span>Common Probability Distributions<a class="headerlink" href="#common-probability-distributions" title="Link to this heading">#</a></h3>
<section id="uniform-distribution">
<h4><span class="section-number">2.5.2.1. </span>Uniform Distribution<a class="headerlink" href="#uniform-distribution" title="Link to this heading">#</a></h4>
<p>A random variable <span class="math notranslate nohighlight">\(\mathbf X\)</span> follows a uniform distribution on the interval <span class="math notranslate nohighlight">\([a, b]\)</span>, denoted <span class="math notranslate nohighlight">\(\mathbf X \sim \mathcal{U}(a, b)\)</span>, if its PDF is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    f_{\mathbf X}(x) = \begin{cases}
    \frac{1}{b - a} &amp; \text{if } x \in [a, b] \\
    0 &amp; \text{otherwise}
    \end{cases}
\end{split}\]</div>
<p>The mean and variance are <span class="math notranslate nohighlight">\(E[\mathbf X] = \frac{a + b}{2}\)</span> and <span class="math notranslate nohighlight">\(\text{Var}\mathbf (X) = \frac{(b - a)^2}{12}\)</span>, respectively.
In <code class="docutils literal notranslate"><span class="pre">NumPy</span></code>, the uniform distribution can be sampled with the <code class="docutils literal notranslate"><span class="pre">numpy.random.uniform</span></code> function.</p>
</section>
<section id="normal-gaussian-distribution">
<h4><span class="section-number">2.5.2.2. </span>Normal (Gaussian) Distribution<a class="headerlink" href="#normal-gaussian-distribution" title="Link to this heading">#</a></h4>
<p>A random variable <span class="math notranslate nohighlight">\(\mathbf X\)</span> follows a normal distribution with parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span>, denoted <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span>, if its PDF is:</p>
<div class="math notranslate nohighlight">
\[
    f_{\mathbf X}(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span> is the mean and <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the variance.
In <code class="docutils literal notranslate"><span class="pre">NumPy</span></code>, the uniform distribution can be sampled with the <code class="docutils literal notranslate"><span class="pre">numpy.random.normal</span></code> function.</p>
</section>
</section>
</section>
<section id="introduction-to-the-numpy-random-module">
<h2><span class="section-number">2.6. </span>Introduction to the <code class="docutils literal notranslate"><span class="pre">numpy.random</span></code> module<a class="headerlink" href="#introduction-to-the-numpy-random-module" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> library includes a <code class="docutils literal notranslate"><span class="pre">numpy.random</span></code> submodule dedicated to random number generation. This module offers:</p>
<ul class="simple">
<li><p>Random number generators for various distributions (uniform, normal, binomial, etc.).</p></li>
<li><p>Tools for drawing samples and manipulating random sequences.</p></li>
</ul>
<section id="reproducibility-of-results">
<h3><span class="section-number">2.6.1. </span>Reproducibility of results<a class="headerlink" href="#reproducibility-of-results" title="Link to this heading">#</a></h3>
<p>To ensure the reproducibility of simulations, it is crucial to set a random seed.</p>
<p>Example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;x=&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle x=\left[
\begin{array}{}
  0.3745 &amp;  0.9507 &amp;  0.7320 &amp;  0.5987 &amp;  0.1560
\end{array}
\right]\]</div>
</div>
</div>
</section>
<section id="available-distributions">
<h3><span class="section-number">2.6.2. </span>Available distributions<a class="headerlink" href="#available-distributions" title="Link to this heading">#</a></h3>
<p>Here are some common distributions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">numpy.random.uniform(low,</span> <span class="pre">high,</span> <span class="pre">size)</span></code> : Uniform distribution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numpy.random.normal(loc,</span> <span class="pre">scale,</span> <span class="pre">size)</span></code> : Normal (Gaussian) distribution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numpy.random.binomial(n,</span> <span class="pre">p,</span> <span class="pre">size)</span></code> : Binomial distribution.</p></li>
</ul>
</section>
<section id="sampling">
<h3><span class="section-number">2.6.3. </span>Sampling<a class="headerlink" href="#sampling" title="Link to this heading">#</a></h3>
<p>Sampling is the process of randomly selecting elements from a population. For example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">population</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;s=&quot;</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle s=\left[
\begin{array}{}
  3.0000 &amp;  3.0000 &amp;  3.0000\\
  5.0000 &amp;  4.0000 &amp;  3.0000\\
  5.0000 &amp;  2.0000 &amp;  4.0000
\end{array}
\right]\end{split}\]</div>
</div>
</div>
</section>
<section id="statistical-analysis">
<h3><span class="section-number">2.6.4. </span>Statistical analysis<a class="headerlink" href="#statistical-analysis" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Scipy</span></code> offers tools to analyse statistical distributions. As an example, if wan to get density, repartition function and quantiles of a normal distribution <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
</pre></div>
</div>
</div>
</div>
<p>The probability density function of a normal distribution is given by</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{(\frac{e^{\frac{-(x-\mu)^2}{2}}}{\sqrt{2\pi}})}{\sigma}\]</div>
<p>for <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> the mean and the standard deviation of the distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.24197072451914337
</pre></div>
</div>
</div>
</div>
<p>The quantiles can be obtained using the <code class="docutils literal notranslate"><span class="pre">ppf</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6744897501960817
</pre></div>
</div>
</div>
</div>
<p>Finally, the cumulative distribution function can be obtained with <code class="docutils literal notranslate"><span class="pre">cdf</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6914624612740131
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-histogram">
<h3><span class="section-number">2.6.5. </span>Exercise: Histogram<a class="headerlink" href="#exercise-histogram" title="Link to this heading">#</a></h3>
<p>Using the previous <code class="docutils literal notranslate"><span class="pre">pdf</span></code> function, plot the histogram of a sampled normal <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> and check that it behaves as the analytical probability density function. Show on the same graph the three quarter quantiles (0.25, 0.5, 0.75).</p>
<section id="solution">
<h4><span class="section-number">2.6.5.1. </span>Solution<a class="headerlink" href="#solution" title="Link to this heading">#</a></h4>
<p>In the following code, we sample a normal <span class="math notranslate nohighlight">\(\mathbf{N}(0, 1)\)</span>, and, using <code class="docutils literal notranslate"><span class="pre">Matplotlib</span></code>, we display the histogram of the sampled values, along the probability density function provided by <code class="docutils literal notranslate"><span class="pre">Scipy</span></code>. We also display the three first quarters using the <code class="docutils literal notranslate"><span class="pre">scipy.stats.norm.ppf</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn-v0_8-muted&#39;</span><span class="p">,</span> <span class="s1">&#39;practicals.mplstyle&#39;</span><span class="p">])</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;s=&quot;</span><span class="p">,</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]),</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle s=\left[
\begin{array}{}
 -0.6745 &amp;  0.0000 &amp;  0.6745
\end{array}
\right]\]</div>
</div>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Try changing the number of bins. What happens if it is too low ?</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_bins</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">25000</span><span class="p">,)),</span> <span class="n">bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]),</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Probability density function of a N(0, 1)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c6048ade83d7089033ebe0520d131c4d3319b69ab675f5690f6473245a9d83db.png" src="_images/c6048ade83d7089033ebe0520d131c4d3319b69ab675f5690f6473245a9d83db.png" />
</div>
</div>
</section>
</section>
</section>
<section id="monte-carlo-simulation">
<h2><span class="section-number">2.7. </span>Monte Carlo Simulation<a class="headerlink" href="#monte-carlo-simulation" title="Link to this heading">#</a></h2>
<p>The core principle of Monte Carlo methods lies in using random sampling to approximate numerical results. Rather than attempting to solve problems through analytical formulas, Monte Carlo techniques leverage the law of large numbers to estimate solutions through repeated random sampling. This approach is particularly valuable when dealing with high-dimensional spaces, complex geometries, or systems with multiple degrees of freedom. The simplest visual example, to understand the notion of Monte Carlo, is the following. You want to measure the surface of a lake. Its shape is complex, difficult to measure and to compute the area it covers. However, you can easily surround it by a square for which the side can accurately be measured. You then decide to randomly throw stones with a catapult on the square. The proportion of number of stones that fall into the lake compared to the total number of thrown stones (if the number of stones is infinite) is the same proportion as the proportion of the surface of the lake compared to the square surface. The more stone you throw, the more accurate the estimation is. This idea is close to the one used for Monte Carlo integration.</p>
<section id="monte-carlo-integration">
<h3><span class="section-number">2.7.1. </span>Monte Carlo Integration<a class="headerlink" href="#monte-carlo-integration" title="Link to this heading">#</a></h3>
<p>Consider the problem of evaluating the integral:</p>
<div class="math notranslate nohighlight">
\[
    I = \int_{\Omega} f(\mathbf{x}) d\mathbf{x}
\]</div>
<p>The Monte Carlo estimate of this integral is:</p>
<div class="math notranslate nohighlight">
\[
    \hat{I}_n = \frac{|\Omega|}{n} \sum_{i=1}^{n} f(\mathbf{X}_i)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{X}_1, \mathbf{X}_2, \dots, \mathbf{X}_n\)</span> are i.i.d. random variables uniformly distributed over <span class="math notranslate nohighlight">\(\Omega\)</span>, and <span class="math notranslate nohighlight">\(|\Omega|\)</span> is the measure (volume) of <span class="math notranslate nohighlight">\(\Omega\)</span>.
For a definite integral over <span class="math notranslate nohighlight">\([a, b]\)</span>, the Monte Carlo estimate is:</p>
<div class="math notranslate nohighlight">
\[
    \int_{a}^{b} f(x) dx \approx (b - a) \cdot \frac{1}{n} \sum_{i=1}^{n} f(X_i)
\]</div>
<p>where <span class="math notranslate nohighlight">\(X_i \sim \mathcal{U}(a, b)\)</span>.</p>
</section>
<section id="exercise-integral-estimation">
<h3><span class="section-number">2.7.2. </span>Exercise: Integral estimation<a class="headerlink" href="#exercise-integral-estimation" title="Link to this heading">#</a></h3>
<p>Implement a Monte Carlo simulation to estimate the integral of the function <span class="math notranslate nohighlight">\(f(x) = x^2\)</span> over the interval <span class="math notranslate nohighlight">\([0, 1]\)</span>.</p>
<section id="id1">
<h4><span class="section-number">2.7.2.1. </span>Solution<a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<p>The indefinite integral is given by</p>
<div class="math notranslate nohighlight">
\[\int x^2 \,dx = \frac{x^3}{3}\]</div>
<p>and therefore the definite interval is</p>
<div class="math notranslate nohighlight">
\[\int_{0}^{1} x^2 \,dx = \frac{1^3}{3} - \frac{0^3}{3} = \frac13\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_points</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">approximations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">under_curve</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
<span class="n">estimation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">under_curve</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">under_curve</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[</span><span class="n">under_curve</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Under the curve&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="o">~</span><span class="n">under_curve</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[</span><span class="o">~</span><span class="n">under_curve</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Above the curve&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Estimated integral: </span><span class="si">{</span><span class="n">estimation</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/76c52fef9e1ca87966488a66da222bbcab65bc5544ea66dba284b3b7acf69b6a.png" src="_images/76c52fef9e1ca87966488a66da222bbcab65bc5544ea66dba284b3b7acf69b6a.png" />
</div>
</div>
</section>
</section>
<section id="exercise-probability-estimation">
<h3><span class="section-number">2.7.3. </span>Exercise: Probability estimation<a class="headerlink" href="#exercise-probability-estimation" title="Link to this heading">#</a></h3>
<p>Use a normal distribution to model a random variable, with parameters <span class="math notranslate nohighlight">\(\mu = 0\)</span> and <span class="math notranslate nohighlight">\(\sigma^2 = \frac12\)</span> and calculate the probability that it takes a value in the interval <span class="math notranslate nohighlight">\([-0.25, 0.25]\)</span>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><strong>Don’t skip this part!</strong> Rather, take a sheet of paper, and understand properly every step. You should be able to redo this computation yourself without the solution. Try also changing the values: don’t worry, then, you will be able to validate your theoretical answer by the simulation.</p>
</aside>
<section id="id2">
<h4><span class="section-number">2.7.3.1. </span>Solution<a class="headerlink" href="#id2" title="Link to this heading">#</a></h4>
<p>Let us first show how to analytically compute the requested probablity.
The probability that <span class="math notranslate nohighlight">\(X\)</span> lies within the interval is given by:</p>
<div class="math notranslate nohighlight">
\[P(-0.25 \leq \mathbf X \leq 0.25) = \int_{-0.25}^{0.25} f_{\mathbf X}(x) \, dx\]</div>
<p>where the Probability Density Function <span class="math notranslate nohighlight">\(f_{\mathbf X}(x)\)</span> is:</p>
<div class="math notranslate nohighlight">
\[f_{\mathbf X}(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x - \mu)^2}{2 \sigma^2}}\]</div>
<p>In our case, <span class="math notranslate nohighlight">\(\mu = 0\)</span> and <span class="math notranslate nohighlight">\(\sigma^2 = 1/2\)</span>, so:</p>
<div class="math notranslate nohighlight">
\[f_{\mathbf X}(x) = \frac{1}{\sqrt{\pi}} e^{-2x^2}\]</div>
<p>To simplify the calculation, we convert <span class="math notranslate nohighlight">\(X\)</span> to the standard normal variable <span class="math notranslate nohighlight">\(\mathbf Z\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mathbf Z = \frac{\mathbf X - \mu}{\sigma}, \quad \text{where } \sigma = \sqrt{1/2} = \frac{\sqrt{2}}{2}\]</div>
<p>For the bounds of the interval:</p>
<div class="math notranslate nohighlight">
\[z_{-0.25} = \frac{-0.25 - 0}{\sigma} = -0.25 \cdot \frac{2}{\sqrt{2}} = -\frac{\sqrt{2}}{4}, \quad
z_{0.25} = \frac{0.25 - 0}{\sigma} = \frac{\sqrt{2}}{4}\]</div>
<p>The probability is then expressed using the repartition function <span class="math notranslate nohighlight">\(\Phi(z)\)</span> of the standard normal distribution:</p>
<div class="math notranslate nohighlight">
\[P(-0.25 \leq \mathbf X \leq 0.25) = P\left(-\frac{\sqrt{2}}{4} \leq \mathbf Z \leq \frac{\sqrt{2}}{4}\right) = \Phi\left(\frac{\sqrt{2}}{4}\right) - \Phi\left(-\frac{\sqrt{2}}{4}\right)\]</div>
<p>Using the symmetry of the standard normal distribution:</p>
<div class="math notranslate nohighlight">
\[\Phi(-z) = 1 - \Phi(z)\]</div>
<p>This simplifies to:</p>
<div class="math notranslate nohighlight">
\[P(-0.25 \leq \mathbf X \leq 0.25) = 2 \cdot \Phi\left(\frac{\sqrt{2}}{4}\right) - 1\]</div>
<p>To find <span class="math notranslate nohighlight">\(\Phi\left(\frac{\sqrt{2}}{4}\right)\)</span>, we can use values in tables. It yields:</p>
<div class="math notranslate nohighlight">
\[\frac{\sqrt{2}}{4} \approx 0.3536\]</div>
<p>From standard normal tables or software (we can use <code class="docutils literal notranslate"><span class="pre">SciPy</span></code>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span>
<span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">((</span><span class="mi">2</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6381631950841185
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[\Phi(0.3536) \approx 0.6388\]</div>
<p>Thus:</p>
<div class="math notranslate nohighlight">
\[P(-0.25 \leq X \leq 0.25)\]</div>
<p>is given by</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">2</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">((</span><span class="mi">2</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2763263901682369
</pre></div>
</div>
</div>
</div>
<p>The Monte Carlo simulation yields a pretty close value:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_points</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">approximations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_points</span><span class="p">,))</span>
<span class="n">in_interval</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">points</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mf">0.25</span><span class="p">)</span>
<span class="n">estimation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">in_interval</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_points</span>
<span class="nb">print</span><span class="p">(</span><span class="n">estimation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.27771
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="exercise-monte-carlo-approximation-of-parameters">
<h3><span class="section-number">2.7.4. </span>Exercise: Monte Carlo approximation of parameters<a class="headerlink" href="#exercise-monte-carlo-approximation-of-parameters" title="Link to this heading">#</a></h3>
<p>Use Monte Carlo simulation to approximate numerically the mean of a Normal r.v. <span class="math notranslate nohighlight">\({\mathbf Z} \sim N(\mu,\sigma^2)\)</span> and of the variable <span class="math notranslate nohighlight">\({\mathbf Y}= {\mathbf Z}^2\)</span>. Verify that MC returns a good approximation of the analytical result. As a hint, note that <span class="math notranslate nohighlight">\(\mbox{Var}[{\mathbf Z}]=E[{\mathbf Z}^2]-E[{\mathbf Z}]^2\)</span></p>
<section id="id3">
<h4><span class="section-number">2.7.4.1. </span>Solution<a class="headerlink" href="#id3" title="Link to this heading">#</a></h4>
<p>First, analytically, we can note that, if <span class="math notranslate nohighlight">\(\mu\)</span> is the expected value of <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>, and  <span class="math notranslate nohighlight">\(\sigma^2\)</span> is its variance, then the expected value of <span class="math notranslate nohighlight">\(\mathbf{Y}=\mathbf{Z}^2\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
    E[\mathbf Z^2] = Var[Z] + (E[\mathbf Z])^2 = \sigma^2 + \mu^2
\]</div>
<p>Secondly, the variance of <span class="math notranslate nohighlight">\(Y=Z^2\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
    Var[\mathbf Z^2] = E[\mathbf Z^4]-(E[\mathbf Z^2])^2
\]</div>
<p>The second term is already known (<span class="math notranslate nohighlight">\(E[\mathbf Z^2] = \sigma^2+\mu^2\)</span>). The first term is the fourth moment (for the development, see the notion <em>moment generating function</em> in the course of <em>Probabilités et Statistiques</em>) of a normal variable, i.e.:</p>
<div class="math notranslate nohighlight">
\[
    E[\mathbf Z^4] = 3\sigma^4 + 6\sigma^2\mu^2 + \mu^4
\]</div>
<p>If we study a concrete example, let us fix <span class="math notranslate nohighlight">\(\mu=\frac12\)</span> and <span class="math notranslate nohighlight">\(\sigma^2=1.7\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span> <span class="o">=</span> <span class="mi">100000</span> 
<span class="n">Ez</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">Vz</span> <span class="o">=</span> <span class="mf">1.7</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">Ez</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Vz</span><span class="p">),</span> <span class="n">R</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span>
<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E[</span><span class="se">\\</span><span class="s2">mathbf Z]=</span><span class="si">{</span><span class="n">Ez</span><span class="si">}</span><span class="s2">;\ MC\ E[</span><span class="se">\\</span><span class="s2">mathbf Z]=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Var[</span><span class="se">\\</span><span class="s2">mathbf Z]=</span><span class="si">{</span><span class="n">Vz</span><span class="si">}</span><span class="s2">;\ MC\ Var[</span><span class="se">\\</span><span class="s2">mathbf Z]=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E[</span><span class="se">\\</span><span class="s2">mathbf Z^2]=</span><span class="si">{</span><span class="n">Vz</span><span class="o">+</span><span class="n">Ez</span><span class="o">**</span><span class="mi">2</span><span class="si">}</span><span class="s2">;\ MC\ E[</span><span class="se">\\</span><span class="s2">mathbf Y=</span><span class="se">\\</span><span class="s2">mathbf Z^2]=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Var[</span><span class="se">\\</span><span class="s2">mathbf Z^2]=</span><span class="si">{</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">Vz</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">6</span><span class="o">*</span><span class="n">Vz</span><span class="o">*</span><span class="n">Ez</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">Ez</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="n">Vz</span><span class="o">+</span><span class="n">Ez</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">;\ MC\ Var[</span><span class="se">\\</span><span class="s2">mathbf Y=</span><span class="se">\\</span><span class="s2">mathbf Z^2]=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle E[\mathbf Z]=0.5;\ MC\ E[\mathbf Z]=0.5015\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle Var[\mathbf Z]=1.7;\ MC\ Var[\mathbf Z]=1.6931\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle E[\mathbf Z^2]=1.95;\ MC\ E[\mathbf Y=\mathbf Z^2]=1.9446\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle Var[\mathbf Z^2]=7.4800;\ MC\ Var[\mathbf Y=\mathbf Z^2]=7.4843\]</div>
</div>
</div>
</section>
</section>
<section id="exercise-absolute-value">
<h3><span class="section-number">2.7.5. </span>Exercise: Absolute value<a class="headerlink" href="#exercise-absolute-value" title="Link to this heading">#</a></h3>
<p>Use MC to approximate numerically <span class="math notranslate nohighlight">\(E[ {\mathbf K}]\)</span> and <span class="math notranslate nohighlight">\(\mbox{Var}[ {\mathbf K}]\)</span> where <span class="math notranslate nohighlight">\({\mathbf K} = |{\mathbf Z}|\)</span> and check that the approximation is good w.r.t. the analytical results in <a class="reference external" href="https://www.quora.com/If-Y-X-where-X-has-normal-distribution-N-0-1-what-is-the-density-function-expectation-and-variance-of-Y">this article</a>.</p>
<section id="id4">
<h4><span class="section-number">2.7.5.1. </span>Solution<a class="headerlink" href="#id4" title="Link to this heading">#</a></h4>
<p>The process is truly similar to the previous one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Ez</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Vz</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">Ez</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Vz</span><span class="p">),</span> <span class="n">R</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="n">Ek</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
<span class="n">Vk</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span>

<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E[</span><span class="se">\\</span><span class="s2">mathbf K] = </span><span class="si">{</span><span class="n">Ek</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">;\ MC\ E[</span><span class="se">\\</span><span class="s2">mathbf K=|</span><span class="se">\\</span><span class="s2">mathbf Z|] = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Var[</span><span class="se">\\</span><span class="s2">mathbf K] = </span><span class="si">{</span><span class="n">Vk</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">;\ MC\ Var[</span><span class="se">\\</span><span class="s2">mathbf K=|</span><span class="se">\\</span><span class="s2">mathbf Z|] = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle E[\mathbf K] = 0.7979;\ MC\ E[\mathbf K=|\mathbf Z|] = 0.7998\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle Var[\mathbf K] = 0.3634;\ MC\ Var[\mathbf K=|\mathbf Z|] = 0.3633\]</div>
</div>
</div>
</section>
</section>
<section id="exercise-expected-value-for-any-function">
<h3><span class="section-number">2.7.6. </span>Exercise: Expected value for any function<a class="headerlink" href="#exercise-expected-value-for-any-function" title="Link to this heading">#</a></h3>
<p>Use MC to approximate numerically the value of <span class="math notranslate nohighlight">\(E[f({\mathbf X})]\)</span> and <span class="math notranslate nohighlight">\(f(E[{\mathbf X}])\)</span> for a given deterministic function <span class="math notranslate nohighlight">\(f\)</span>, where <span class="math notranslate nohighlight">\({\mathbf X}\)</span> is a normal random variable.</p>
<section id="id5">
<h4><span class="section-number">2.7.6.1. </span>Solution<a class="headerlink" href="#id5" title="Link to this heading">#</a></h4>
<p>The following script show the MC process to estimate the expected value of any Python function.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Change the function <code class="docutils literal notranslate"><span class="pre">f</span></code>. Is the process valid in all the cases ? Try to find an example of function for which this process could fail. Hint: some functions might not be defined depending on their input.</p>
</aside>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span>

<span class="n">FX</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">a</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">R</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">FX</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">muX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E[f(x)]= </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">FX</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;f(E[x])= </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">muX</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle E[f(x)]= -0.9756\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle f(E[x])= -0.0003\]</div>
</div>
</div>
</section>
</section>
<section id="exercise-variance-of-uniform-random-variable">
<h3><span class="section-number">2.7.7. </span>Exercise: Variance of uniform random variable<a class="headerlink" href="#exercise-variance-of-uniform-random-variable" title="Link to this heading">#</a></h3>
<p>Use MC to approximate numerically the value of the variance <span class="math notranslate nohighlight">\(\mbox{Var}[{\mathbf Z}]\)</span> where <span class="math notranslate nohighlight">\({\mathbf Z} \sim U(a,b)\)</span> is uniformly distributed. Check that the result is a good approximation of the analytical value.</p>
<section id="id6">
<h4><span class="section-number">2.7.7.1. </span>Solution<a class="headerlink" href="#id6" title="Link to this heading">#</a></h4>
<p>The following script estimates the variance of an uniformly distributed variable by Monte Carlo. The distribution is uniform between <span class="math notranslate nohighlight">\(-1\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
<span class="n">b</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">muz</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

<span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">R</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">Z</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">muz</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Var[</span><span class="se">\\</span><span class="s2">mathbf Z]= </span><span class="si">{</span><span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">12</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">;\ MC\ Var[</span><span class="se">\\</span><span class="s2">mathbf Z]= </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle Var[\mathbf Z]= 0.3333;\ MC\ Var[\mathbf Z]= 0.3340\]</div>
</div>
</div>
</section>
</section>
<section id="exercise-covariance-of-a-multiple-of-a-random-variable">
<h3><span class="section-number">2.7.8. </span>Exercise: Covariance of a multiple of a random variable<a class="headerlink" href="#exercise-covariance-of-a-multiple-of-a-random-variable" title="Link to this heading">#</a></h3>
<p>Use MC to approximate the value of the covariance of <span class="math notranslate nohighlight">\({\mathbf X}\)</span> and <span class="math notranslate nohighlight">\({\mathbf Y}=K{\mathbf X}\)</span> and verify that the result is a good approximation of the analytical derivation. Check for different distributions of <span class="math notranslate nohighlight">\({\mathbf X}\)</span>. As a hint, note that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mbox{Cov}({\mathbf X},{\mathbf Y})&amp;=E[{\mathbf X}{\mathbf Y}]-K E[{\mathbf X}]E[{\mathbf X}]\\
&amp;=E[K*{\mathbf X}^2]-K(E[{\mathbf X}]^2)\\
&amp;=K(\mbox{Var}({\mathbf X})+E[{\mathbf X}]^2)-K (E[{\mathbf X}])^2\\
&amp;=K\mbox{Var}({\mathbf X})
\end{align}\end{split}\]</div>
<section id="id7">
<h4><span class="section-number">2.7.8.1. </span>Solution<a class="headerlink" href="#id7" title="Link to this heading">#</a></h4>
<p>The following code shows the covariance estimation of a sampled random variable with a multiple of this random variable. The estimated covariance is close to the analytical value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">distr</span> <span class="o">=</span> <span class="s2">&quot;uniform&quot;</span>
<span class="n">XY</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">R</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">distr</span> <span class="o">==</span> <span class="s2">&quot;uniform&quot;</span><span class="p">:</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">VX</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">12</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">K</span> <span class="o">*</span> <span class="n">x</span>
    <span class="n">XY</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Analytical covariance: </span><span class="si">{</span><span class="n">K</span><span class="o">*</span><span class="n">VX</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Monte Carlo covariance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">XY</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">K</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Analytical covariance: 60.166666666666664
Monte Carlo covariance: 60.455461621858774
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="multivariate-gaussian-distributions">
<h2><span class="section-number">2.8. </span>Multivariate Gaussian distributions<a class="headerlink" href="#multivariate-gaussian-distributions" title="Link to this heading">#</a></h2>
<p>Multivariate Gaussian distributions are multidimensional generalizations of the normal distribution (that you already know well).
They can be described by mean vector <span class="math notranslate nohighlight">\(\mu\)</span> and a covariance matrix <span class="math notranslate nohighlight">\(\Sigma\)</span>, which shows the covariance between each of the distribution’s dimensions. As an example, if this matrix is diagonal, the variables corresponding to each dimension are independant. In the same way, this matrix has to be diagonal (can you tell why ?).</p>
<section id="exercise-2d-monte-carlo-simulation">
<h3><span class="section-number">2.8.1. </span>Exercise: 2D Monte Carlo Simulation<a class="headerlink" href="#exercise-2d-monte-carlo-simulation" title="Link to this heading">#</a></h3>
<p>Use MC simulation approximate the mean and covairance of 2-dimensional Gaussian random data with the following parameters:</p>
<ul class="simple">
<li><p>Mean vector: <span class="math notranslate nohighlight">\([2, 3]\)</span></p></li>
<li><p>Covariance matrix: <span class="math notranslate nohighlight">\(\begin{bmatrix}2&amp;0.8\\0.8&amp;1\end{bmatrix}\)</span></p></li>
</ul>
<p>Visualize the used data as a scatter plot. Compare the sample mean and the given mean vector.
Hint: use <code class="docutils literal notranslate"><span class="pre">scipy.stats.multivariate_normal</span></code> for generation and numpy to calculate the sample mean, and use <code class="docutils literal notranslate"><span class="pre">numpy.cov</span></code> for covariance estimation.
Ensure you understand the difference between population and sample covariance.</p>
<section id="id8">
<h4><span class="section-number">2.8.1.1. </span>Solution<a class="headerlink" href="#id8" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">rvs</span></code> from <code class="docutils literal notranslate"><span class="pre">scipy.stats.multivariate\_normal</span></code> (for <em>random variable sample</em> allows to sample a bivariate Gaussian adequately defined. The following code shows how to sample such kind of distribution, how to display it in <code class="docutils literal notranslate"><span class="pre">Matplotlib</span></code>, and how to estimate the covariance matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">multivariate_normal</span> <span class="k">as</span> <span class="n">mvn</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1500</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">mvn</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

<span class="n">sample_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scatter Plot of Generated Data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Dimension 1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Dimension 2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">sample_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">mu=&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">hat{</span><span class="se">\\</span><span class="s2">mu}=&quot;</span><span class="p">,</span> <span class="n">sample_mean</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;Cov:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cov</span><span class="p">))</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;MC\ Cov:&quot;</span><span class="p">,</span> <span class="n">sample_cov</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c42d014b523f46b0ef10bb2f5c7486d45fdbbdd0816fd2077add36f4e7dd6863.png" src="_images/c42d014b523f46b0ef10bb2f5c7486d45fdbbdd0816fd2077add36f4e7dd6863.png" />
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \mu=\left[
\begin{array}{}
  2.0000 &amp;  3.0000
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \hat{\mu}=\left[
\begin{array}{}
  1.9620 &amp;  2.9493
\end{array}
\right]\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle Cov:\left[
\begin{array}{}
  1.0000 &amp;  0.8000\\
  0.8000 &amp;  1.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle MC\ Cov:\left[
\begin{array}{}
  0.9969 &amp;  0.7940\\
  0.7940 &amp;  0.9862
\end{array}
\right]\end{split}\]</div>
</div>
</div>
</section>
</section>
<section id="exercise">
<h3><span class="section-number">2.8.2. </span>Exercise:<a class="headerlink" href="#exercise" title="Link to this heading">#</a></h3>
<p>We define a bivariate gaussian distribution <span class="math notranslate nohighlight">\((\mathbf Z_1, \mathbf Z_2)\)</span> with the following parameters:</p>
<ul class="simple">
<li><p>Mean vector: <span class="math notranslate nohighlight">\([0.25, 1.0]\)</span></p></li>
<li><p>Covariance matrix: <span class="math notranslate nohighlight">\(\begin{bmatrix}1.0&amp;0.5\\0.5&amp;1.0\end{bmatrix}\)</span></p></li>
</ul>
<p>Plot the regressions of <span class="math notranslate nohighlight">\(\mathbf Z_1|\mathbf Z_2\)</span> and <span class="math notranslate nohighlight">\(\mathbf Z_2|\mathbf Z_1\)</span>. What is their intersection ? Hint: those are given by expressing <span class="math notranslate nohighlight">\(\mathbf Z_1\)</span> in terms of <span class="math notranslate nohighlight">\(\mathbf Z_2\)</span> (or the opposite): <span class="math notranslate nohighlight">\(\mathbf Z_1 = a_1 + b_1\mathbf Z_2\)</span>.</p>
<section id="id9">
<h4><span class="section-number">2.8.2.1. </span>Solution<a class="headerlink" href="#id9" title="Link to this heading">#</a></h4>
<p>For the following derivation, we redirect the student to the theoretical handbook, pages 64-65. The following code generates a set of samples from a bivariate normal distribution with mean vector <span class="math notranslate nohighlight">\(\mu = \begin{bmatrix} 0.25 \\ 1 \end{bmatrix}\)</span> and covariance matrix <span class="math notranslate nohighlight">\(\Sigma = \begin{bmatrix} 1 &amp; 0.5 \\ 0.5 &amp; 1 \end{bmatrix}\)</span>, then computes and visualizes the regression lines corresponding to the conditional expectations <span class="math notranslate nohighlight">\(\mathbb{E}[\mathbf Z_1 \mid \mathbf Z_2]\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E}[\mathbf Z_2 \mid \mathbf Z_1]\)</span>. The regression coefficients are computed as <span class="math notranslate nohighlight">\(b_1 = \frac{\Sigma_{12}}{\Sigma_{22}}\)</span> and <span class="math notranslate nohighlight">\(b_2 = \frac{\Sigma_{12}}{\Sigma_{11}}\)</span>, with intercepts <span class="math notranslate nohighlight">\(a_1 = \mu_1 - b_1 \mu_2\)</span> and <span class="math notranslate nohighlight">\(a_2 = \mu_2 - b_2 \mu_1\)</span>. The resulting lines are plotted on the <span class="math notranslate nohighlight">\((\mathbf Z_2, \mathbf Z_1)\)</span> plane, showing the best linear predictors of each variable given the other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">mvn</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n_points</span><span class="p">)</span>

<span class="n">b_1</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">b_2</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">a1</span> <span class="o">=</span> <span class="n">mean</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">b_1</span> <span class="o">*</span> <span class="n">mean</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">mean</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">b_2</span> <span class="o">*</span> <span class="n">mean</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Regression of }Z_1</span><span class="se">\\</span><span class="s2">text{ on }Z_2: a_1 =&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">a1</span><span class="p">),</span> <span class="s2">&quot;,\ b_1 =&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">b_1</span><span class="p">))</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Regression of }Z_2</span><span class="se">\\</span><span class="s2">text{ on }Z_1: a_2 =&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">a2</span><span class="p">),</span> <span class="s2">&quot;,\ b_2 =&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">b_2</span><span class="p">))</span>

<span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">z1_pred</span> <span class="o">=</span> <span class="n">a1</span> <span class="o">+</span> <span class="n">b_1</span> <span class="o">*</span> <span class="n">z2</span>
<span class="n">z2_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">z2</span> <span class="o">-</span> <span class="n">a2</span><span class="p">)</span> <span class="o">/</span> <span class="n">b_2</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">z1_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$E[Z_1 | Z_2]$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">z2_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$E[Z_2 | Z_1]$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$Z_2$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$Z_1$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Regression Lines for Bivariate Normal Distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{Regression of }Z_1\text{ on }Z_2: a_1 =-0.25,\ b_1 =0.5\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{Regression of }Z_2\text{ on }Z_1: a_2 =0.875,\ b_2 =0.5\]</div>
<img alt="_images/12e9fa2e1abf6d09227f5bff379bce3fbf11e457999a0c7a08c5b9a768a3e925.png" src="_images/12e9fa2e1abf6d09227f5bff379bce3fbf11e457999a0c7a08c5b9a768a3e925.png" />
</div>
</div>
</section>
</section>
<section id="exercise-trivariate-gaussian-data">
<h3><span class="section-number">2.8.3. </span>Exercise: Trivariate Gaussian data<a class="headerlink" href="#exercise-trivariate-gaussian-data" title="Link to this heading">#</a></h3>
<p>Finally, generate 1000 samples of 3-dimensional Gaussian random data with the following parameters:</p>
<ul class="simple">
<li><p>Mean vector: <span class="math notranslate nohighlight">\([1, 4, 7]\)</span></p></li>
<li><p>Covariance matrix:<span class="math notranslate nohighlight">\(\begin{bmatrix}3&amp;1.5&amp;0.8\\1.5&amp;2&amp;0.5\\0.8&amp;0.5&amp;1\end{bmatrix}\)</span></p></li>
</ul>
<p>Estimate the covariance matrix using the generated data. Visualize the pairwise scatter plots of the dimensions (use a scatter plot matrix).
Hints: use <code class="docutils literal notranslate"><span class="pre">pandas.plotting.scatter_matrix</span></code> or <code class="docutils literal notranslate"><span class="pre">seaborn.pairplot</span></code> for visualization.
Pay attention to the interpretation of correlations between dimensions.</p>
<section id="id10">
<h4><span class="section-number">2.8.3.1. </span>Solution<a class="headerlink" href="#id10" title="Link to this heading">#</a></h4>
<p>The following code generates a 3-dimensional dataset of 1000 samples from a multivariate normal distribution with a specified mean vector <span class="math notranslate nohighlight">\([1, 4, 7]\)</span> and covariance matrix <span class="math notranslate nohighlight">\(\begin{bmatrix} 3 &amp; 1.5 &amp; 0.8 \\ 1.5 &amp; 2 &amp; 0.5 \\ 0.8 &amp; 0.5 &amp; 1 \end{bmatrix}\)</span>. It stores the generated samples in a Pandas DataFrame with columns labeled “Dimension 1”, “Dimension 2”, and “Dimension 3”. It then computes the empirical covariance matrix of the generated data using <code class="docutils literal notranslate"><span class="pre">np.cov</span></code>, prints both the given and estimated covariance matrices, and visualizes the pairwise relationships between the three dimensions using <code class="docutils literal notranslate"><span class="pre">Seaborn</span></code>’s <code class="docutils literal notranslate"><span class="pre">pairplot</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="n">mean_3d</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">cov_3d</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> 
          <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> 
          <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>

<span class="n">n_samples_3d</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">data_3d</span> <span class="o">=</span> <span class="n">mvn</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean_3d</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov_3d</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples_3d</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_3d</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Dimension 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Dimension 2&quot;</span><span class="p">,</span> <span class="s2">&quot;Dimension 3&quot;</span><span class="p">])</span>

<span class="n">sample_cov_3d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">data_3d</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;Cov:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cov_3d</span><span class="p">))</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;MC\ Cov:&quot;</span><span class="p">,</span> <span class="n">sample_cov_3d</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle Cov:\left[
\begin{array}{}
  3.0000 &amp;  1.5000 &amp;  0.8000\\
  1.5000 &amp;  2.0000 &amp;  0.5000\\
  0.8000 &amp;  0.5000 &amp;  1.0000
\end{array}
\right]\end{split}\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\begin{split}\displaystyle MC\ Cov:\left[
\begin{array}{}
  3.1791 &amp;  1.6075 &amp;  0.9758\\
  1.6075 &amp;  2.0246 &amp;  0.6169\\
  0.9758 &amp;  0.6169 &amp;  1.0465
\end{array}
\right]\end{split}\]</div>
<img alt="_images/456ed6152d21f8ca9da08f15285b096c8104ae43d4546612965b188a5349556c.png" src="_images/456ed6152d21f8ca9da08f15285b096c8104ae43d4546612965b188a5349556c.png" />
</div>
</div>
</section>
</section>
<section id="exercise-partial-correlation">
<h3><span class="section-number">2.8.4. </span>Exercise: Partial correlation<a class="headerlink" href="#exercise-partial-correlation" title="Link to this heading">#</a></h3>
<p>Given two normal <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> r.v. <span class="math notranslate nohighlight">\(Z_1, Z_2\)</span> and a third r.v. <span class="math notranslate nohighlight">\(Y = Z_1 + Z_2\)</span>, compute the correlation between <span class="math notranslate nohighlight">\(Z_1\)</span> and <span class="math notranslate nohighlight">\(Z_2\)</span>, then compute the partial correlation between <span class="math notranslate nohighlight">\(Z_1\)</span> and <span class="math notranslate nohighlight">\(Z_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>. Hint: use the function <code class="docutils literal notranslate"><span class="pre">corrcoef</span></code> of <code class="docutils literal notranslate"><span class="pre">Numpy</span></code> to compute the correlation coefficients. What happens to the partial correlation between <span class="math notranslate nohighlight">\(Z_1\)</span> and <span class="math notranslate nohighlight">\(Z_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> if now  <span class="math notranslate nohighlight">\(Y = Z_1 + Z_2 + Z_3\)</span>, for <span class="math notranslate nohighlight">\(Z_3\)</span> another <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> r.v. ?</p>
<section id="id11">
<h4><span class="section-number">2.8.4.1. </span>Solution<a class="headerlink" href="#id11" title="Link to this heading">#</a></h4>
<p>This code defines a function <code class="docutils literal notranslate"><span class="pre">partial_corr(X,</span> <span class="pre">Y,</span> <span class="pre">Z)</span></code> that computes the partial correlation between two variables <span class="math notranslate nohighlight">\(\mathbf X\)</span> and <span class="math notranslate nohighlight">\(\mathbf Y\)</span> given a third variable <span class="math notranslate nohighlight">\(\mathbf Z\)</span>, using the formula <span class="math notranslate nohighlight">\(\rho_{\mathbf X\mathbf Y \cdot \mathbf Z} = \frac{\rho_{\mathbf X\mathbf Y} - \rho_{\mathbf X\mathbf Z}\rho_{\mathbf Y\mathbf Z}}{\sqrt{(1 - \rho_{\mathbf X\mathbf Z}^2)(1 - \rho_{\mathbf Y\mathbf Z}^2)}}\)</span>. It then generates one million samples of three independent standard normal variables <span class="math notranslate nohighlight">\(\mathbf Z_1, \mathbf Z_2, \mathbf Z_3\)</span>, defines <span class="math notranslate nohighlight">\(\mathbf Y = \mathbf Z_1 + \mathbf Z_2\)</span>, and prints the empirical correlation between <span class="math notranslate nohighlight">\(\mathbf Z_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf Z_2\)</span>, as well as the partial correlations between <span class="math notranslate nohighlight">\(\mathbf Z_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf Z_2\)</span> given <span class="math notranslate nohighlight">\(\mathbf Y\)</span> and given <span class="math notranslate nohighlight">\(\mathbf Y + \mathbf Z_3\)</span>, illustrating that the dependence between <span class="math notranslate nohighlight">\(\mathbf Z_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf Z_2\)</span> vanishes when conditioning on their sum.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">partial_corr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">Z</span><span class="p">):</span>
    <span class="n">rhoXY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">rhoXZ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">Z</span><span class="o">.</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">rhoYZ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">Z</span><span class="o">.</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>    
    <span class="k">return</span> <span class="p">(</span><span class="n">rhoXY</span><span class="o">-</span><span class="n">rhoXZ</span><span class="o">*</span><span class="n">rhoYZ</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">rhoXZ</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">rhoYZ</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>

<span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">)</span>

<span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">Z3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">Z1</span> <span class="o">+</span> <span class="n">Z2</span>

<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Correlation between }</span><span class="se">\\</span><span class="s2">mathbf Z_1</span><span class="se">\\</span><span class="s2">text{ and }</span><span class="se">\\</span><span class="s2">mathbf Z_2: &quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">Z1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">Z2</span><span class="o">.</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])[:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Partial Correlation between }</span><span class="se">\\</span><span class="s2">mathbf Z_1</span><span class="se">\\</span><span class="s2">text{ and }</span><span class="se">\\</span><span class="s2">mathbf Z_2</span><span class="se">\\</span><span class="s2">text{ given }</span><span class="se">\\</span><span class="s2">mathbf Y=</span><span class="se">\\</span><span class="s2">mathbf Z_1+</span><span class="se">\\</span><span class="s2">mathbf Z_2:&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">partial_corr</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">Y</span><span class="p">))[:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">pprint</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">text{Partial Correlation between }</span><span class="se">\\</span><span class="s2">mathbf Z_1</span><span class="se">\\</span><span class="s2">text{ and }</span><span class="se">\\</span><span class="s2">mathbf Z_2</span><span class="se">\\</span><span class="s2">text{ given }</span><span class="se">\\</span><span class="s2">mathbf Y=</span><span class="se">\\</span><span class="s2">mathbf Z_1+</span><span class="se">\\</span><span class="s2">mathbf Z_2+</span><span class="se">\\</span><span class="s2">mathbf Z_3:&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">partial_corr</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="n">Z2</span><span class="p">,</span> <span class="n">Z1</span> <span class="o">+</span> <span class="n">Z2</span> <span class="o">+</span> <span class="n">Z3</span><span class="p">))[:</span><span class="mi">8</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{Correlation between }\mathbf Z_1\text{ and }\mathbf Z_2: -0.00073\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{Partial Correlation between }\mathbf Z_1\text{ and }\mathbf Z_2\text{ given }\mathbf Y=\mathbf Z_1+\mathbf Z_2:-0.99999\]</div>
<div class="output text_latex math notranslate nohighlight">
\[\displaystyle \text{Partial Correlation between }\mathbf Z_1\text{ and }\mathbf Z_2\text{ given }\mathbf Y=\mathbf Z_1+\mathbf Z_2+\mathbf Z_3:-0.50070\]</div>
</div>
</div>
</section>
</section>
</section>
<section id="minimization">
<h2><span class="section-number">2.9. </span>Minimization<a class="headerlink" href="#minimization" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Scipy</span></code> offers a convenient tool to perform the minimization of a derivable univariate function: in the module <code class="docutils literal notranslate"><span class="pre">optimize</span></code>, we have the <code class="docutils literal notranslate"><span class="pre">minimize</span></code> function.</p>
<section id="exercise-minimization">
<h3><span class="section-number">2.9.1. </span>Exercise: Minimization<a class="headerlink" href="#exercise-minimization" title="Link to this heading">#</a></h3>
<p>Define a function</p>
<div class="math notranslate nohighlight">
\[f(x) = x^2 + (\sin{x} + 25)^2\]</div>
<p>and use the <code class="docutils literal notranslate"><span class="pre">sp.optimize.minimize</span></code> function to find different local minima. Plot the function an show the different minimas. On which parameter of the <code class="docutils literal notranslate"><span class="pre">minimize</span></code> function can you play?</p>
<section id="id12">
<h4><span class="section-number">2.9.1.1. </span>Solution<a class="headerlink" href="#id12" title="Link to this heading">#</a></h4>
<p>The following code defines a function <span class="math notranslate nohighlight">\(f(x) = x^2 + (\sin(x) + 25)^2\)</span>, then plots it over the interval <span class="math notranslate nohighlight">\([-15, 15]\)</span>. For several initial guesses <span class="math notranslate nohighlight">\(x_0 \in \{-12, -4, 1, 7, 14\}\)</span>, the script uses the <code class="docutils literal notranslate"><span class="pre">SciPy</span></code> optimization routine <code class="docutils literal notranslate"><span class="pre">minimize</span></code> to find a local minimum of <span class="math notranslate nohighlight">\(f(x)\)</span> starting from <span class="math notranslate nohighlight">\(x_0\)</span>. Each minimization path is illustrated as a dashed line connecting the initial point to the corresponding minimum, with different colors representing different initial guesses. The plot includes a legend, grid, and title to clearly display the function and minimization results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="mi">25</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">x_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vec</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x_vec</span><span class="p">),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;f(x)&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">(</span><span class="n">c_i</span><span class="o">:=</span><span class="p">{</span><span class="s2">&quot;red&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;magenta&quot;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;lightgreen&quot;</span><span class="p">:</span> <span class="mi">14</span><span class="p">}):</span>   
    <span class="n">minimum</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">c_i</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
    <span class="n">line_x</span><span class="p">,</span> <span class="n">line_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">c_i</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">minimum</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">c_i</span><span class="p">[</span><span class="n">c</span><span class="p">]),</span> <span class="n">minimum</span><span class="o">.</span><span class="n">fun</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line_x</span><span class="p">,</span> <span class="n">line_y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Initial condition: x=</span><span class="si">{</span><span class="n">c_i</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Minimization examples from different initial conditions&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/680ab4f7cc133d9b86a6fdbf5be875a6dfacc6d512d1feca0bcdad161600ed51.png" src="_images/680ab4f7cc133d9b86a6fdbf5be875a6dfacc6d512d1feca0bcdad161600ed51.png" />
</div>
</div>
</section>
</section>
</section>
<section id="mixture-of-gaussians">
<h2><span class="section-number">2.10. </span>Mixture of Gaussians<a class="headerlink" href="#mixture-of-gaussians" title="Link to this heading">#</a></h2>
<p>Mixture of Gaussians are particular cases of linear combinations of Gaussians r.v. Formally, they are defined as</p>
<div class="math notranslate nohighlight">
\[p = \sum_{i=1}^m w_i p_i\]</div>
<p>where <span class="math notranslate nohighlight">\(p_i\)</span> are normal r.v. and <span class="math notranslate nohighlight">\(\sum_i w_1=1\)</span>.
As an example, we show here how to define (and plot) the mixture of three Gaussians:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>  
<span class="n">stds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>  
<span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">]</span>  

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">for</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">+=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">),</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;N(</span><span class="si">{</span><span class="n">mean</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">std</span><span class="si">}</span><span class="s1">^2)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mixture Density&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;on&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Mixture of Three Gaussians&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c85b218ae74a0e479630257a4e194fa687bea5896ea379d3822518165fdd349e.png" src="_images/c85b218ae74a0e479630257a4e194fa687bea5896ea379d3822518165fdd349e.png" />
</div>
</div>
</section>
<section id="conclusion">
<h2><span class="section-number">2.11. </span>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>Monte Carlo methods represent a powerful paradigm in computational mathematics, offering solutions to problems that would otherwise be analytically intractable. Throughout this chapter, we’ve explored the fundamental principles of probabilistic methods and Monte Carlo simulations, covering essential concepts from probability theory and their practical applications.</p>
<p>We’ve seen how random sampling can be leveraged to approximate integrals, estimate statistical properties, and solve complex problems in high-dimensional spaces. The exercises provided hands-on experience with implementing these techniques using <code class="docutils literal notranslate"><span class="pre">Python</span></code>’s scientific computing ecosystem, particularly <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> and <code class="docutils literal notranslate"><span class="pre">SciPy</span></code>.</p>
<p>The versatility of Monte Carlo methods makes them invaluable across numerous fields, from physics and engineering to finance and machine learning. By understanding both the theoretical foundations and practical implementations, you now possess a valuable computational tool that can be applied to a wide range of problems.</p>
<p>As computational resources continue to advance, Monte Carlo techniques will remain at the forefront of scientific computing, enabling researchers and practitioners to tackle increasingly complex challenges. The principles covered in this chapter provide a solid foundation for exploring more advanced Monte Carlo techniques such as Markov Chain Monte Carlo (MCMC), importance sampling, particle filters… But, in our case, Monte Carlo processes can be seen as good abstraction of real-life processes, and Machine Learning techniques then serve as tools to study the outcomes of Monte Carlo experiments.</p>
<p>Remember that Monte Carlo methods are not just computational techniques but represent a probabilistic way of thinking about problems. This mindset of using randomness to solve deterministic problems opens up new approaches to complex challenges across all quantitative disciplines.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="introduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Introduction</p>
      </div>
    </a>
    <a class="right-next"
       href="02.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Linear Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#necessary-libraries">2.1. Necessary libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-numpy">2.2. Introduction to <code class="docutils literal notranslate"><span class="pre">NumPy</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#manipulation-of-numpy-arrays">2.2.1. Manipulation of <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> arrays</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-of-creation-of-arrays">2.3. Example of creation of arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-operations">2.4. Basic operations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-foundations">2.5. Probabilistic Foundations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-and-variance">2.5.1. Expectation and Variance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-probability-distributions">2.5.2. Common Probability Distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#uniform-distribution">2.5.2.1. Uniform Distribution</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#normal-gaussian-distribution">2.5.2.2. Normal (Gaussian) Distribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-the-numpy-random-module">2.6. Introduction to the <code class="docutils literal notranslate"><span class="pre">numpy.random</span></code> module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reproducibility-of-results">2.6.1. Reproducibility of results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#available-distributions">2.6.2. Available distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling">2.6.3. Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-analysis">2.6.4. Statistical analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-histogram">2.6.5. Exercise: Histogram</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">2.6.5.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-simulation">2.7. Monte Carlo Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-integration">2.7.1. Monte Carlo Integration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-integral-estimation">2.7.2. Exercise: Integral estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.7.2.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-probability-estimation">2.7.3. Exercise: Probability estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.7.3.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-monte-carlo-approximation-of-parameters">2.7.4. Exercise: Monte Carlo approximation of parameters</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.7.4.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-absolute-value">2.7.5. Exercise: Absolute value</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.7.5.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-expected-value-for-any-function">2.7.6. Exercise: Expected value for any function</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.7.6.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-variance-of-uniform-random-variable">2.7.7. Exercise: Variance of uniform random variable</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.7.7.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-covariance-of-a-multiple-of-a-random-variable">2.7.8. Exercise: Covariance of a multiple of a random variable</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">2.7.8.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-gaussian-distributions">2.8. Multivariate Gaussian distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2d-monte-carlo-simulation">2.8.1. Exercise: 2D Monte Carlo Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">2.8.1.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">2.8.2. Exercise:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.8.2.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-trivariate-gaussian-data">2.8.3. Exercise: Trivariate Gaussian data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.8.3.1. Solution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-partial-correlation">2.8.4. Exercise: Partial correlation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">2.8.4.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimization">2.9. Minimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-minimization">2.9.1. Exercise: Minimization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">2.9.1.1. Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixture-of-gaussians">2.10. Mixture of Gaussians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">2.11. Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Tribel Pascal, Simar Cédric, Bontempi Gianluca
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  This is the practicals handbook for the course INFO-F422 - Statistical Foundations of Machine Learning. This is intended to be used alongside the <a href='https://www.researchgate.net/publication/242692234_Statistical_foundations_of_machine_learning_the_handbook'> theoretical handbook</a>.
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>