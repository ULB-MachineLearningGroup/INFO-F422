{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e978d6-ab9c-42de-9687-726094b0333a",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Pascal Tribel - [pascal.tribel@ulb.be](mailto:pascal.tribel@ulb.be)\n",
    "### Cédric Simar - [cedric.simar@ulb.be](mailto:cedric.simar@ulb.be)\n",
    "### Gian Marco Paldino - [gian.marco.paldino@ulb.be](mailto:gian.marco.paldino@ulb.be)\n",
    "\n",
    "## TP 5 - Ensembles of models and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40423ba9-a8a1-4a8d-88f0-d2e49a2ab271",
   "metadata": {},
   "source": [
    "## Reminder:  Supervised learning\n",
    "\n",
    "Supervised learning aims to model the (unknown) stochastic dependence between a set of $n$ inputs $x$ (also called features) and an output ${\\mathbf y}$ on the basis of a training set $D_N$ of size $N$. Supervised learning tasks are decomposed into *regression* and *classification* tasks.\n",
    "#### Regression\n",
    "In regression the stochastic dependence is given by\n",
    "$$ {\\mathbf y} = f(x)+\\mathbf{w}$$\n",
    "where:\n",
    "- $\\mathbf{y} \\in \\mathbb{R}$ represents the output variable (also called target)\n",
    "- $x \\in \\mathbb{R}^n$ represents the vector of inputs (also called features)\n",
    "- $\\mathbf{w}$ denotes the noise, and is typically assumed that $E[\\mathbf{w}]=0$ and the variance \n",
    " $\\text{Var}[\\mathbf{w}]=\\sigma^2_{\\mathbf{w}}$ is constant\n",
    "- $f(x)=E[{\\mathbf y} | x]$ is the (unknown) mapping between input and outputs, also known as the *regression function*.\n",
    "\n",
    "In regression, the goal of learning is to return an estimator \n",
    "$$h(x,\\alpha)$$\n",
    "of the regression function $f(x)$, where $\\alpha$ denotes the set of parameters of the model $h$.\n",
    "\n",
    "### Classification\n",
    "In classification the target is a category and its conditional distribution is \n",
    "$$P({\\mathbf y}|x)$$\n",
    "where:\n",
    "- $\\mathbf{y} \\in \\{ C_1,\\dots, C_K\\}$ represents the output variable (also called target)\n",
    "- $x \\in \\mathbb{R}^n$ represents the vector of inputs (also called features)\n",
    "\n",
    "In classification, the goal of learning is to return an estimator \n",
    "$$h(x,\\alpha)$$\n",
    "of the conditional probabiity $P({\\mathbf y}|x)$, where $\\alpha$ denotes the set of parameters of the model $h$. \n",
    "\n",
    "The learning of the estimator is done  on the basis of an available input/output\n",
    "training set $D_N$ made of $N$ observation pairs $(\\mathbf{x}_i,y_i)$ where $x_i \\in \\mathbb{R}^n$. \n",
    "\n",
    "\n",
    "## Feature selection\n",
    "\n",
    "Feature selection and ensembles of models are two techniques which can be used to improve the accuracy of predictions.\n",
    "\n",
    "Feature selection aims at reducing the dimensionality of the problem, and is useful when input variables contain redundant or irrelevant (noisy) information. Benefits are twofold: it decreases the training time by simplifying the problem, and it decreases the complexity of the predictive model. This in turn usually improves the prediction accuracy, since high-dimensionality makes predictive models more prone to overfitting, and estimates of parameters more variant.\n",
    "s\n",
    "There are three main approaches to feature selection:\n",
    "- **Filter methods:** \n",
    "These methods rely solely on the data and their intrinsic properties, without considering the impact of the selected features on the learning algorithm performance. For this reason, they are often used as preprocessing techniques.\n",
    "\n",
    "- **Wrapper methods:** \n",
    "These methods assess subsets of variables according to their usefulness to a given predictor. The feature selection is performed using an evaluation function that includes the predictive performance of the considered learning algorithm as a selection criterion.\n",
    "\n",
    "- **Embedded methods:** \n",
    "These methods are specific to given learning machines, and usually built-in in the learning procedure (e.g. random forest, regularization based techniques).\n",
    "\n",
    "Ensembles of models consist in building several predictive models using resampled subsets of the original training set. The method works particularly well for predictive models with high variance (for example, decision trees or neural networks). The average prediction of the resulting models usually strongly decreases the variance component of the error, and as a consequence improves the prediction accuracy.\n",
    "\n",
    "In this session, we will illustrate both techniques using the IMDB 5000 dataset, which contains 27 variables describing 5043 movies. The variables contain information about the director, actors, number of Facebook likes for each actor, duration, genre, language, country, etc... We will use them to predict the movie success (through the IMDB score). The dataset together with a description of the variables is at https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset.\n",
    "\n",
    "The dataset is on the github of the course, in `movie_metadata.csv`\n",
    "\n",
    "This is regression problem, with the IMDB score being the continuous target variable to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229df95f-5b5d-442b-9ef6-bb99fa717680",
   "metadata": {},
   "source": [
    "#### Data overview and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612553ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>Color</td>\n",
       "      <td>Randall Miller</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>Elden Henson</td>\n",
       "      <td>882.0</td>\n",
       "      <td>333658.0</td>\n",
       "      <td>Comedy|Family|Musical|Romance|Short</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Color</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>301.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>Stephen Root</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>380838870.0</td>\n",
       "      <td>Adventure|Animation|Comedy|Family</td>\n",
       "      <td>...</td>\n",
       "      <td>866.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>G</td>\n",
       "      <td>94000000.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.85</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      color   director_name  num_critic_for_reviews  duration  \\\n",
       "4198  Color  Randall Miller                     1.0      34.0   \n",
       "338   Color  Andrew Stanton                   301.0     100.0   \n",
       "\n",
       "      director_facebook_likes  actor_3_facebook_likes  actor_2_name  \\\n",
       "4198                     19.0                   362.0  Elden Henson   \n",
       "338                     475.0                   799.0  Stephen Root   \n",
       "\n",
       "      actor_1_facebook_likes        gross  \\\n",
       "4198                   882.0     333658.0   \n",
       "338                   1000.0  380838870.0   \n",
       "\n",
       "                                   genres  ... num_user_for_reviews language  \\\n",
       "4198  Comedy|Family|Musical|Romance|Short  ...                  2.0  English   \n",
       "338     Adventure|Animation|Comedy|Family  ...                866.0  English   \n",
       "\n",
       "      country  content_rating      budget  title_year actor_2_facebook_likes  \\\n",
       "4198      USA             NaN     34000.0      1990.0                  577.0   \n",
       "338       USA               G  94000000.0      2003.0                  939.0   \n",
       "\n",
       "     imdb_score  aspect_ratio movie_facebook_likes  \n",
       "4198        7.1           NaN                   16  \n",
       "338         8.2          1.85                11000  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"movie_metadata.csv\")\n",
    "np.random.seed(2)\n",
    "data = data.sample(1000) # Random subset of 1000 movies\n",
    "\n",
    "print(data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262a2d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>993</td>\n",
       "      <td>973</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>996</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>8.320000e+02</td>\n",
       "      <td>1000</td>\n",
       "      <td>...</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>930</td>\n",
       "      <td>9.040000e+02</td>\n",
       "      <td>971.000000</td>\n",
       "      <td>996.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>938.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Color</td>\n",
       "      <td>Woody Allen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Morgan Freeman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>946</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>938</td>\n",
       "      <td>751</td>\n",
       "      <td>421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.780364</td>\n",
       "      <td>106.428715</td>\n",
       "      <td>591.619733</td>\n",
       "      <td>606.791751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6378.470942</td>\n",
       "      <td>4.708677e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>272.970796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.555264e+07</td>\n",
       "      <td>2002.624099</td>\n",
       "      <td>1620.724900</td>\n",
       "      <td>6.420600</td>\n",
       "      <td>2.250458</td>\n",
       "      <td>7459.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.036541</td>\n",
       "      <td>23.878039</td>\n",
       "      <td>2559.402129</td>\n",
       "      <td>1599.266382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10260.480083</td>\n",
       "      <td>7.016262e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>387.030856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.731897e+07</td>\n",
       "      <td>12.088241</td>\n",
       "      <td>3587.837829</td>\n",
       "      <td>1.100457</td>\n",
       "      <td>1.528877</td>\n",
       "      <td>18155.875279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.711000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.250000e+03</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>147.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>4.436616e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>2.265441e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.250000</td>\n",
       "      <td>116.250000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>628.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>5.887055e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.400000e+07</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>22000.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137000.000000</td>\n",
       "      <td>4.745447e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5060.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>164000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        color director_name  num_critic_for_reviews    duration  \\\n",
       "count     993           973              988.000000  996.000000   \n",
       "unique      2           771                     NaN         NaN   \n",
       "top     Color   Woody Allen                     NaN         NaN   \n",
       "freq      946             7                     NaN         NaN   \n",
       "mean      NaN           NaN              140.780364  106.428715   \n",
       "std       NaN           NaN              122.036541   23.878039   \n",
       "min       NaN           NaN                1.000000   14.000000   \n",
       "25%       NaN           NaN               49.000000   94.000000   \n",
       "50%       NaN           NaN              107.000000  103.000000   \n",
       "75%       NaN           NaN              200.250000  116.250000   \n",
       "max       NaN           NaN              813.000000  226.000000   \n",
       "\n",
       "        director_facebook_likes  actor_3_facebook_likes    actor_2_name  \\\n",
       "count                973.000000              994.000000             996   \n",
       "unique                      NaN                     NaN             852   \n",
       "top                         NaN                     NaN  Morgan Freeman   \n",
       "freq                        NaN                     NaN               6   \n",
       "mean                 591.619733              606.791751             NaN   \n",
       "std                 2559.402129             1599.266382             NaN   \n",
       "min                    0.000000                0.000000             NaN   \n",
       "25%                    7.000000              147.250000             NaN   \n",
       "50%                   50.000000              362.000000             NaN   \n",
       "75%                  190.000000              628.500000             NaN   \n",
       "max                22000.000000            23000.000000             NaN   \n",
       "\n",
       "        actor_1_facebook_likes         gross genres  ... num_user_for_reviews  \\\n",
       "count               998.000000  8.320000e+02   1000  ...           993.000000   \n",
       "unique                     NaN           NaN    360  ...                  NaN   \n",
       "top                        NaN           NaN  Drama  ...                  NaN   \n",
       "freq                       NaN           NaN     44  ...                  NaN   \n",
       "mean               6378.470942  4.708677e+07    NaN  ...           272.970796   \n",
       "std               10260.480083  7.016262e+07    NaN  ...           387.030856   \n",
       "min                   0.000000  1.711000e+03    NaN  ...             1.000000   \n",
       "25%                 591.000000  4.436616e+06    NaN  ...            69.000000   \n",
       "50%                 989.000000  2.265441e+07    NaN  ...           158.000000   \n",
       "75%               11000.000000  5.887055e+07    NaN  ...           337.000000   \n",
       "max              137000.000000  4.745447e+08    NaN  ...          5060.000000   \n",
       "\n",
       "       language  country  content_rating        budget   title_year  \\\n",
       "count       998      998             930  9.040000e+02   971.000000   \n",
       "unique       19       30              14           NaN          NaN   \n",
       "top     English      USA               R           NaN          NaN   \n",
       "freq        938      751             421           NaN          NaN   \n",
       "mean        NaN      NaN             NaN  3.555264e+07  2002.624099   \n",
       "std         NaN      NaN             NaN  5.731897e+07    12.088241   \n",
       "min         NaN      NaN             NaN  3.250000e+03  1930.000000   \n",
       "25%         NaN      NaN             NaN  5.000000e+06  1999.000000   \n",
       "50%         NaN      NaN             NaN  2.000000e+07  2005.000000   \n",
       "75%         NaN      NaN             NaN  4.400000e+07  2011.000000   \n",
       "max         NaN      NaN             NaN  1.000000e+09  2016.000000   \n",
       "\n",
       "       actor_2_facebook_likes   imdb_score  aspect_ratio movie_facebook_likes  \n",
       "count              996.000000  1000.000000    938.000000          1000.000000  \n",
       "unique                    NaN          NaN           NaN                  NaN  \n",
       "top                       NaN          NaN           NaN                  NaN  \n",
       "freq                      NaN          NaN           NaN                  NaN  \n",
       "mean              1620.724900     6.420600      2.250458          7459.589000  \n",
       "std               3587.837829     1.100457      1.528877         18155.875279  \n",
       "min                  0.000000     1.600000      1.200000             0.000000  \n",
       "25%                294.000000     5.800000      1.850000             0.000000  \n",
       "50%                602.000000     6.500000      2.350000           174.000000  \n",
       "75%                939.000000     7.200000      2.350000          5000.000000  \n",
       "max              23000.000000     9.100000     16.000000        164000.000000  \n",
       "\n",
       "[11 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32257b-f5ec-4836-a704-c13861f49807",
   "metadata": {},
   "source": [
    "We see there is a mix of categorical and numerical variables, and some missing values. In order to simplify the analysis, let us remove the categorical variables, and replace the NA values with the mean values of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc88c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['color', 'director_name', 'actor_2_name', 'genres', 'actor_1_name',\n",
       "       'movie_title', 'actor_3_name', 'plot_keywords', 'movie_imdb_link',\n",
       "       'language', 'country', 'content_rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify factor (categorical) variables\n",
    "factor_cols = data.select_dtypes(include=['object']).columns\n",
    "factor_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817de31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>140.780364</td>\n",
       "      <td>106.428715</td>\n",
       "      <td>591.619733</td>\n",
       "      <td>606.791751</td>\n",
       "      <td>6378.470942</td>\n",
       "      <td>4.708677e+07</td>\n",
       "      <td>8.008905e+04</td>\n",
       "      <td>9470.591000</td>\n",
       "      <td>1.352705</td>\n",
       "      <td>272.970796</td>\n",
       "      <td>3.555264e+07</td>\n",
       "      <td>2002.624099</td>\n",
       "      <td>1620.724900</td>\n",
       "      <td>6.420600</td>\n",
       "      <td>2.250458</td>\n",
       "      <td>7459.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>121.301374</td>\n",
       "      <td>23.830187</td>\n",
       "      <td>2524.578708</td>\n",
       "      <td>1594.456547</td>\n",
       "      <td>10250.204186</td>\n",
       "      <td>6.399168e+07</td>\n",
       "      <td>1.300510e+05</td>\n",
       "      <td>13847.572387</td>\n",
       "      <td>2.087632</td>\n",
       "      <td>385.672508</td>\n",
       "      <td>5.449535e+07</td>\n",
       "      <td>11.911494</td>\n",
       "      <td>3580.647766</td>\n",
       "      <td>1.100457</td>\n",
       "      <td>1.480674</td>\n",
       "      <td>18155.875279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.711000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.250000e+03</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>6.977259e+06</td>\n",
       "      <td>8.901500e+03</td>\n",
       "      <td>1429.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>294.750000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>366.500000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>3.415931e+07</td>\n",
       "      <td>3.565200e+04</td>\n",
       "      <td>3009.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>2.300000e+07</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2.250458</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>199.250000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>626.250000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>4.792683e+07</td>\n",
       "      <td>9.295550e+04</td>\n",
       "      <td>13720.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>335.250000</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>940.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>813.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>22000.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>137000.000000</td>\n",
       "      <td>4.745447e+08</td>\n",
       "      <td>1.347461e+06</td>\n",
       "      <td>137712.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>5060.000000</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>164000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_critic_for_reviews     duration  director_facebook_likes  \\\n",
       "count             1000.000000  1000.000000              1000.000000   \n",
       "mean               140.780364   106.428715               591.619733   \n",
       "std                121.301374    23.830187              2524.578708   \n",
       "min                  1.000000    14.000000                 0.000000   \n",
       "25%                 50.000000    94.000000                 7.000000   \n",
       "50%                110.000000   103.000000                53.500000   \n",
       "75%                199.250000   116.000000               223.000000   \n",
       "max                813.000000   226.000000             22000.000000   \n",
       "\n",
       "       actor_3_facebook_likes  actor_1_facebook_likes         gross  \\\n",
       "count             1000.000000             1000.000000  1.000000e+03   \n",
       "mean               606.791751             6378.470942  4.708677e+07   \n",
       "std               1594.456547            10250.204186  6.399168e+07   \n",
       "min                  0.000000                0.000000  1.711000e+03   \n",
       "25%                148.000000              591.000000  6.977259e+06   \n",
       "50%                366.500000              989.000000  3.415931e+07   \n",
       "75%                626.250000            11000.000000  4.792683e+07   \n",
       "max              23000.000000           137000.000000  4.745447e+08   \n",
       "\n",
       "       num_voted_users  cast_total_facebook_likes  facenumber_in_poster  \\\n",
       "count     1.000000e+03                1000.000000           1000.000000   \n",
       "mean      8.008905e+04                9470.591000              1.352705   \n",
       "std       1.300510e+05               13847.572387              2.087632   \n",
       "min       6.000000e+00                   0.000000              0.000000   \n",
       "25%       8.901500e+03                1429.750000              0.000000   \n",
       "50%       3.565200e+04                3009.500000              1.000000   \n",
       "75%       9.295550e+04               13720.500000              2.000000   \n",
       "max       1.347461e+06              137712.000000             31.000000   \n",
       "\n",
       "       num_user_for_reviews        budget   title_year  \\\n",
       "count           1000.000000  1.000000e+03  1000.000000   \n",
       "mean             272.970796  3.555264e+07  2002.624099   \n",
       "std              385.672508  5.449535e+07    11.911494   \n",
       "min                1.000000  3.250000e+03  1930.000000   \n",
       "25%               69.750000  7.000000e+06  1999.000000   \n",
       "50%              159.000000  2.300000e+07  2005.000000   \n",
       "75%              335.250000  4.000000e+07  2010.000000   \n",
       "max             5060.000000  1.000000e+09  2016.000000   \n",
       "\n",
       "       actor_2_facebook_likes   imdb_score  aspect_ratio  movie_facebook_likes  \n",
       "count             1000.000000  1000.000000   1000.000000           1000.000000  \n",
       "mean              1620.724900     6.420600      2.250458           7459.589000  \n",
       "std               3580.647766     1.100457      1.480674          18155.875279  \n",
       "min                  0.000000     1.600000      1.200000              0.000000  \n",
       "25%                294.750000     5.800000      1.850000              0.000000  \n",
       "50%                605.000000     6.500000      2.250458            174.000000  \n",
       "75%                940.000000     7.200000      2.350000           5000.000000  \n",
       "max              23000.000000     9.100000     16.000000         164000.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove categorical variables\n",
    "data_preprocessed = data.drop(columns=factor_cols)\n",
    "\n",
    "# Replace NaN with mean\n",
    "data_preprocessed = data_preprocessed.apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "data_preprocessed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a8726-c458-4d83-b0f8-c6de0d2c9953",
   "metadata": {},
   "source": [
    "### Input and output variables\n",
    "\n",
    "The output variable (Y) is the `imdb_score`, and all other variables (X) are considered as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efd9a186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Y: 6.4206\n",
      "Variance of Y: 1.2097956399999998\n"
     ]
    }
   ],
   "source": [
    "Y = data_preprocessed['imdb_score'].values\n",
    "X = data_preprocessed.drop(columns=['imdb_score'])\n",
    "\n",
    "N = X.shape[0] ## number of observations\n",
    "n = X.shape[1] ## number of input features\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(Y, bins=20)\n",
    "plt.title(\"Distribution of imdb_score\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of Y:\", np.mean(Y))\n",
    "print(\"Variance of Y:\", np.var(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36151e1d-1f06-42ef-85bc-316b04042449",
   "metadata": {},
   "source": [
    "### 1) Modelling with linear and decision tree models\n",
    "\n",
    "#### Linear model\n",
    "\n",
    "* Create a linear model $h(x)$ for predicting the IMDB score on the basis of the input variables, and compute its empirical (or training) mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fc25b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical error= 0.9154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "Y_hat = model.predict(X)\n",
    "\n",
    "empirical_error = np.mean((Y_hat - Y)**2)\n",
    "print(\"Empirical error=\", round(empirical_error,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416ca2f-c944-4acb-80ab-f6f65435b891",
   "metadata": {},
   "source": [
    "* Which input variables are statistically correlated with the output?\n",
    "\n",
    "In Python, we can check the coefficients of the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "952a54da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_critic_for_reviews       1.700807e-03\n",
       "duration                     5.405962e-03\n",
       "director_facebook_likes      8.798490e-06\n",
       "actor_3_facebook_likes      -1.124559e-05\n",
       "actor_1_facebook_likes       1.339764e-05\n",
       "gross                       -1.345351e-09\n",
       "num_voted_users              3.948450e-06\n",
       "cast_total_facebook_likes   -1.178803e-05\n",
       "facenumber_in_poster        -1.145375e-02\n",
       "num_user_for_reviews        -6.795024e-04\n",
       "budget                      -1.265215e-09\n",
       "title_year                  -2.180756e-02\n",
       "actor_2_facebook_likes       1.923221e-05\n",
       "aspect_ratio                 8.809596e-02\n",
       "movie_facebook_likes         2.258206e-06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.Series(model.coef_, index=X.columns)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dad011-bb46-4b36-891d-45262de8ff1f",
   "metadata": {},
   "source": [
    "* Compute the validation error with a 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1434da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error= 0.9817 ; std dev= 0.2359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=3)\n",
    "CV_err_lm_single_model = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_tr, Y_tr)\n",
    "    Y_hat_ts = model.predict(X_ts)\n",
    "    CV_err_lm_single_model.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "\n",
    "print(\"CV error=\", round(np.mean(CV_err_lm_single_model),4), \n",
    "      \"; std dev=\", round(np.std(CV_err_lm_single_model),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32539f5d-fe7e-4f32-b4b2-7e1db2cc130f",
   "metadata": {},
   "source": [
    "#### Decision tree\n",
    "\n",
    "* Modify the previous code to compute the empirical error using a decision tree model. Use sklearn's `DecisionTreeRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6e7e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical error= 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=3)\n",
    "model.fit(X, Y)\n",
    "Y_hat = model.predict(X)\n",
    "\n",
    "empirical_error = np.mean((Y_hat - Y)**2)\n",
    "print(\"Empirical error=\", round(empirical_error,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911e381-5bb1-46bb-b05a-5bbf3810ed43",
   "metadata": {},
   "source": [
    "* Plot the resulting tree is more complicated in Python due to size, but we can just visualize its structure or get the depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df528ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 867)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_depth(), model.get_n_leaves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9622f-57a6-4aa6-9a64-8dabae637cb3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "* What is the 10-fold cross-validation error using a decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d53bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error= 1.4988 ; std dev= 0.2935\n"
     ]
    }
   ],
   "source": [
    "CV_err_rpart_single_model = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = DecisionTreeRegressor(random_state=3)\n",
    "    model.fit(X_tr, Y_tr)\n",
    "    Y_hat_ts = model.predict(X_ts)\n",
    "    CV_err_rpart_single_model.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "\n",
    "print(\"CV error=\", round(np.mean(CV_err_rpart_single_model),4), \n",
    "      \"; std dev=\", round(np.std(CV_err_rpart_single_model),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9ba71-62f3-4137-93d2-5ef652d8e569",
   "metadata": {},
   "source": [
    "Why is the result so different using the 10-fold cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebb829-6f16-43b4-926b-37f424d697e1",
   "metadata": {},
   "source": [
    "#### Ridge regression with LOO-CV\n",
    "Recall: Ridge regression looks like a linear regression but includes a penalty term for large coefficients:\n",
    "$$\n",
    "  \\min_{\\beta} \\;\\; \\| Y - X \\beta \\|^2 + \\alpha \\| \\beta \\|^2.\n",
    "$$\n",
    "\n",
    "\n",
    "Ridge also has a known closed-form:\n",
    "$$\n",
    "  \\hat{\\beta}_{\\mathrm{ridge}} = (X^\\top X + \\alpha I)^{-1} X^\\top Y.\n",
    "$$\n",
    "\n",
    "* Leave-one out cross-validation is a method that consists in evaluating a given model by training it on the entire training set, except for one sample used for validation. By performing this validation, eliminating each of the samples at a time, we get an estimation of the quality of the model.\n",
    "* Then, the coefficients can give an idea of the importance of each of the features in the prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de063c60-f4f0-4590-8f81-e6eb91742163",
   "metadata": {},
   "source": [
    "## 2) Ensemble of models\n",
    "\n",
    "Let us now create an ensemble of R=20 linear models to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b55d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error= 0.9775 ; std dev= 0.2393\n",
      "Is ensemble error lower than single model? True\n"
     ]
    }
   ],
   "source": [
    "R = 20\n",
    "CV_err_lm_ensemble_model = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    Y_hat_ts_ensemble = np.zeros((X_ts.shape[0], R))\n",
    "    for r in range(R):\n",
    "        # Resample the training indices\n",
    "        idx_tr_resample = np.random.choice(train_index, size=len(train_index), replace=True)\n",
    "        X_tr_res = X.iloc[idx_tr_resample]\n",
    "        Y_tr_res = Y[idx_tr_resample]\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr_res, Y_tr_res)\n",
    "        Y_hat_ts_ensemble[:, r] = model.predict(X_ts)\n",
    "    \n",
    "    Y_hat_ts = np.mean(Y_hat_ts_ensemble, axis=1)\n",
    "    CV_err_lm_ensemble_model.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "\n",
    "print(\"CV error=\", round(np.mean(CV_err_lm_ensemble_model),4), \n",
    "      \"; std dev=\", round(np.std(CV_err_lm_ensemble_model),4))\n",
    "\n",
    "# Is the CV error lower?\n",
    "print(\"Is ensemble error lower than single model?\", \n",
    "      np.mean(CV_err_lm_ensemble_model) < np.mean(CV_err_lm_single_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37162c-04f5-4a30-9465-a74961aa54c2",
   "metadata": {},
   "source": [
    "* Use a decision tree as the base model. Is the CV error lower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "441967f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error= 0.8092 ; std dev= 0.1835\n",
      "Is ensemble error lower than single tree model? True\n"
     ]
    }
   ],
   "source": [
    "R = 20\n",
    "CV_err_rpart_ensemble_model = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    Y_hat_ts_ensemble = np.zeros((X_ts.shape[0], R))\n",
    "    for r in range(R):\n",
    "        idx_tr_resample = np.random.choice(train_index, size=len(train_index), replace=True)\n",
    "        X_tr_res = X.iloc[idx_tr_resample]\n",
    "        Y_tr_res = Y[idx_tr_resample]\n",
    "        \n",
    "        model = DecisionTreeRegressor(random_state=r)\n",
    "        model.fit(X_tr_res, Y_tr_res)\n",
    "        Y_hat_ts_ensemble[:, r] = model.predict(X_ts)\n",
    "    \n",
    "    Y_hat_ts = np.mean(Y_hat_ts_ensemble, axis=1)\n",
    "    CV_err_rpart_ensemble_model.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "\n",
    "print(\"CV error=\", round(np.mean(CV_err_rpart_ensemble_model),4), \n",
    "      \"; std dev=\", round(np.std(CV_err_rpart_ensemble_model),4))\n",
    "\n",
    "# Is ensemble error lower?\n",
    "print(\"Is ensemble error lower than single tree model?\", \n",
    "      np.mean(CV_err_rpart_ensemble_model) < np.mean(CV_err_rpart_single_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30000bc-a557-4ec8-8da7-542ef1a1cf08",
   "metadata": {},
   "source": [
    "## 3) Feature selection\n",
    "\n",
    "### Filter methods\n",
    "\n",
    "#### Correlation with the output\n",
    "\n",
    "The following code performs feature selection by keeping the most correlated variables with the output. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "868f63c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Features: 1 ; CV error= 1.1482 ; std dev= 0.2285\n",
      "#Features: 2 ; CV error= 1.144 ; std dev= 0.2237\n",
      "#Features: 3 ; CV error= 1.1452 ; std dev= 0.2227\n",
      "#Features: 4 ; CV error= 1.1586 ; std dev= 0.2355\n",
      "#Features: 5 ; CV error= 1.1435 ; std dev= 0.2556\n",
      "#Features: 6 ; CV error= 1.1454 ; std dev= 0.2555\n",
      "#Features: 7 ; CV error= 1.1143 ; std dev= 0.2732\n",
      "#Features: 8 ; CV error= 1.1209 ; std dev= 0.2913\n",
      "#Features: 9 ; CV error= 1.115 ; std dev= 0.2858\n",
      "#Features: 10 ; CV error= 1.0372 ; std dev= 0.254\n",
      "#Features: 11 ; CV error= 0.9768 ; std dev= 0.2331\n",
      "#Features: 12 ; CV error= 0.9761 ; std dev= 0.2313\n",
      "#Features: 13 ; CV error= 0.978 ; std dev= 0.2319\n",
      "#Features: 14 ; CV error= 0.9794 ; std dev= 0.234\n",
      "#Features: 15 ; CV error= 0.9817 ; std dev= 0.2359\n",
      "Correlation ranking:\n",
      "['num_user_for_reviews', 'cast_total_facebook_likes', 'actor_1_facebook_likes', 'budget', 'duration', 'actor_3_facebook_likes', 'movie_facebook_likes', 'num_critic_for_reviews', 'aspect_ratio', 'title_year', 'num_voted_users', 'gross', 'director_facebook_likes', 'facenumber_in_poster', 'actor_2_facebook_likes']\n"
     ]
    }
   ],
   "source": [
    "correlations = np.abs(X.corrwith(pd.Series(Y)))\n",
    "ranking_corr_idx = correlations.sort_values(ascending=False).index\n",
    "\n",
    "CV_err = np.zeros((n,10))\n",
    "\n",
    "fold_id = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    for nb_features in range(1, n+1):\n",
    "        selected_features = ranking_corr_idx[:nb_features]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr[selected_features], Y_tr)\n",
    "        Y_hat_ts = model.predict(X_ts[selected_features])\n",
    "        CV_err[nb_features-1, fold_id] = np.mean((Y_hat_ts - Y_ts)**2)\n",
    "    fold_id += 1\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"#Features:\", i+1, \"; CV error=\", round(np.mean(CV_err[i,:]),4),\n",
    "          \"; std dev=\", round(np.std(CV_err[i,:]),4))\n",
    "\n",
    "print(\"Correlation ranking:\")\n",
    "print(ranking_corr_idx.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e090673-df93-4a5e-beee-0118c4d1520c",
   "metadata": {},
   "source": [
    "#### mRMR\n",
    "\n",
    "We will implement a simple mRMR feature selection. mRMR uses mutual information. We will approximate mutual information via the correlation-based formula provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770f86e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Features: 1 ; CV error= 1.0427 ; std dev= 0.2024\n",
      "#Features: 2 ; CV error= 1.0018 ; std dev= 0.1985\n",
      "#Features: 3 ; CV error= 1.0031 ; std dev= 0.196\n",
      "#Features: 4 ; CV error= 0.9925 ; std dev= 0.2068\n",
      "#Features: 5 ; CV error= 0.9898 ; std dev= 0.208\n",
      "#Features: 6 ; CV error= 0.9896 ; std dev= 0.2094\n",
      "#Features: 7 ; CV error= 0.9938 ; std dev= 0.2164\n",
      "#Features: 8 ; CV error= 0.9807 ; std dev= 0.2155\n",
      "#Features: 9 ; CV error= 0.9647 ; std dev= 0.2146\n",
      "#Features: 10 ; CV error= 0.9663 ; std dev= 0.22\n",
      "#Features: 11 ; CV error= 0.9697 ; std dev= 0.2262\n",
      "#Features: 12 ; CV error= 0.9693 ; std dev= 0.2266\n",
      "#Features: 13 ; CV error= 0.9602 ; std dev= 0.2241\n",
      "#Features: 14 ; CV error= 0.9785 ; std dev= 0.2341\n",
      "#Features: 15 ; CV error= 0.9817 ; std dev= 0.2359\n",
      "Selected features ranking (mRMR):\n",
      "['num_voted_users', 'title_year', 'aspect_ratio', 'duration', 'facenumber_in_poster', 'director_facebook_likes', 'actor_1_facebook_likes', 'movie_facebook_likes', 'budget', 'actor_3_facebook_likes', 'gross', 'actor_2_facebook_likes', 'num_critic_for_reviews', 'num_user_for_reviews', 'cast_total_facebook_likes']\n"
     ]
    }
   ],
   "source": [
    "def mutual_info_corr(X, Y):\n",
    "    c = np.corrcoef(X, Y)[0,1]\n",
    "    # Avoid invalid value if correlation == 1 or == -1\n",
    "    if abs(c)==1:\n",
    "        c = 0.999999\n",
    "    return -0.5 * np.log(1 - c**2)\n",
    "\n",
    "def compute_mi_vector(X_tr, Y_tr):\n",
    "    mis = []\n",
    "    for col in X_tr.columns:\n",
    "        mi = mutual_info_corr(X_tr[col].values, Y_tr)\n",
    "        mis.append(mi)\n",
    "    return np.array(mis)\n",
    "\n",
    "CV_err = np.zeros((n,10))\n",
    "\n",
    "fold_id = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    mutual_info_values = compute_mi_vector(X_tr, Y_tr)\n",
    "    selected = []\n",
    "    candidates = list(range(n))\n",
    "    \n",
    "    for j in range(n):\n",
    "        redundancy_score = np.zeros(len(candidates))\n",
    "        if len(selected)>0:\n",
    "            # Compute pairwise mi between selected and candidates\n",
    "            mi_sc = []\n",
    "            for cidx in candidates:\n",
    "                col_c = X_tr.iloc[:, cidx]\n",
    "                mis_c = []\n",
    "                for sidx in selected:\n",
    "                    col_s = X_tr.iloc[:, sidx]\n",
    "                    # Compute mutual info between col_s and col_c\n",
    "                    cc = np.corrcoef(col_s, col_c)[0,1]\n",
    "                    if abs(cc)==1:\n",
    "                        cc=0.999999\n",
    "                    mis_c.append(-0.5*np.log(1-cc**2))\n",
    "                redundancy_score[candidates.index(cidx)] = np.mean(mis_c)\n",
    "        mRMR_score = mutual_info_values[candidates] - redundancy_score\n",
    "        best_idx = candidates[np.argmax(mRMR_score)]\n",
    "        selected.append(best_idx)\n",
    "        candidates.remove(best_idx)\n",
    "    \n",
    "    # selected is the ranking\n",
    "    for nb_features in range(1, n+1):\n",
    "        features_to_use = [X.columns[i] for i in selected[:nb_features]]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr[features_to_use], Y_tr)\n",
    "        Y_hat_ts = model.predict(X_ts[features_to_use])\n",
    "        CV_err[nb_features-1, fold_id] = np.mean((Y_hat_ts - Y_ts)**2)\n",
    "    fold_id += 1\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"#Features:\", i+1, \"; CV error=\", round(np.mean(CV_err[i,:]),4),\n",
    "          \"; std dev=\", round(np.std(CV_err[i,:]),4))\n",
    "    \n",
    "print(\"Selected features ranking (mRMR):\")\n",
    "print([X.columns[i] for i in selected])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c0c2b-2fa4-414e-938c-031b3abfb384",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "The following code performs features selection by first transforming the inputs using PCA, and then keeping the most relevant principal components in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d01949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Features: 1 ; CV error= 1.1915 ; std dev= 0.213\n",
      "#Features: 2 ; CV error= 1.1902 ; std dev= 0.2177\n",
      "#Features: 3 ; CV error= 1.0599 ; std dev= 0.2286\n",
      "#Features: 4 ; CV error= 1.0629 ; std dev= 0.2351\n",
      "#Features: 5 ; CV error= 1.0615 ; std dev= 0.2417\n",
      "#Features: 6 ; CV error= 1.0629 ; std dev= 0.2413\n",
      "#Features: 7 ; CV error= 1.0639 ; std dev= 0.2431\n",
      "#Features: 8 ; CV error= 1.0622 ; std dev= 0.2463\n",
      "#Features: 9 ; CV error= 1.065 ; std dev= 0.2461\n",
      "#Features: 10 ; CV error= 1.0578 ; std dev= 0.2346\n",
      "#Features: 11 ; CV error= 1.0679 ; std dev= 0.2483\n",
      "#Features: 12 ; CV error= 1.0569 ; std dev= 0.2781\n",
      "#Features: 13 ; CV error= 0.9919 ; std dev= 0.2374\n",
      "#Features: 14 ; CV error= 0.9926 ; std dev= 0.2396\n",
      "#Features: 15 ; CV error= 0.9817 ; std dev= 0.2359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "CV_err = np.zeros((n,10))\n",
    "fold_id = 0\n",
    "for train_index, test_index in kf.split(X_pca):\n",
    "    X_tr, X_ts = X_pca[train_index], X_pca[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    for nb_components in range(1, n+1):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_tr[:, :nb_components], Y_tr)\n",
    "        Y_hat_ts = model.predict(X_ts[:, :nb_components])\n",
    "        CV_err[nb_components-1, fold_id] = np.mean((Y_hat_ts - Y_ts)**2)\n",
    "    fold_id += 1\n",
    "\n",
    "for i in range(n):\n",
    "    print(\"#Features:\", i+1, \"; CV error=\", round(np.mean(CV_err[i,:]),4),\n",
    "          \"; std dev=\", round(np.std(CV_err[i,:]),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd0016-c32f-486b-a9d2-0af96b00f45b",
   "metadata": {},
   "source": [
    "### Wrapper method: Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d662579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 ; Selected feature: 6 ; CV error= 1.0427 ; std dev= 0.2234\n",
      "Round 2 ; Selected feature: 11 ; CV error= 1.0018 ; std dev= 0.209\n",
      "Round 3 ; Selected feature: 0 ; CV error= 0.9876 ; std dev= 0.2093\n",
      "Round 4 ; Selected feature: 9 ; CV error= 0.9683 ; std dev= 0.2101\n",
      "Round 5 ; Selected feature: 13 ; CV error= 0.9592 ; std dev= 0.1934\n",
      "Round 6 ; Selected feature: 1 ; CV error= 0.9502 ; std dev= 0.1908\n",
      "Round 7 ; Selected feature: 5 ; CV error= 0.9466 ; std dev= 0.1992\n",
      "Round 8 ; Selected feature: 4 ; CV error= 0.9471 ; std dev= 0.2068\n",
      "Round 9 ; Selected feature: 14 ; CV error= 0.9482 ; std dev= 0.2066\n",
      "Round 10 ; Selected feature: 12 ; CV error= 0.9493 ; std dev= 0.207\n",
      "Round 11 ; Selected feature: 3 ; CV error= 0.9497 ; std dev= 0.2297\n",
      "Round 12 ; Selected feature: 8 ; CV error= 0.951 ; std dev= 0.2129\n",
      "Round 13 ; Selected feature: 2 ; CV error= 0.9531 ; std dev= 0.2154\n",
      "Round 14 ; Selected feature: 7 ; CV error= 0.9561 ; std dev= 0.2166\n",
      "Round 15 ; Selected feature: 10 ; CV error= 0.9817 ; std dev= 0.2359\n",
      "Selected features: ['num_voted_users', 'title_year', 'num_critic_for_reviews', 'num_user_for_reviews', 'aspect_ratio', 'duration', 'gross', 'actor_1_facebook_likes', 'movie_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'facenumber_in_poster', 'director_facebook_likes', 'cast_total_facebook_likes', 'budget']\n"
     ]
    }
   ],
   "source": [
    "# Forward selection\n",
    "selected = []\n",
    "for round_i in range(n):\n",
    "    candidates = list(set(range(n)) - set(selected))\n",
    "    CV_err_temp = []\n",
    "    for c in candidates:\n",
    "        features_to_include = selected + [c]\n",
    "        fold_errors = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_tr, X_ts = X.iloc[train_index, features_to_include], X.iloc[test_index, features_to_include]\n",
    "            Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "            \n",
    "            model = LinearRegression()\n",
    "            model.fit(X_tr, Y_tr)\n",
    "            Y_hat_ts = model.predict(X_ts)\n",
    "            fold_errors.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "        CV_err_temp.append(np.mean(fold_errors))\n",
    "    \n",
    "    best_candidate = candidates[np.argmin(CV_err_temp)]\n",
    "    selected.append(best_candidate)\n",
    "    print(\"Round\", round_i+1, \"; Selected feature:\", best_candidate,\n",
    "          \"; CV error=\", round(min(CV_err_temp),4), \n",
    "          \"; std dev=\", round(np.std(fold_errors),4))\n",
    "\n",
    "print(\"Selected features:\", [X.columns[i] for i in selected])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef39c80-7edf-4135-83ea-1a8716e92dd1",
   "metadata": {},
   "source": [
    "## Further preprocessing to add categorical variables\n",
    "\n",
    "Categorical variables usually need to be transformed with 'one-hot-encoding' in order to be processed by a learning algorithm.\n",
    "\n",
    "In the following, we add some categorical variables (color, language, country, content_rating) to the preprocessed dataset, and use them to improve prediction performance.\n",
    "\n",
    "We can do the one-hot encoding using pandas `get_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41510451",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_vars = factor_cols\n",
    "data_factor = data[factor_vars]\n",
    "\n",
    "variables_to_keep = [\"color\", \"language\", \"country\", \"content_rating\"]\n",
    "\n",
    "data_factor_onehot = pd.get_dummies(data_factor[variables_to_keep], prefix=variables_to_keep, dummy_na=False)\n",
    "\n",
    "data_preprocessed_extended = pd.concat([data_preprocessed, data_factor_onehot], axis=1)\n",
    "X = data_preprocessed_extended.drop(columns=['imdb_score'])\n",
    "Y = data_preprocessed_extended['imdb_score'].values\n",
    "N, n = X.shape\n",
    "\n",
    "X.columns = [c.replace(\" \", \"_\").replace(\"-\", \"_\") for c in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557ab862-4373-4a05-a4df-24f49a8094f2",
   "metadata": {},
   "source": [
    "## Using other predictive models\n",
    "\n",
    "We can try other models like SVM (SVR), Neural Networks (MLPRegressor), K-Nearest Neighbors (KNeighborsRegressor) and see if performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a9ab0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error= 1.1883 ; std dev= 0.213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "CV_err_svm_single_model = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = SVR()\n",
    "    model.fit(X_tr, Y_tr)\n",
    "    Y_hat_ts = model.predict(X_ts)\n",
    "    CV_err_svm_single_model.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "\n",
    "print(\"CV error=\",round(np.mean(CV_err_svm_single_model),4),\n",
    "      \"; std dev=\", round(np.std(CV_err_svm_single_model),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2953483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Features: 1 ; CV error= 1.21 ; std dev= 0.2373\n",
      "#Features: 2 ; CV error= 1.1264 ; std dev= 0.2295\n",
      "#Features: 3 ; CV error= 1.0468 ; std dev= 0.2358\n",
      "#Features: 4 ; CV error= 1.0875 ; std dev= 0.2352\n",
      "#Features: 5 ; CV error= 1.1004 ; std dev= 0.2347\n",
      "#Features: 6 ; CV error= 1.1629 ; std dev= 0.2201\n",
      "#Features: 7 ; CV error= 1.1787 ; std dev= 0.2237\n",
      "#Features: 8 ; CV error= 1.1783 ; std dev= 0.2237\n",
      "#Features: 9 ; CV error= 1.1782 ; std dev= 0.2238\n",
      "#Features: 10 ; CV error= 1.1781 ; std dev= 0.2239\n"
     ]
    }
   ],
   "source": [
    "# Feature selection with mRMR for SVM\n",
    "\n",
    "n_variables = 10\n",
    "\n",
    "CV_err_svm_single_model_fs = np.zeros((n_variables,10))\n",
    "fold_id = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    mutual_info_values = compute_mi_vector(X_tr, Y_tr)\n",
    "    selected = []\n",
    "    candidates = list(range(n))\n",
    "    \n",
    "    for j in range(n_variables):\n",
    "        redundancy_score = np.zeros(len(candidates))\n",
    "        if len(selected)>0:\n",
    "            for ci, cidx in enumerate(candidates):\n",
    "                col_c = X_tr.iloc[:, cidx].values\n",
    "                mis_c = []\n",
    "                for sidx in selected:\n",
    "                    col_s = X_tr.iloc[:, sidx].values\n",
    "                    cc = np.corrcoef(col_s, col_c)[0,1]\n",
    "                    if abs(cc)==1:\n",
    "                        cc=0.999999\n",
    "                    mis_c.append(-0.5*np.log(1-cc**2))\n",
    "                redundancy_score[ci] = np.mean(mis_c)\n",
    "        mRMR_score = mutual_info_values[candidates] - redundancy_score\n",
    "        best_idx = candidates[np.argmax(mRMR_score)]\n",
    "        selected.append(best_idx)\n",
    "        candidates.remove(best_idx)\n",
    "        \n",
    "    # Evaluate performance with subsets of selected features\n",
    "    for nb_features in range(1, n_variables+1):\n",
    "        feats = [X.columns[i] for i in selected[:nb_features]]\n",
    "        model = SVR()\n",
    "        model.fit(X_tr[feats], Y_tr)\n",
    "        Y_hat_ts = model.predict(X_ts[feats])\n",
    "        CV_err_svm_single_model_fs[nb_features-1, fold_id] = np.mean((Y_hat_ts - Y_ts)**2)\n",
    "    fold_id+=1\n",
    "\n",
    "for i in range(n_variables):\n",
    "    print(\"#Features:\", i+1, \"; CV error=\",round(np.mean(CV_err_svm_single_model_fs[i,:]),4),\n",
    "          \"; std dev=\", round(np.std(CV_err_svm_single_model_fs[i,:]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4ea98ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error= 1.1967 ; std dev= 0.2135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "CV_err_nnet_single_model = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Rescale input to 0-1\n",
    "    min_X, max_X = np.min(X_tr), np.max(X_tr)\n",
    "    X_tr = (X_tr-min_X)/(max_X-min_X)\n",
    "    X_ts = (X_ts-min_X)/(max_X-min_X)\n",
    "    \n",
    "    # Rescale output to 0-1\n",
    "    Y_tr_rescale = Y_tr/10.0\n",
    "    model = MLPRegressor(hidden_layer_sizes=(20, 10), max_iter=1000000, random_state=3)\n",
    "    model.fit(X_tr, Y_tr_rescale)\n",
    "    Y_hat_ts = model.predict(X_ts)*10.0\n",
    "    CV_err_nnet_single_model.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "\n",
    "print(\"CV error=\",round(np.mean(CV_err_nnet_single_model),4), \"; std dev=\", round(np.std(CV_err_nnet_single_model),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0c1e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Features: 1 ; CV error= 1.2132 ; std dev= 0.2146\n",
      "#Features: 2 ; CV error= 1.2131 ; std dev= 0.2127\n",
      "#Features: 3 ; CV error= 1.2132 ; std dev= 0.2117\n",
      "#Features: 4 ; CV error= 1.2132 ; std dev= 0.2132\n",
      "#Features: 5 ; CV error= 1.213 ; std dev= 0.2127\n",
      "#Features: 6 ; CV error= 1.2135 ; std dev= 0.2129\n",
      "#Features: 7 ; CV error= 1.3368 ; std dev= 0.248\n",
      "#Features: 8 ; CV error= 1.1862 ; std dev= 0.2101\n",
      "#Features: 9 ; CV error= 1.1856 ; std dev= 0.2141\n",
      "#Features: 10 ; CV error= 1.2076 ; std dev= 0.2133\n"
     ]
    }
   ],
   "source": [
    "CV_err_nnet_single_model_fs = np.zeros((n_variables,10))\n",
    "fold_id=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    # Rescale input to 0-1\n",
    "    min_X, max_X = np.min(X_tr), np.max(X_tr)\n",
    "    X_tr = (X_tr-min_X)/(max_X-min_X)\n",
    "    X_ts = (X_ts-min_X)/(max_X-min_X)\n",
    "    \n",
    "    mutual_info_values = compute_mi_vector(X_tr, Y_tr)\n",
    "    selected = []\n",
    "    candidates = list(range(n))\n",
    "    \n",
    "    for j in range(n_variables):\n",
    "        redundancy_score = np.zeros(len(candidates))\n",
    "        if len(selected)>0:\n",
    "            for ci, cidx in enumerate(candidates):\n",
    "                col_c = X_tr.iloc[:, cidx].values\n",
    "                mis_c = []\n",
    "                for sidx in selected:\n",
    "                    col_s = X_tr.iloc[:, sidx].values\n",
    "                    cc = np.corrcoef(col_s, col_c)[0,1]\n",
    "                    if abs(cc)==1:\n",
    "                        cc=0.999999\n",
    "                    mis_c.append(-0.5*np.log(1-cc**2))\n",
    "                redundancy_score[ci] = np.mean(mis_c)\n",
    "        mRMR_score = mutual_info_values[candidates] - redundancy_score\n",
    "        best_idx = candidates[np.argmax(mRMR_score)]\n",
    "        selected.append(best_idx)\n",
    "        candidates.remove(best_idx)\n",
    "        \n",
    "    for nb_features in range(1, n_variables+1):\n",
    "        feats = [X.columns[i] for i in selected[:nb_features]]\n",
    "        Y_tr_rescale = Y_tr/10.0\n",
    "        model = MLPRegressor(hidden_layer_sizes=(20, 10), max_iter=1000000, random_state=3)\n",
    "        model.fit(X_tr[feats], Y_tr_rescale)\n",
    "        Y_hat_ts = model.predict(X_ts[feats])*10.0\n",
    "        CV_err_nnet_single_model_fs[nb_features-1, fold_id] = np.mean((Y_hat_ts - Y_ts)**2)\n",
    "    fold_id+=1\n",
    "\n",
    "for i in range(n_variables):\n",
    "    print(\"#Features:\", i+1, \"; CV error=\",round(np.mean(CV_err_nnet_single_model_fs[i,:]),4),\n",
    "          \"; std dev=\", round(np.std(CV_err_nnet_single_model_fs[i,:]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cea8b8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error= 1.3163 ; std dev= 0.2438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "CV_err_lazy_single_model = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    model = KNeighborsRegressor(n_neighbors=5)\n",
    "    model.fit(X_tr, Y_tr)\n",
    "    Y_hat_ts = model.predict(X_ts)\n",
    "    CV_err_lazy_single_model.append(np.mean((Y_hat_ts - Y_ts)**2))\n",
    "\n",
    "print(\"CV error=\",round(np.mean(CV_err_lazy_single_model),4),\n",
    "      \"; std dev=\", round(np.std(CV_err_lazy_single_model),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57e4b07f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Features: 1 ; CV error= 1.2271 ; std dev= 0.2408\n",
      "#Features: 2 ; CV error= 1.2897 ; std dev= 0.2448\n",
      "#Features: 3 ; CV error= 1.1045 ; std dev= 0.2074\n",
      "#Features: 4 ; CV error= 1.1318 ; std dev= 0.2232\n",
      "#Features: 5 ; CV error= 1.1636 ; std dev= 0.2545\n",
      "#Features: 6 ; CV error= 1.2591 ; std dev= 0.293\n",
      "#Features: 7 ; CV error= 1.3438 ; std dev= 0.2411\n",
      "#Features: 8 ; CV error= 1.2756 ; std dev= 0.1949\n",
      "#Features: 9 ; CV error= 1.277 ; std dev= 0.1748\n",
      "#Features: 10 ; CV error= 1.2951 ; std dev= 0.1621\n"
     ]
    }
   ],
   "source": [
    "# Feature selection for KNN using mRMR\n",
    "CV_err_lazy_single_model_fs = np.zeros((n_variables,10))\n",
    "fold_id=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_tr, X_ts = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_tr, Y_ts = Y[train_index], Y[test_index]\n",
    "    \n",
    "    mutual_info_values = compute_mi_vector(X_tr, Y_tr)\n",
    "    selected = []\n",
    "    candidates = list(range(n))\n",
    "    \n",
    "    for j in range(n_variables):\n",
    "        redundancy_score = np.zeros(len(candidates))\n",
    "        if len(selected)>0:\n",
    "            for ci, cidx in enumerate(candidates):\n",
    "                col_c = X_tr.iloc[:, cidx].values\n",
    "                mis_c = []\n",
    "                for sidx in selected:\n",
    "                    col_s = X_tr.iloc[:, sidx].values\n",
    "                    cc = np.corrcoef(col_s, col_c)[0,1]\n",
    "                    if abs(cc)==1:\n",
    "                        cc=0.999999\n",
    "                    mis_c.append(-0.5*np.log(1-cc**2))\n",
    "                redundancy_score[ci] = np.mean(mis_c)\n",
    "        mRMR_score = mutual_info_values[candidates] - redundancy_score\n",
    "        best_idx = candidates[np.argmax(mRMR_score)]\n",
    "        selected.append(best_idx)\n",
    "        candidates.remove(best_idx)\n",
    "        \n",
    "    for nb_features in range(1, n_variables+1):\n",
    "        feats = [X.columns[i] for i in selected[:nb_features]]\n",
    "        model = KNeighborsRegressor(n_neighbors=5)\n",
    "        model.fit(X_tr[feats], Y_tr)\n",
    "        Y_hat_ts = model.predict(X_ts[feats])\n",
    "        CV_err_lazy_single_model_fs[nb_features-1, fold_id] = np.mean((Y_hat_ts - Y_ts)**2)\n",
    "    fold_id+=1\n",
    "\n",
    "for i in range(n_variables):\n",
    "    print(\"#Features:\", i+1, \"; CV error=\",round(np.mean(CV_err_lazy_single_model_fs[i,:]),4),\n",
    "          \"; std dev=\", round(np.std(CV_err_lazy_single_model_fs[i,:]),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1f250",
   "metadata": {},
   "source": [
    "#### Ridge regression with LOO-CV\n",
    "Recall: Ridge regression looks like a linear regression but includes a penalty term for large coefficients:\n",
    "$$\n",
    "  \\min_{\\beta} \\;\\; \\| Y - X \\beta \\|^2 + \\alpha \\| \\beta \\|^2.\n",
    "$$\n",
    "\n",
    "\n",
    "Ridge also has a known closed-form:\n",
    "$$\n",
    "  \\hat{\\beta}_{\\mathrm{ridge}} = (X^\\top X + \\alpha I)^{-1} X^\\top Y.\n",
    "$$\n",
    "\n",
    "* Leave-one out cross-validation is a method that consists in evaluating a given model by training it on the entire training set, except for one sample used for validation. By performing this validation, eliminating each of the samples at a time, we get an estimation of the quality of the model.\n",
    "* Then, the coefficients can give an idea of the importance of each of the features in the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92ff5cf4-5baf-43f2-a515-21fa93cd82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_preprocessed['imdb_score'].values\n",
    "X = data_preprocessed.drop(columns=['imdb_score'])\n",
    "X_np = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "01de437f-8944-46a9-9ca4-5d475b90be1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha: 1\n",
      "Greatests coefficients indexes: [ 0 14  9  2]\n",
      "Greatests coefficients: [ 1.3710444   0.07399823 -0.02049075  0.00767804]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = X_np.shape[0]\n",
    "alphas = np.arange(1, X_np.shape[1], 1) \n",
    "E = np.empty((N, len(alphas)))  \n",
    "E[:] = np.nan\n",
    "\n",
    "for i in range(N):\n",
    "    Xtr = np.column_stack((np.ones(N - 1), np.delete(X_np, i, axis=0)))\n",
    "    Ytr = np.delete(Y, i)\n",
    "    \n",
    "    Xts = np.concatenate(([1], X_np[i,]))\n",
    "    \n",
    "    cnt = 0\n",
    "    for alpha in alphas:\n",
    "        A = Xtr.T @ Xtr + alpha * np.eye(n + 1)\n",
    "        b = Xtr.T @ Ytr\n",
    "        betahat = np.linalg.inv(A) @ b\n",
    "        Yhati = Xts @ betahat\n",
    "        E[i, cnt] = (Y[i] - Yhati) ** 2\n",
    "        cnt += 1\n",
    "\n",
    "mseloo = np.mean(E, axis=0)\n",
    "\n",
    "bestAlpha = alphas[np.argmin(np.mean(E, axis=0))]\n",
    "print(f\"best alpha: {bestAlpha}\")\n",
    "\n",
    "XX = np.column_stack((np.ones(N), X_np))\n",
    "A_final = np.dot(XX.T, XX) + bestAlpha * np.eye(n + 1)\n",
    "b_final = np.dot(XX.T, Y)\n",
    "betahat = np.linalg.inv(A_final) @ XX.T @ Y\n",
    "\n",
    "abs_betahat = np.abs(betahat)\n",
    "sorted_indices = np.argsort(-abs_betahat)\n",
    "top4 = sorted_indices[:4] \n",
    "print(f\"Greatests coefficients indexes: {top4}\")\n",
    "print(f\"Greatests coefficients: {betahat[top4]}\")\n",
    "plt.plot(alphas, mseloo)\n",
    "plt.title('MSE.loo vs Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015419b2-9ad9-4844-b30a-a3ce0efc88d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
